{
    "id": "H-84",
    "original_text": "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner. Previous research focused only on organizing news stories by their topics into a flat hierarchy. We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly. In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models. We call the process of recognizing events and their dependencies event threading. We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories. We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem. Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies. Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1. INTRODUCTION News forms a major portion of information disseminated in the world everyday. Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day. Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly. This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization. One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories. For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics. However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events. This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3]. For example, when a bomb explodes in a building, that is the seminal event that triggers the topic. Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on. We see that there is a pattern of dependencies between pairs of events in the topic. In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators. In this work we investigate methods for modeling the structure of a topic in terms of its events. By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them. We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages. We refer to the resulting interconnected structure of events as the event model of the topic. Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do. From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster. The rest of the paper is organized as follows. In section 2, we discuss related work. In section 3, we define the problem and use an example to illustrate threading of events within a news topic. In section 4, we describe how we built the corpus for our problem. Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure. In section 7 we present our experiments and results. Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2. RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part. Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7]. Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion. Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6]. The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships. Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models. Our work differs from theirs in that we do not constrain the dependency to be linear. Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic. In TDT, researchers have traditionally considered topics as flatclusters [1]. However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure. However this structure still did not explicitly model any dependencies between events. In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events. However, the paper stopped short of proposing any models to the problem. Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3. PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT. We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1. Story: A story is a news article delivering some information to users. In TDT, a story is assumed to refer to only a single topic. In this work, we also assume that each story discusses a single event. In other words, a story is the smallest atomic unit in the hierarchy (topic event story). Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2. Event: An event is something that happens at some specific time and place [10]. In our work, we represent an event by a set of stories that discuss it. Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3. Topic: A set of news stories strongly connected by a seminal event. We expand on this definition and interpret a topic as a series of related events. Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events. We will describe this representation of a topic in more detail in the next section. 4. Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3]. Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5. Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events. Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics. Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories. We first define our problem and representation of our model formally and then illustrate with the help of an example. We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication. We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event. The last constraint tells us that every story belongs to one of the events in . In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events. It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering. By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A. By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A. For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident. Clearly, the investigations are a result of the crash. Hence an arrow from A to B falls under the category of causal dependency. Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba. Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A. An arrow in such scenario captures what we call time ordering. In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical. A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges. This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic. To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news). This topic has 23 stories which form 5 events. An event model of this topic can be represented as in figure 1. Each box in the figure indicates an event in the topic of Osamas indictment. The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1. Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward. Thus all the dependencies in the example are causal. Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ . We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies. Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment. Event threading is strongly related to topic detection and tracking, but also different from it significantly. It goes beyond topics, and models the relationships between events. Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1. The number of events is unknown. 2. The granularity of events is hard to define. 3. The dependencies among events are hard to model. 4. Since it is a brand new research area, no standard evaluation metrics and benchmark data is available. In the next few sections, we will describe our attempts to tackle these problems. 4. LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus. The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news. If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators. The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme. We believe modeling such stories would be a useful first step before dealing with more complex data sets. We hired an annotator to create truth data. Annotation includes defining the event membership for each story and also the dependencies. We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3. In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location. The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B. This is to satisfy our assumption that each story corresponds to a unique event. The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible. We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small. As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic. We believe that this would help make her understanding of the events more concrete. We however, do not use or model these titles in our algorithms. In defining dependencies between events, we imposed no restrictions on the graph structure. Each event could have single, multiple or no parents. Further, the graph could have cycles or orphannodes. The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time. From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly. Table 1 shows that the training and test sets have fairly similar statistics. Feature Training set Test set Num. topics 26 27 Avg. Num. Stories/Topic 28.69 26.74 Avg. Doc. Len. 64.60 64.04 Avg. Num. Stories/Event 5.65 6.22 Avg. Num. Events/Topic 5.07 4.29 Avg. Num. Dependencies/Topic 3.07 2.92 Avg. Num. Dependencies/Event 0.61 0.68 Avg. Num. Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5. EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake). Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure. And different event granularities may bring huge discrepancy between Å¼ and Å. This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution. Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies. Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å. Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ. In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake. As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation. Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event. È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event. Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼. Note that the direction of dependency is important in comparison. È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å. Again, the direction of dependency is taken into consideration. Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2. We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6. TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them. In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them. For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream. This task is similar to traditional clustering but features other than word distributions may also be critical in our application. In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features. Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature. Additionally, named-entities such as person and location names are another obvious feature when forming events. Stories in the same event tend to be related to the same person(s) and locations(s). In this subsection, we present an agglomerative clustering algorithm that combines all these features. In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story. So the similarity between two events, to start with, is exactly the similarity between the corresponding stories. The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features. In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them. Ó×´×½ ×¾µ is the cosine similarity of the term vectors. ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0. È Ö´×½ ×¾µ is similarly defined for person name. We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities. The time period of each topic differs a lot, from a few days to a few months. So we normalize the time difference using the whole duration of that topic. The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively. T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor. In each iteration, we find the most similar event pair and merge them. We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question. A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world. For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general. We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them. Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent. In this subsection, we describe the models we considered for capturing dependencies. In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼. First we define a couple of features that the following models will employ. First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication. Now, the event-time-ordering function Ø is defined as follows. Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories. We will also use average cosine similarity between two events as a feature and it is defined as follows. Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events. The direction of dependency is determined by the time-ordering of the first stories in the respective events. Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function. In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú . We point out that this is not to be confused with the complete-link algorithm in clustering. Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì. Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent. We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate. The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent. An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì. Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼. Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7. EXPERIMENTS Our experiments consists of three parts. First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1. Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2. Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model. This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components. The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance. All the parameters are learned by tuning on the training set. We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training. We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline. The results on the training and test sets are in Table 2 and 3 respectively. We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion. Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test). The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering. In equation 12, ½ ½, ¾ ¿ ¼. And « ¼ in equation 13. This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used. Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12. All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm. When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì. Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs. We had expected locations and person names to improve the result, but it is not the case. Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events. Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time. Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity. However, for most applications, it is not available. We used it only as a cheat experiment for comparison with other algorithms. On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies. We use the true mapping function and by implication the true events Î . We build our dependency structure ¼ using all the five models described in section 6.2. We first train our models on the 26 training topics. Training involves learning the best threshold Ì for each of the models. We then test the performances of all the trained models on the 27 test topics. We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF). We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents. Table 4 lists the results on the training set. We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level. Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level. In table 5 we present the comparison of the models on the test set. Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set. The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set. However all the other models are better than the baseline including the best similarity which is statistically significant. Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure. We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant. On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set. Although there is a lot of room for improvement, we believe this is a good first step. Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model. Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation. From the clustering techniques, we choose the best performing Cos+TD. As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies. Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure. For each algorithm, we need to optimize both the clustering threshold and the dependency threshold. We did this empirically on the training set and the optimal values are listed in table 6. The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level. On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance. Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality. Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance. The results on the test set present a very similar story as shown in table 7. We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly. The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8. DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics. Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies. In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them. We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity. Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system. However, the performance deteriorates rapidly if the system has to discover the events by itself. Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines. Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level. Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments. Hence, we should focus not only on improving dependencies but also on clustering at the same time. As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies. And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events. We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers. We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures. Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments. This work was supported in part by the Center 452 Model Cluster T Dep. T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903. Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9. REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. Topic detection and tracking pilot study: Final report. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar. Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor. Topic Detection and Tracking:Event based Information Organization. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal. Temporal summaries of new topics. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18. ACM Press, 2001. [5] Regina Barzilay and Lillian Lee. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft. Discovering and comparing topic hierarchies. In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles. Threading electronic mail: a preliminary study. Inf. Process. Manage., 33(2):209-217, 1997. [8] Juha Makkonen. Investigations on event evolution in tdt. In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim. Hierarchical text classification and evaluation. In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu. Learning approaches for detecting and tracking news events. In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453",
    "original_translation": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453",
    "original_sentences": [
        "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
        "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
        "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
        "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
        "We call the process of recognizing events and their dependencies event threading.",
        "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
        "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
        "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
        "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
        "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
        "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
        "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
        "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
        "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
        "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
        "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
        "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
        "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
        "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
        "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
        "We see that there is a pattern of dependencies between pairs of events in the topic.",
        "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
        "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
        "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
        "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
        "We refer to the resulting interconnected structure of events as the event model of the topic.",
        "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
        "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
        "The rest of the paper is organized as follows.",
        "In section 2, we discuss related work.",
        "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
        "In section 4, we describe how we built the corpus for our problem.",
        "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
        "In section 7 we present our experiments and results.",
        "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
        "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
        "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
        "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
        "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
        "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
        "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
        "Our work differs from theirs in that we do not constrain the dependency to be linear.",
        "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
        "In TDT, researchers have traditionally considered topics as flatclusters [1].",
        "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
        "However this structure still did not explicitly model any dependencies between events.",
        "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
        "However, the paper stopped short of proposing any models to the problem.",
        "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
        "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
        "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
        "Story: A story is a news article delivering some information to users.",
        "In TDT, a story is assumed to refer to only a single topic.",
        "In this work, we also assume that each story discusses a single event.",
        "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
        "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
        "Event: An event is something that happens at some specific time and place [10].",
        "In our work, we represent an event by a set of stories that discuss it.",
        "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
        "Topic: A set of news stories strongly connected by a seminal event.",
        "We expand on this definition and interpret a topic as a series of related events.",
        "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
        "We will describe this representation of a topic in more detail in the next section. 4.",
        "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
        "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
        "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
        "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
        "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
        "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
        "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
        "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
        "The last constraint tells us that every story belongs to one of the events in .",
        "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
        "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
        "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
        "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
        "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
        "Clearly, the investigations are a result of the crash.",
        "Hence an arrow from A to B falls under the category of causal dependency.",
        "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
        "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
        "An arrow in such scenario captures what we call time ordering.",
        "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
        "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
        "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
        "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
        "This topic has 23 stories which form 5 events.",
        "An event model of this topic can be represented as in figure 1.",
        "Each box in the figure indicates an event in the topic of Osamas indictment.",
        "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
        "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
        "Thus all the dependencies in the example are causal.",
        "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
        "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
        "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
        "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
        "It goes beyond topics, and models the relationships between events.",
        "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
        "The number of events is unknown. 2.",
        "The granularity of events is hard to define. 3.",
        "The dependencies among events are hard to model. 4.",
        "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
        "In the next few sections, we will describe our attempts to tackle these problems. 4.",
        "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
        "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
        "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
        "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
        "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
        "We hired an annotator to create truth data.",
        "Annotation includes defining the event membership for each story and also the dependencies.",
        "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
        "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
        "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
        "This is to satisfy our assumption that each story corresponds to a unique event.",
        "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
        "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
        "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
        "We believe that this would help make her understanding of the events more concrete.",
        "We however, do not use or model these titles in our algorithms.",
        "In defining dependencies between events, we imposed no restrictions on the graph structure.",
        "Each event could have single, multiple or no parents.",
        "Further, the graph could have cycles or orphannodes.",
        "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
        "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
        "Table 1 shows that the training and test sets have fairly similar statistics.",
        "Feature Training set Test set Num. topics 26 27 Avg.",
        "Num.",
        "Stories/Topic 28.69 26.74 Avg.",
        "Doc.",
        "Len. 64.60 64.04 Avg.",
        "Num.",
        "Stories/Event 5.65 6.22 Avg.",
        "Num.",
        "Events/Topic 5.07 4.29 Avg.",
        "Num.",
        "Dependencies/Topic 3.07 2.92 Avg.",
        "Num.",
        "Dependencies/Event 0.61 0.68 Avg.",
        "Num.",
        "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
        "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
        "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
        "And different event granularities may bring huge discrepancy between Å¼ and Å.",
        "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
        "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
        "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
        "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
        "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
        "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
        "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
        "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
        "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
        "Note that the direction of dependency is important in comparison.",
        "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
        "Again, the direction of dependency is taken into consideration.",
        "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
        "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
        "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
        "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
        "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
        "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
        "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
        "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
        "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
        "Stories in the same event tend to be related to the same person(s) and locations(s).",
        "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
        "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
        "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
        "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
        "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
        "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
        "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
        "È Ö´×½ ×¾µ is similarly defined for person name.",
        "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
        "The time period of each topic differs a lot, from a few days to a few months.",
        "So we normalize the time difference using the whole duration of that topic.",
        "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
        "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
        "In each iteration, we find the most similar event pair and merge them.",
        "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
        "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
        "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
        "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
        "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
        "In this subsection, we describe the models we considered for capturing dependencies.",
        "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
        "First we define a couple of features that the following models will employ.",
        "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
        "Now, the event-time-ordering function Ø is defined as follows.",
        "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
        "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
        "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
        "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
        "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
        "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
        "We point out that this is not to be confused with the complete-link algorithm in clustering.",
        "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
        "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
        "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
        "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
        "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
        "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
        "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
        "EXPERIMENTS Our experiments consists of three parts.",
        "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
        "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
        "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
        "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
        "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
        "All the parameters are learned by tuning on the training set.",
        "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
        "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
        "The results on the training and test sets are in Table 2 and 3 respectively.",
        "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
        "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
        "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
        "In equation 12, ½ ½, ¾ ¿ ¼.",
        "And « ¼ in equation 13.",
        "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
        "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
        "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
        "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
        "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
        "We had expected locations and person names to improve the result, but it is not the case.",
        "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
        "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
        "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
        "However, for most applications, it is not available.",
        "We used it only as a cheat experiment for comparison with other algorithms.",
        "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
        "We use the true mapping function and by implication the true events Î .",
        "We build our dependency structure ¼ using all the five models described in section 6.2.",
        "We first train our models on the 26 training topics.",
        "Training involves learning the best threshold Ì for each of the models.",
        "We then test the performances of all the trained models on the 27 test topics.",
        "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
        "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
        "Table 4 lists the results on the training set.",
        "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
        "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
        "In table 5 we present the comparison of the models on the test set.",
        "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
        "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
        "However all the other models are better than the baseline including the best similarity which is statistically significant.",
        "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
        "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
        "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
        "Although there is a lot of room for improvement, we believe this is a good first step.",
        "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
        "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
        "From the clustering techniques, we choose the best performing Cos+TD.",
        "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
        "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
        "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
        "We did this empirically on the training set and the optimal values are listed in table 6.",
        "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
        "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
        "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
        "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
        "The results on the test set present a very similar story as shown in table 7.",
        "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
        "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
        "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
        "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
        "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
        "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
        "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
        "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
        "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
        "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
        "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
        "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
        "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
        "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
        "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
        "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
        "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
        "This work was supported in part by the Center 452 Model Cluster T Dep.",
        "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
        "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
        "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
        "Topic detection and tracking pilot study: Final report.",
        "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
        "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
        "Topic Detection and Tracking:Event based Information Organization.",
        "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
        "Temporal summaries of new topics.",
        "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
        "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
        "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
        "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
        "Discovering and comparing topic hierarchies.",
        "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
        "Threading electronic mail: a preliminary study.",
        "Inf.",
        "Process.",
        "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
        "Investigations on event evolution in tdt.",
        "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
        "Hierarchical text classification and evaluation.",
        "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
        "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
        "Learning approaches for detecting and tracking news events.",
        "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
    ],
    "translated_text_sentences": [
        "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente.",
        "Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana.",
        "Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema.",
        "En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos.",
        "Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos.",
        "Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema.",
        "Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema.",
        "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias.",
        "Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1.",
        "INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días.",
        "Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día.",
        "Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente.",
        "Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias.",
        "Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias.",
        "Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas.",
        "Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados.",
        "Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3].",
        "Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema.",
        "Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros.",
        "Vemos que hay un patrón de dependencias entre pares de eventos en el tema.",
        "En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores.",
        "En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos.",
        "Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos.",
        "Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados.",
        "Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema.",
        "Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados.",
        "Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente.",
        "El resto del documento está organizado de la siguiente manera.",
        "En la sección 2, discutimos el trabajo relacionado.",
        "En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias.",
        "En la sección 4, describimos cómo construimos el corpus para nuestro problema.",
        "La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos.",
        "En la sección 7 presentamos nuestros experimentos y resultados.",
        "La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2.",
        "TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte.",
        "El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7].",
        "El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión.",
        "Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6].",
        "La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos.",
        "Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov.",
        "Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal.",
        "También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema.",
        "En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1].",
        "Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura.",
        "Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos.",
        "En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución.",
        "Sin embargo, el artículo no llegó a proponer ningún modelo para el problema.",
        "Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3.",
        "DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT.",
        "Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1.",
        "Historia: Una historia es un artículo de noticias que entrega información a los usuarios.",
        "En TDT, se asume que una historia se refiere solo a un tema.",
        "En este trabajo, también asumimos que cada historia discute un solo evento.",
        "En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia).",
        "Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2.",
        "Evento: Un evento es algo que sucede en un momento y lugar específicos [10].",
        "En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten.",
        "Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3.",
        "Un conjunto de noticias fuertemente conectadas por un evento seminal.",
        "Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados.",
        "Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos.",
        "Describiremos esta representación de un tema con más detalle en la siguiente sección. 4.",
        "Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3].",
        "Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5.",
        "Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos.",
        "Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios.",
        "Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias.",
        "Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo.",
        "Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación.",
        "Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento.",
        "La última restricción nos dice que cada historia pertenece a uno de los eventos en .",
        "De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos.",
        "Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal.",
        "Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A.",
        "Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A.",
        "Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión.",
        "Claramente, las investigaciones son resultado del accidente.",
        "Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal.",
        "Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba.",
        "Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A.",
        "Una flecha en dicho escenario captura lo que llamamos orden temporal.",
        "En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos.",
        "Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos.",
        "Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema.",
        "Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998).",
        "Este tema tiene 23 historias que forman 5 eventos.",
        "Un modelo de evento de este tema puede ser representado como en la figura 1.",
        "Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama.",
        "La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1.",
        "De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa.",
        "Por lo tanto, todas las dependencias en el ejemplo son causales.",
        "Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾.",
        "Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias.",
        "El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden.",
        "El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello.",
        "Va más allá de los temas y modela las relaciones entre eventos.",
        "Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1.",
        "El número de eventos es desconocido. 2.",
        "La granularidad de los eventos es difícil de definir.",
        "Las dependencias entre eventos son difíciles de modelar. 4.",
        "Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles.",
        "En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4.",
        "DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3.",
        "El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN.",
        "Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores.",
        "La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central.",
        "Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos.",
        "Contratamos a un anotador para crear datos verídicos.",
        "La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias.",
        "Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3.",
        "Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos.",
        "Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B.",
        "Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único.",
        "Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible.",
        "Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño.",
        "Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema.",
        "Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta.",
        "Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos.",
        "Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo.",
        "Cada evento podría tener uno, varios o ningún padre.",
        "Además, el gráfico podría tener ciclos o nodos huérfanos.",
        "Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo.",
        "A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente.",
        "La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares.",
        "Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom.",
        "Número.",
        "Historias/Tema 28.69 26.74 Prom.",
        "\"Doc.\"",
        "Len. 64.60 64.04 Prom.",
        "Número.",
        "Historias/Evento 5.65 6.22 Prom.",
        "Número.",
        "Eventos/Tema 5.07 4.29 Prom.",
        "Número.",
        "Dependencias/Tema 3.07 2.92 Prom.",
        "Número.",
        "Dependencias/Evento 0.61 0.68 Prom.",
        "Número.",
        "Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5.",
        "Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error).",
        "Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia.",
        "Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å.",
        "Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico.",
        "Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias.",
        "Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å.",
        "Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ.",
        "En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta.",
        "Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación.",
        "Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema.",
        "Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero.",
        "Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼.",
        "Ten en cuenta que la dirección de la dependencia es importante en la comparación.",
        "Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å.",
        "Nuevamente, se toma en consideración la dirección de la dependencia.",
        "Las medidas se ilustran con un ejemplo en la figura 2.",
        "También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6.",
        "TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos.",
        "En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos.",
        "Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto.",
        "Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación.",
        "En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características.",
        "Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil.",
        "Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos.",
        "Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es).",
        "En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características.",
        "En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia.",
        "Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes.",
        "La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características.",
        "En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos.",
        "La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ.",
        "La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0.",
        "El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona.",
        "Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud.",
        "El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses.",
        "Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema.",
        "La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente.",
        "T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal.",
        "En cada iteración, encontramos el par de eventos más similar y los fusionamos.",
        "Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión.",
        "Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo.",
        "Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general.",
        "Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas.",
        "Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida.",
        "En esta subsección, describimos los modelos que consideramos para capturar dependencias.",
        "En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼.",
        "Primero definimos un par de características que los modelos siguientes emplearán.",
        "Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación.",
        "Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera.",
        "En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias.",
        "También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera.",
        "En este modelo, asumimos que existen dependencias entre todos los pares de eventos.",
        "La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos.",
        "Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo.",
        "En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú.",
        "Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento.",
        "Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì.",
        "Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre.",
        "Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial.",
        "El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre.",
        "Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì.",
        "Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼.",
        "Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema.",
        "Nuestros experimentos consisten en tres partes.",
        "Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1.",
        "Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2.",
        "Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos.",
        "Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes.",
        "Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento.",
        "Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento.",
        "También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento.",
        "Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento.",
        "Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente.",
        "Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación.",
        "Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola).",
        "Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación.",
        "En la ecuación 12, ½ ½, ¾ ¿ ¼.",
        "Y « ¼ en la ecuación 13.",
        "Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15.",
        "Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12.",
        "Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo.",
        "Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì.",
        "Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias.",
        "Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso.",
        "El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos.",
        "La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo.",
        "También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta.",
        "Sin embargo, para la mayoría de las aplicaciones, no está disponible.",
        "Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos.",
        "En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias.",
        "Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î.",
        "Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2.",
        "Primero entrenamos nuestros modelos en los 26 temas de entrenamiento.",
        "El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos.",
        "Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba.",
        "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF).",
        "Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres.",
        "La tabla 4 enumera los resultados en el conjunto de entrenamiento.",
        "Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza.",
        "El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%.",
        "En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas.",
        "Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento.",
        "Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas.",
        "Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa.",
        "Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF.",
        "Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa.",
        "En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas.",
        "Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso.",
        "Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo.",
        "Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación.",
        "De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD.",
        "Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias.",
        "Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta.",
        "Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia.",
        "Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6.",
        "Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%.",
        "En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia.",
        "A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos.",
        "Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general.",
        "Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7.",
        "También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia.",
        "Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8.",
        "DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias.",
        "A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias.",
        "En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas.",
        "Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno.",
        "Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema.",
        "Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo.",
        "A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines.",
        "Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal.",
        "Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos.",
        "Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo.",
        "Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias.",
        "Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos.",
        "También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores.",
        "También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas.",
        "Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios.",
        "Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep.",
        "T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903.",
        "Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador.",
        "REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang.",
        "Estudio piloto de detección y seguimiento de temas: Informe final.",
        "En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar.",
        "Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor.",
        "Detección y seguimiento de temas: Organización de la información basada en eventos.",
        "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal.",
        "Resúmenes temporales de nuevos temas.",
        "En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18.",
        "ACM Press, 2001. [5] Regina Barzilay y Lillian Lee.",
        "Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen.",
        "En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft.",
        "Descubriendo y comparando jerarquías de temas.",
        "En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles.",
        "Hilvanado de correos electrónicos: un estudio preliminar.",
        "I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation?",
        "Proceso.",
        "Manejo., 33(2):209-217, 1997. [8] Juha Makkonen.",
        "Investigaciones sobre la evolución de eventos en tdt.",
        "En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim.",
        "Clasificación jerárquica de texto y evaluación.",
        "En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528.",
        "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu.",
        "Enfoques de aprendizaje para detectar y rastrear eventos de noticias.",
        "En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453"
    ],
    "error_count": 14,
    "keys": {
        "event threading": {
            "translated_key": "enhebrado de eventos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>event threading</br> within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies <br>event threading</br>.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them <br>event threading</br>, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "<br>event threading</br>: <br>event threading</br> detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between <br>event threading</br> and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally <br>event threading</br> models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of <br>event threading</br> more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "<br>event threading</br> is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, <br>event threading</br> can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "<br>event threading</br> within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "We call the process of recognizing events and their dependencies <br>event threading</br>.",
                "We call the process of recognizing events and identifying dependencies among them <br>event threading</br>, an analogy to email threading that shows connections between related email messages.",
                "<br>event threading</br>: <br>event threading</br> detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between <br>event threading</br> and TDT is that we focus our modeling effort on microscopic events rather than larger topics."
            ],
            "translated_annotated_samples": [
                "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente.",
                "Llamamos al proceso de reconocer eventos y sus dependencias como <br>enhebrado de eventos</br>.",
                "Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos <br>enhebrado de eventos</br>, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados.",
                "Enhebrado de eventos: El <br>enhebrado de eventos</br> detecta eventos dentro de un tema y también captura las dependencias entre los eventos.",
                "Por lo tanto, la principal diferencia entre el <br>enhebrado de eventos</br> y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como <br>enhebrado de eventos</br>. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos <br>enhebrado de eventos</br>, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El <br>enhebrado de eventos</br> detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el <br>enhebrado de eventos</br> y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "automatic technique": {
            "translated_key": "técnicas automáticas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for <br>automatic technique</br>s to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for <br>automatic technique</br>s to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for <br>automatic technique</br>s to analyze and present news to the user in a meaningful and efficient manner.",
                "Hence there is an increasing need for <br>automatic technique</br>s to organize news stories in a way that helps users interpret and analyze them quickly."
            ],
            "translated_annotated_samples": [
                "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de <br>técnicas automáticas</br> para analizar y presentar noticias al usuario de manera significativa y eficiente.",
                "Por lo tanto, hay una creciente necesidad de <br>técnicas automáticas</br> para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de <br>técnicas automáticas</br> para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de <br>técnicas automáticas</br> para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "flat hierarchy": {
            "translated_key": "jerarquía plana",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a <br>flat hierarchy</br>.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Previous research focused only on organizing news stories by their topics into a <br>flat hierarchy</br>."
            ],
            "translated_annotated_samples": [
                "Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una <br>jerarquía plana</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una <br>jerarquía plana</br>. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "dependency": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based <br>dependency</br> structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the <br>dependency</br> to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional <br>dependency</br>: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal <br>dependency</br> we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal <br>dependency</br>.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a <br>dependency</br> from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their <br>dependency</br> structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ <br>dependency</br> pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a <br>dependency</br> from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) <br>dependency</br> pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 <br>dependency</br> Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ <br>dependency</br> Precision(DP): It is the probability that there is a <br>dependency</br> between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of <br>dependency</br> is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ <br>dependency</br> Recall(DR): It is the probability that there is a <br>dependency</br> between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of <br>dependency</br> is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and <br>dependency</br> F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 <br>dependency</br> modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of <br>dependency</br> is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the <br>dependency</br> edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a <br>dependency</br> between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed <br>dependency</br> edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the <br>dependency</br> algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and <br>dependency</br> algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our <br>dependency</br> structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of <br>dependency</br> Precision (DP), <br>dependency</br> Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and <br>dependency</br> algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the <br>dependency</br> algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the <br>dependency</br> threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low <br>dependency</br> performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the <br>dependency</br> algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and <br>dependency</br> performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based <br>dependency</br> structure more accurately reflects the structure of news than strictly bounded topics do.",
                "Our work differs from theirs in that we do not constrain the <br>dependency</br> to be linear.",
                "It is important to explain what we mean by this directional <br>dependency</br>: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal <br>dependency</br> we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "Hence an arrow from A to B falls under the category of causal <br>dependency</br>."
            ],
            "translated_annotated_samples": [
                "Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una <br>estructura de dependencia</br> basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados.",
                "Nuestro trabajo difiere del de ellos en que no restringimos la <br>dependencia</br> a ser lineal.",
                "Es importante explicar lo que queremos decir con esta <br>dependencia</br> direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal.",
                "Por <br>dependencia causal</br> nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A.",
                "Por lo tanto, una flecha de A a B cae bajo la categoría de <br>dependencia causal</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una <br>estructura de dependencia</br> basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la <br>dependencia</br> a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta <br>dependencia</br> direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por <br>dependencia causal</br> nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de <br>dependencia causal</br>. ",
            "candidates": [],
            "error": [
                [
                    "estructura de dependencia",
                    "dependencia",
                    "dependencia",
                    "dependencia causal",
                    "dependencia causal"
                ]
            ]
        },
        "novel feature": {
            "translated_key": "características novedosas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account <br>novel feature</br>s such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Besides the standard word based features, our approaches take into account <br>novel feature</br>s such as temporal locality of stories for event recognition and time-ordering for capturing dependencies."
            ],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta <br>características novedosas</br> como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta <br>características novedosas</br> como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "temporal locality": {
            "translated_key": "localidad temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as <br>temporal locality</br> of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow <br>temporal locality</br>, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Besides the standard word based features, our approaches take into account novel features such as <br>temporal locality</br> of stories for event recognition and time-ordering for capturing dependencies.",
                "Stories in the same event tend to follow <br>temporal locality</br>, so the time stamp of each story can be a useful feature."
            ],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la <br>localidad temporal</br> de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias.",
                "Las historias en el mismo evento tienden a seguir una <br>localidad temporal</br>, por lo que la marca de tiempo de cada historia puede ser una característica útil."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la <br>localidad temporal</br> de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una <br>localidad temporal</br>, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "event recognition": {
            "translated_key": "reconocimiento de eventos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for <br>event recognition</br> and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for <br>event recognition</br> and time-ordering for capturing dependencies."
            ],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el <br>reconocimiento de eventos</br> y el orden temporal para capturar dependencias."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el <br>reconocimiento de eventos</br> y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "time-ordering": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and <br>time-ordering</br> for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as <br>time-ordering</br> of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 <br>time-ordering</br> function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-<br>time-ordering</br> function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the <br>time-ordering</br> of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the <br>time-ordering</br> of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-<br>time-ordering</br> function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and <br>time-ordering</br> for capturing dependencies.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as <br>time-ordering</br> of news stories and word distributions to model them.",
                "First we define a 1-1 <br>time-ordering</br> function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-<br>time-ordering</br> function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the <br>time-ordering</br> of their respective first stories."
            ],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el <br>orden temporal</br> para capturar dependencias.",
                "Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el <br>orden temporal</br> de las noticias y las distribuciones de palabras para modelarlas.",
                "Primero definimos una <br>función de ordenación temporal</br> 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación.",
                "Ahora, la función de <br>ordenación de eventos en el tiempo</br> Ø se define de la siguiente manera.",
                "En otras palabras, Ø ordena los eventos en función del <br>orden temporal</br> de sus respectivas primeras historias."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el <br>orden temporal</br> para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el <br>orden temporal</br> de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una <br>función de ordenación temporal</br> 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de <br>ordenación de eventos en el tiempo</br> Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del <br>orden temporal</br> de sus respectivas primeras historias. ",
            "candidates": [],
            "error": [
                [
                    "orden temporal",
                    "orden temporal",
                    "función de ordenación temporal",
                    "ordenación de eventos en el tiempo",
                    "orden temporal"
                ]
            ]
        },
        "news organization": {
            "translated_key": "organización de noticias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of <br>news organization</br>.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of <br>news organization</br>."
            ],
            "translated_annotated_samples": [
                "Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de <br>organización de noticias</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de <br>organización de noticias</br>. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "topic detection": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called <br>topic detection</br> and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of <br>topic detection</br> has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "<br>topic detection</br> and tracking (TDT) :<br>topic detection</br> detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to <br>topic detection</br> and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of <br>topic detection</br> and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "<br>topic detection</br> and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "<br>topic detection</br> and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "This problem is addressed by a research program called <br>topic detection</br> and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "However, in TDT-2003, a hierarchical structure of <br>topic detection</br> has been proposed and [2] made useful attempts to adopt the new structure.",
                "<br>topic detection</br> and tracking (TDT) :<br>topic detection</br> detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Event threading is strongly related to <br>topic detection</br> and tracking, but also different from it significantly.",
                "Thus, event threading can be considered as a further extension of <br>topic detection</br> and tracking and is more challenging due to at least the following difficulties. 1."
            ],
            "translated_annotated_samples": [
                "Este problema es abordado por un programa de investigación llamado <br>Detección y Seguimiento de Temas</br> (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias.",
                "Sin embargo, en TDT-2003 se propuso una estructura jerárquica de <br>detección de temas</br> y [2] realizó intentos útiles para adoptar la nueva estructura.",
                "Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3].",
                "El enhebrado de eventos está fuertemente relacionado con la <br>detección y seguimiento de temas</br>, pero también es significativamente diferente de ello.",
                "Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado <br>Detección y Seguimiento de Temas</br> (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de <br>detección de temas</br> y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la <br>detección y seguimiento de temas</br>, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. ",
            "candidates": [],
            "error": [
                [
                    "Detección y Seguimiento de Temas",
                    "detección de temas",
                    "detección y seguimiento de temas"
                ]
            ]
        },
        "clusters of topics": {
            "translated_key": "grupos de temas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into <br>clusters of topics</br>.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "For example, the detection task of TDT is to arrange a collection of news stories into <br>clusters of topics</br>."
            ],
            "translated_annotated_samples": [
                "Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en <br>grupos de temas</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en <br>grupos de temas</br>. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "topic cluster": {
            "translated_key": "grupo de temas",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "inter-related event": {
            "translated_key": "eventos interrelacionados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of <br>inter-related event</br>s.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of <br>inter-related event</br>s."
            ],
            "translated_annotated_samples": [
                "Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de <br>eventos interrelacionados</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de <br>eventos interrelacionados</br>. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "seminal event": {
            "translated_key": "evento seminal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the <br>seminal event</br> that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a <br>seminal event</br>.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "For example, when a bomb explodes in a building, that is the <br>seminal event</br> that triggers the topic.",
                "Topic: A set of news stories strongly connected by a <br>seminal event</br>."
            ],
            "translated_annotated_samples": [
                "Por ejemplo, cuando una bomba explota en un edificio, ese es el <br>evento seminal</br> que desencadena el tema.",
                "Un conjunto de noticias fuertemente conectadas por un <br>evento seminal</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el <br>evento seminal</br> que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un <br>evento seminal</br>. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "event model": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the <br>event model</br> of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An <br>event model</br> of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an <br>event model</br> Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An <br>event model</br> of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some <br>event model</br> Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system <br>event model</br> Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True <br>event model</br> System <br>event model</br> A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true <br>event model</br> Å and the system <br>event model</br> Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete <br>event model</br>.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire <br>event model</br>.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "We refer to the resulting interconnected structure of events as the <br>event model</br> of the topic.",
                "An <br>event model</br> of this topic can be represented as in figure 1.",
                "We define an <br>event model</br> Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An <br>event model</br> of TDT topic Osama bin Ladens indictment.",
                "EVALUATION A system can generate some <br>event model</br> Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake)."
            ],
            "translated_annotated_samples": [
                "Nos referimos a la estructura interconectada resultante de eventos como el <br>modelo de eventos</br> del tema.",
                "Un <br>modelo de evento</br> de este tema puede ser representado como en la figura 1.",
                "Definimos un <br>modelo de evento</br> Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias.",
                "El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un <br>modelo de evento</br> del tema de TDT, la acusación de Osama bin Laden.",
                "Un sistema puede generar un <br>modelo de evento</br> Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error)."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el <br>modelo de eventos</br> del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un <br>modelo de evento</br> de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un <br>modelo de evento</br> Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un <br>modelo de evento</br> del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un <br>modelo de evento</br> Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). ",
            "candidates": [],
            "error": [
                [
                    "modelo de eventos",
                    "modelo de evento",
                    "modelo de evento",
                    "modelo de evento",
                    "modelo de evento"
                ]
            ]
        },
        "quick overview": {
            "translated_key": "visión general rápida",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a <br>quick overview</br> of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a <br>quick overview</br> of the topic and also allows him/her navigate through the topic faster."
            ],
            "translated_annotated_samples": [
                "Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una <br>visión general rápida</br> del tema y también les permite navegar por el tema más rápidamente."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una <br>visión general rápida</br> del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "hidden markov model": {
            "translated_key": "modelo oculto de Markov",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "flatcluster": {
            "translated_key": "clústeres planos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as <br>flatcluster</br>s [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "In TDT, researchers have traditionally considered topics as <br>flatcluster</br>s [1]."
            ],
            "translated_annotated_samples": [
                "En TDT, los investigadores han considerado tradicionalmente los temas como <br>clústeres planos</br> [1]."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como <br>clústeres planos</br> [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "atomicity": {
            "translated_key": "atomicidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of <br>atomicity</br> of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Following the assumption of <br>atomicity</br> of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3."
            ],
            "translated_annotated_samples": [
                "Siguiendo la suposición de la <br>atomicidad</br> de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la <br>atomicidad</br> de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "microscopic event": {
            "translated_key": "eventos microscópicos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on <br>microscopic event</br>s rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on <br>microscopic event</br>s rather than larger topics."
            ],
            "translated_annotated_samples": [
                "Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en <br>eventos microscópicos</br> en lugar de temas más amplios."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en <br>eventos microscópicos</br> en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "mapping function": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a <br>mapping function</br> from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event <br>mapping function</br> corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the <br>mapping function</br> ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true <br>mapping function</br> and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "In fact this allows us to define a <br>mapping function</br> from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event <br>mapping function</br> corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "First we modeled only the event clustering part (defining the <br>mapping function</br> ¼) using clustering algorithms described in section 6.1.",
                "We use the true <br>mapping function</br> and by implication the true events Î ."
            ],
            "translated_annotated_samples": [
                "De hecho, esto nos permite definir una <br>función de mapeo</br> de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos.",
                "Donde ¼ es la <br>función de mapeo</br> de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero.",
                "Primero modelamos solo la parte de agrupamiento de eventos (definiendo la <br>función de asignación</br> ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1.",
                "Utilizamos la <br>función de mapeo</br> verdadera y, por implicación, los eventos verdaderos Î."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una <br>función de mapeo</br> de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la <br>función de mapeo</br> de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la <br>función de asignación</br> ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la <br>función de mapeo</br> verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    "función de mapeo",
                    "función de mapeo",
                    "función de asignación",
                    "función de mapeo"
                ]
            ]
        },
        "directed edge": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of <br>directed edge</br>s ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only un<br>directed edge</br>s.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of <br>directed edge</br>s ´ µ which denote dependencies between events.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only un<br>directed edge</br>s."
            ],
            "translated_annotated_samples": [
                "De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de <br>aristas dirigidas</br> ´ µ que denotan las dependencias entre eventos.",
                "Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los <br>bordes no dirigidos</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de <br>aristas dirigidas</br> ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los <br>bordes no dirigidos</br>. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    "aristas dirigidas",
                    "bordes no dirigidos"
                ]
            ]
        },
        "time ordering": {
            "translated_key": "orden temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call <br>time ordering</br>.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "An arrow in such scenario captures what we call <br>time ordering</br>."
            ],
            "translated_annotated_samples": [
                "Una flecha en dicho escenario captura lo que llamamos <br>orden temporal</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos <br>orden temporal</br>. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "agglomerative clustering": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an <br>agglomerative clustering</br> algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 <br>agglomerative clustering</br> with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of <br>agglomerative clustering</br> algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of <br>agglomerative clustering</br> algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the <br>agglomerative clustering</br> algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "In this subsection, we present an <br>agglomerative clustering</br> algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 <br>agglomerative clustering</br> with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of <br>agglomerative clustering</br> algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of <br>agglomerative clustering</br> algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the <br>agglomerative clustering</br> algorithm."
            ],
            "translated_annotated_samples": [
                "En esta subsección, presentamos un algoritmo de <br>agrupamiento aglomerativo</br> que combina todas estas características.",
                "En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 <br>Agrupamiento aglomerativo</br> con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia.",
                "Utilizamos el modelo de <br>agrupamiento aglomerativo</br> con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de <br>agrupamiento aglomerativo</br> (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento.",
                "Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de <br>agrupamiento aglomerativo</br> (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola).",
                "Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el <br>algoritmo de agrupamiento aglomerativo</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de <br>agrupamiento aglomerativo</br> que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 <br>Agrupamiento aglomerativo</br> con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de <br>agrupamiento aglomerativo</br> con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de <br>agrupamiento aglomerativo</br> (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de <br>agrupamiento aglomerativo</br> (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el <br>algoritmo de agrupamiento aglomerativo</br>. ",
            "candidates": [],
            "error": [
                [
                    "agrupamiento aglomerativo",
                    "Agrupamiento aglomerativo",
                    "agrupamiento aglomerativo",
                    "agrupamiento aglomerativo",
                    "agrupamiento aglomerativo",
                    "algoritmo de agrupamiento aglomerativo"
                ]
            ]
        },
        "cosine similarity": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the <br>cosine similarity</br> of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average <br>cosine similarity</br> between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average <br>cosine similarity</br> between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only <br>cosine similarity</br> as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, <br>cosine similarity</br>, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides <br>cosine similarity</br> on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on <br>cosine similarity</br>.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Ó×´×½ ×¾µ is the <br>cosine similarity</br> of the term vectors.",
                "We will also use average <br>cosine similarity</br> between two events as a feature and it is defined as follows.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average <br>cosine similarity</br> between event Ù and event Ú is greater than a threshold Ì.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only <br>cosine similarity</br> as our clustering baseline.",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, <br>cosine similarity</br>, average link in clustering."
            ],
            "translated_annotated_samples": [
                "La <br>similitud del coseno</br> de los vectores de términos es Ó×´×½ ×¾µ.",
                "También utilizaremos la <br>similitud coseno</br> promedio entre dos eventos como una característica y se define de la siguiente manera.",
                "Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la <br>similitud coseno</br> promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì.",
                "Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la <br>similitud coseno</br> como nuestro punto de referencia para el agrupamiento.",
                "Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, <br>similitud del coseno</br>, enlace promedio en la agrupación."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La <br>similitud del coseno</br> de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la <br>similitud coseno</br> promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la <br>similitud coseno</br> promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la <br>similitud coseno</br> como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, <br>similitud del coseno</br>, enlace promedio en la agrupación. ",
            "candidates": [],
            "error": [
                [
                    "similitud del coseno",
                    "similitud coseno",
                    "similitud coseno",
                    "similitud coseno",
                    "similitud del coseno"
                ]
            ]
        },
        "term vector": {
            "translated_key": "vectores de términos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the <br>term vector</br>s.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Ó×´×½ ×¾µ is the cosine similarity of the <br>term vector</br>s."
            ],
            "translated_annotated_samples": [
                "La similitud del coseno de los <br>vectores de términos</br> es Ó×´×½ ×¾µ."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los <br>vectores de términos</br> es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "simple thresholding": {
            "translated_key": "Umbral Simple",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 <br>simple thresholding</br> This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+<br>simple thresholding</br> 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 <br>simple thresholding</br> This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+<br>simple thresholding</br> 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903."
            ],
            "translated_annotated_samples": [
                "Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì.",
                "T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+<br>Umbral Simple</br> 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+<br>Umbral Simple</br> 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+<br>Umbral Simple</br> 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+<br>Umbral Simple</br> 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "maximum spanning tree": {
            "translated_key": "árbol de expansión máxima",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 <br>maximum spanning tree</br> model In this model, we first build a <br>maximum spanning tree</br> (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 <br>maximum spanning tree</br> model In this model, we first build a <br>maximum spanning tree</br> (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼."
            ],
            "translated_annotated_samples": [
                "Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un <br>árbol de expansión máxima</br> (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el <br>árbol de expansión máxima</br> de ¼."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un <br>árbol de expansión máxima</br> (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el <br>árbol de expansión máxima</br> de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "correct granularity": {
            "translated_key": "granularidad correcta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get <br>correct granularity</br>.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get <br>correct granularity</br>."
            ],
            "translated_annotated_samples": [
                "También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la <br>granularidad correcta</br>."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la <br>granularidad correcta</br>. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "dependency precision": {
            "translated_key": "Precisión de Dependencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 <br>dependency precision</br>: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ <br>dependency precision</br>(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of <br>dependency precision</br> (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 <br>dependency precision</br>: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ <br>dependency precision</br>(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "We evaluate our performance 451 using the average values of <br>dependency precision</br> (DP), Dependency Recall (DR) and Dependency F-measure (DF)."
            ],
            "translated_annotated_samples": [
                "En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta.",
                "Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼.",
                "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de <br>Precisión de Dependencia</br> (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF)."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de <br>Precisión de Dependencia</br> (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "dependency recall": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 <br>dependency recall</br>: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ <br>dependency recall</br>(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), <br>dependency recall</br> (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 <br>dependency recall</br>: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ <br>dependency recall</br>(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), <br>dependency recall</br> (DR) and Dependency F-measure (DF)."
            ],
            "translated_annotated_samples": [
                "En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta.",
                "<br>Recuerdo de Dependencia</br> (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å.",
                "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), <br>Recuperación de Dependencia</br> (DR) y Medida F de Dependencia (DF)."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. <br>Recuerdo de Dependencia</br> (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), <br>Recuperación de Dependencia</br> (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    "Recuerdo de Dependencia",
                    "Recuperación de Dependencia"
                ]
            ]
        },
        "dependency f-measure": {
            "translated_key": "Medida F de Dependencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and <br>dependency f-measure</br> (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and <br>dependency f-measure</br> (DF)."
            ],
            "translated_annotated_samples": [
                "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y <br>Medida F de Dependencia</br> (DF)."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y <br>Medida F de Dependencia</br> (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "temporallocalization": {
            "translated_key": "localización temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of <br>temporallocalization</br> of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "We developed a timedecay based clustering approach that takes advantage of <br>temporallocalization</br> of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity."
            ],
            "translated_annotated_samples": [
                "Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la <br>localización temporal</br> de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la <br>localización temporal</br> de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "timedecay": {
            "translated_key": "decaimiento temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a <br>timedecay</br> based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "We developed a <br>timedecay</br> based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity."
            ],
            "translated_annotated_samples": [
                "Desarrollamos un enfoque de agrupamiento basado en la <br>decaimiento temporal</br> que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la <br>decaimiento temporal</br> que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence \"Inf.\" is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "event": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>event</br> Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our <br>event</br> models.",
                "We call the process of recognizing events and their dependencies <br>event</br> threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for <br>event</br> recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld <br>event</br> where an <br>event</br> is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal <br>event</br> that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the <br>event</br> of rescue attempts is influenced by the <br>event</br> of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them <br>event</br> threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the <br>event</br> model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such <br>event</br> based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling <br>event</br> structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying <br>event</br> relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of <br>event</br> and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single <br>event</br>.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic <br>event</br> story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "<br>event</br>: An <br>event</br> is something that happens at some specific time and place [10].",
                "In our work, we represent an <br>event</br> by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal <br>event</br>.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an <br>event</br> and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "<br>event</br> threading: <br>event</br> threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between <br>event</br> threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally <br>event</br> threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each <br>event</br> is an element in the power set of S, the second constraint ensures that each story can belong to at most one <br>event</br>.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of <br>event</br> B is related to and is a consequence of the occurrence of <br>event</br> A.",
                "By temporal ordering, we mean that <br>event</br> B happened after <br>event</br> A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (<br>event</br> A) and subsequent investigations (<br>event</br> B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(<br>event</br> A) and Pope meets Castro(<br>event</br> B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but <br>event</br> B is not necessarily a consequence of the occurrence of <br>event</br> A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of <br>event</br> threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An <br>event</br> model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an <br>event</br> in the topic of Osamas indictment.",
                "The occurrence of <br>event</br> 2, namely Trial and Indictment of Osama is dependent on the <br>event</br> of evidence gathered by CIA, i.e., event 1.",
                "Similarly, <br>event</br> 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an <br>event</br> A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an <br>event</br> model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An <br>event</br> model of TDT topic Osama bin Ladens indictment.",
                "<br>event</br> threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, <br>event</br> threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the <br>event</br> membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an <br>event</br>, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single <br>event</br> C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique <br>event</br>.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an <br>event</br> especially when the number of stories in that <br>event</br> is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each <br>event</br> could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from <br>event</br> A to <br>event</br> B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/<br>event</br> 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/<br>event</br> 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some <br>event</br> model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system <br>event</br> model Å¼ with the true model Å requires comparing the entire <br>event</br> models including their dependency structure.",
                "And different <br>event</br> granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their <br>event</br>-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same <br>event</br> given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the <br>event</br> of × to the <br>event</br> of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True <br>event</br> model System <br>event</br> model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true <br>event</br> model Å and the system <br>event</br> model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-<br>event</br> mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-<br>event</br> given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of <br>event</br> modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same <br>event</br> tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same <br>event</br> tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar <br>event</br> pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the <br>event</br>-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the <br>event</br>-time-ordering function.",
                "In other words, the dependency edge is directed from <br>event</br> Ù to <br>event</br> Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between <br>event</br> Ù and <br>event</br> Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each <br>event</br> can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each <br>event</br> Ú , the nearest parent model considers only the <br>event</br> preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each <br>event</br> can have at most one parent.",
                "An <br>event</br> Ú is assigned a parent Ù if and only if Ù is the most similar earlier <br>event</br> to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the <br>event</br> clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete <br>event</br> model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the <br>event</br> they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same <br>event</br> tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each <br>event</br>, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire <br>event</br> model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same <br>event</br> and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex <br>event</br> structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:<br>event</br> based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on <br>event</br> evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "<br>event</br> Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our <br>event</br> models.",
                "We call the process of recognizing events and their dependencies <br>event</br> threading.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for <br>event</br> recognition and time-ordering for capturing dependencies.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld <br>event</br> where an <br>event</br> is defined as something that happens at a specific time and location [3]."
            ],
            "translated_annotated_samples": [
                "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente.",
                "En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros <br>modelos de eventos</br>.",
                "Llamamos al proceso de reconocer eventos y sus dependencias como <br>enhebrado de eventos</br>.",
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el <br>reconocimiento de eventos</br> y el orden temporal para capturar dependencias.",
                "Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún <br>evento</br> seminal del mundo real, donde un <br>evento</br> se define como algo que sucede en un momento y lugar específicos [3]."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros <br>modelos de eventos</br>. Llamamos al proceso de reconocer eventos y sus dependencias como <br>enhebrado de eventos</br>. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el <br>reconocimiento de eventos</br> y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún <br>evento</br> seminal del mundo real, donde un <br>evento</br> se define como algo que sucede en un momento y lugar específicos [3]. ",
            "candidates": [],
            "error": [
                [
                    "modelos de eventos",
                    "enhebrado de eventos",
                    "reconocimiento de eventos",
                    "evento",
                    "evento"
                ]
            ]
        },
        "thread": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event <br>thread</br>ing.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event <br>thread</br>ing, an analogy to email <br>thread</br>ing that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on <br>thread</br>ing events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate <br>thread</br>ing of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of <br>thread</br>ing events together is related to <br>thread</br>ing of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email <br>thread</br>ing captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event <br>thread</br>ing: Event <br>thread</br>ing detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event <br>thread</br>ing and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event <br>thread</br>ing models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event <br>thread</br>ing more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event <br>thread</br>ing is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event <br>thread</br>ing can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "We call the process of recognizing events and their dependencies event <br>thread</br>ing.",
                "We call the process of recognizing events and identifying dependencies among them event <br>thread</br>ing, an analogy to email <br>thread</br>ing that shows connections between related email messages.",
                "Although this paper focuses on <br>thread</br>ing events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "In section 3, we define the problem and use an example to illustrate <br>thread</br>ing of events within a news topic.",
                "RELATED WORK The process of <br>thread</br>ing events together is related to <br>thread</br>ing of electronic mail only by name for the most part."
            ],
            "translated_annotated_samples": [
                "Llamamos al proceso de reconocer eventos y sus dependencias como <br>enhebrado</br> de eventos.",
                "Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos <br>enhebrado</br> de eventos, una analogía al <br>enhebrado</br> de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados.",
                "Aunque este documento se centra en <br>enhebrar</br> eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados.",
                "En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el <br>enhebrado</br> de eventos dentro de un tema de noticias.",
                "TRABAJO RELACIONADO El proceso de <br>enlazar</br> eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como <br>enhebrado</br> de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos <br>enhebrado</br> de eventos, una analogía al <br>enhebrado</br> de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en <br>enhebrar</br> eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el <br>enhebrado</br> de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de <br>enlazar</br> eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. ",
            "candidates": [],
            "error": [
                [
                    "enhebrado",
                    "enhebrado",
                    "enhebrado",
                    "enhebrar",
                    "enhebrado",
                    "enlazar"
                ]
            ]
        },
        "cluster": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ <br>cluster</br> pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) <br>cluster</br> pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) <br>cluster</br> precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ <br>cluster</br> Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ <br>cluster</br> Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the <br>cluster</br> and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each <br>cluster</br> contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the <br>cluster</br> F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the <br>cluster</br> quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model <br>cluster</br> T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [
                "Specifically, we compare two kinds of story pairs: ¯ <br>cluster</br> pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "In our evaluation, a correct pair with wrong 448 (B->D) <br>cluster</br> pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) <br>cluster</br> precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ <br>cluster</br> Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ <br>cluster</br> Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the <br>cluster</br> and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6."
            ],
            "translated_annotated_samples": [
                "Específicamente, comparamos dos tipos de pares de historias: pares de <br>clúster</br> (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å.",
                "En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de <br>clúster</br> (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de <br>clúster</br>: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta.",
                "Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema.",
                "Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero.",
                "También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de <br>agrupación</br> y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6."
            ],
            "translated_text": "Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. \"Doc.\" Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de <br>clúster</br> (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de <br>clúster</br> (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de <br>clúster</br>: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de <br>agrupación</br> y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. ",
            "candidates": [],
            "error": [
                [
                    "clúster",
                    "clúster",
                    "clúster",
                    "agrupación"
                ]
            ]
        }
    }
}