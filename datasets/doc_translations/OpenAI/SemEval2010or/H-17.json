{
    "id": "H-17",
    "original_text": "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept. Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information. In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results. While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index. Given the fierce competition in the online search market, this phenomenon is clearly undesirable. In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit. Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time. We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages. Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1. INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24]. According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages. Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web. Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index. An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword. In most cases, a query that the user issues may have thousands or even millions of matching documents. In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents. The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query. A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results. That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine. At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large. Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24]. One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index. While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20]. That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20]. Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible. In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit. That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index. Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time. These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines. Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results. IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries. When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2. CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly. Inverted indexes. Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents. For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti. Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc. The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information. For example, Google is estimated to answer more than 250 million user queries per day. In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a). The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines. We also suppose that one copy of IF can handle the query load of 1000 queries/sec. Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load. Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index. In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results. Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier. In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF . The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture. Example 2 Assume the same parameter settings as in Example 1. That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec. Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine. Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF . Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier. For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load. Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ). Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index. However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results. Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture? Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index. The algorithm in Figure 2 formalizes this idea. In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF . If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2). Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5). Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time. Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone. Question 1 How can we compute the correctness indicator function C? A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them. This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF . Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ? Question 2 How should we prune IF to IP to realize the maximum cost saving? The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1. If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF . What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries? In the next few sections, we try to address these questions. 3. OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher. When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF . Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving? To find the answer, we start with a simple example. Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines. But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries). Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries. Which one of the IP 1, IP 2 is preferable for the 1st -tier index? To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier. At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec. Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine. Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy). Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy). Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load. We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used. Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone. We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ). We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ). In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows. In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows. In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load. Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size. Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints. This theorem shows that the optimal point is when the slope of the f(s) curve is 1. For example, in Figure 3, the optimal size is when s = 0.16. Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy. For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s). Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s). Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy. In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4. PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP . In designing the pruning policies, we note the following two localities in the users search behavior: 1. Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads. This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2. Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16]. Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them). Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results. As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee. Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms. The goal of the search engine is to return the documents that are most relevant to query q. This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query. Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest. Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics). In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query. It is straightforward to extend our results to OR-semantics as well. The exact ranking function that search engines employ is a closely guarded secret. What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance. This particular factor of relevance captures how relevant the query is to every document. At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values. One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric. Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality. This is a factor that measures the overall quality of a document D independent of the particular query issued by the user. Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15]. Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function. The exact combination of these parts may be done in a variety of ways. In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores. More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part. In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine. Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning. Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning. Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms. In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load. Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned. In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF . Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP . It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm. We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries. This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof). Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution. A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9]. In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP . We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti). For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |. Figure 6: Approximation algorithm for the optimal keyword pruning. Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1. The cost of including I(ti) in the pindex is its size |I(ti)|. Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |. Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query. Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway. We depict the conceptual diagram of the document pruning policy in Figure 4. In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries. Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP . In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines. The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g. PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp). The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index. Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr. Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp. We refer to this pruning policy as global PR-based pruning (GPR). Variations of this pruning policy are possible. For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti). This policy is shown in Figure 8. We refer to this pruning policy as local PR-based pruning (LPR). Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way. Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP . Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Now consider another document Dj that was pruned from IP because pr(Dj) < τp. Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF . In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores. Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score. That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP . Otherwise, we prune it from IP . Figure 9 formally describes this algorithm. The threshold values, τpi and τti, may be selected in a number of different ways. For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti). This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index. We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)). There are three possible scenarios on how a document D appears in the pruned index IP . 1. D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2. D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score. However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2. Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3. D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values. However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2. Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values. This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score. In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k. The following theorem formally proves the correctness of the algorithm. In [11] Fagin et al., provides a similar proof in the context of multimedia middleware. Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6. For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP . In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk). That is, Dis score can never be larger than that of Dk. Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP . Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di). Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di). Therefore, r(Di) cannot be larger than r(Dk). 5. EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype. For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004. The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner. Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB. For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003. After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries. Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms. Some experiments require us to use a particular ranking function. For these, we use the ranking function similar to the one used in [20]. More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q. This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2. More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set. Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP . According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords. We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11. The horizontal axis denotes the size s of the p-index as a fraction of the size of IF . The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer. The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index. For example, approximately 73% of the queries can be answered using 30% of the original index. Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3. For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set. The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries. For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4. Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct. We have performed the experiment for varying index sizes s and the result is shown in Figure 12. Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries. This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size. From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy. We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12. Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%. For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size. Later in Section 5.3, we discuss the combination of the two policies. In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3. To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies. For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index. Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index. Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning. The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies. On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size. The fraction of queries that LPR can answer remains below that of EKS until about s = 37%. For any index size larger than 37%, LPR performs the best. In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index. However, in a practical scenario, it may be acceptable to have some of the results out of order. Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index. The result of the experiment is shown on Figure 14. The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index. Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes. One interesting question however is how do these policies perform in combination? What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ? To answer this question, we performed the following experiment. We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF . After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P . We then calculated the fraction of guaranteed queries in IP . We repeated the experiment for different values of sh and sv. The result is shown on Figure 15. The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings. For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries. By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well. For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries. In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5. For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6. RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems. Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33]. The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used. The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking. However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results. Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results. Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31]. This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost. The exact ranking functions employed by current search engines are closely guarded secrets. In general, however, the rankings are based on query-dependent relevance and queryindependent document quality. Query-dependent relevance can be calculated in a variety of ways (see [3, 30]). Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26]. Since our work does not assume a particular form of ranking function, it is complementary to this body of work. There has been a great body of work on top-k result calculation. The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8]. Our proof for the correctness indicator function was primarily inspired by [12]. 7. CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads. While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality. In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order. We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination. Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results. In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size. When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%. It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8. REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat. Vector-space ranking with effective early termination. In SIGIR, 2001. [2] V. N. Anh and A. Moffat. Pruning strategies for mixed-mode querying. In CIKM, 2006. [3] R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian. Evaluating top-k queries over web-accessible databases. In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke. A document-centric approach to static index pruning in text retrieval systems. In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu. Evaluating the performance of distributed architectures for information retrieval using a variety of workloads. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer. Static index pruning for information retrieval systems. In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano. Optimizing queries over multimedia repositories. In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest. Introduction to Algorithms, 2nd Edition. MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin. Combining fuzzy information: an overview. In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor. Optimal aggregation algorithms for middleware. In PODS, 2001. [13] A. Gulli and A. Signorini. The indexable web is more than 11.5 billion pages. In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling. Towards efficient multi-feature queries in heterogeneous environments. In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam with trustrank. In VLDB, 2004. [16] B. J. Jansen and A. Spink. An analysis of web documents retrieved and viewed. In International Conf. on Internet Computing, 2003. [17] J. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran. Predictive caching and prefetching of query results in search engines. In WWW, 2003. [19] R. Lempel and S. Moran. Optimizing result prefetching in web search engines with segmented indices. ACM Trans. Inter. Tech., 4(1), 2004. [20] X. Long and T. Suel. Optimized query execution in large search engines with global page ordering. In VLDB, 2003. [21] X. Long and T. Suel. Three-level caching for efficient query processing in large web search engines. In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina. Building a distributed full-text index for the web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. Whats new on the web? The evolution of the web from a search engine perspective. In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. Detecting spam web pages through content analysis. In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered document retrieval with frequency-sorted indexes. Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos. The intelligent surfer: Probabilistic combination of link and content information in pagerank. In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones. Relevance weighting of search terms. Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill. Introduction to modern information retrieval. McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto. Rank-preserving two-level caching for scalable search engines. In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel. Top-k query evaluation with probabilistic guarantees. In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina. Performance of inverted indices in shared-nothing distributed text document information retrieval systems. In Parallel and Distributed Information Systems, 1993.",
    "original_translation": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993.",
    "original_sentences": [
        "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
        "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
        "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
        "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
        "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
        "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
        "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
        "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
        "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
        "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
        "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
        "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
        "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
        "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
        "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
        "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
        "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
        "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
        "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
        "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
        "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
        "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
        "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
        "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
        "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
        "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
        "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
        "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
        "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
        "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
        "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
        "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
        "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
        "Inverted indexes.",
        "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
        "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
        "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
        "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
        "For example, Google is estimated to answer more than 250 million user queries per day.",
        "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
        "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
        "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
        "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
        "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
        "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
        "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
        "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
        "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
        "Example 2 Assume the same parameter settings as in Example 1.",
        "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
        "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
        "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
        "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
        "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
        "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
        "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
        "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
        "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
        "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
        "The algorithm in Figure 2 formalizes this idea.",
        "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
        "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
        "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
        "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
        "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
        "Question 1 How can we compute the correctness indicator function C?",
        "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
        "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
        "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
        "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
        "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
        "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
        "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
        "In the next few sections, we try to address these questions. 3.",
        "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
        "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
        "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
        "To find the answer, we start with a simple example.",
        "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
        "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
        "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
        "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
        "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
        "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
        "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
        "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
        "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
        "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
        "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
        "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
        "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
        "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
        "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
        "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
        "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
        "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
        "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
        "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
        "For example, in Figure 3, the optimal size is when s = 0.16.",
        "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
        "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
        "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
        "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
        "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
        "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
        "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
        "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
        "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
        "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
        "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
        "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
        "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
        "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
        "The goal of the search engine is to return the documents that are most relevant to query q.",
        "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
        "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
        "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
        "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
        "It is straightforward to extend our results to OR-semantics as well.",
        "The exact ranking function that search engines employ is a closely guarded secret.",
        "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
        "This particular factor of relevance captures how relevant the query is to every document.",
        "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
        "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
        "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
        "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
        "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
        "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
        "The exact combination of these parts may be done in a variety of ways.",
        "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
        "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
        "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
        "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
        "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
        "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
        "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
        "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
        "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
        "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
        "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
        "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
        "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
        "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
        "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
        "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
        "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
        "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
        "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
        "Figure 6: Approximation algorithm for the optimal keyword pruning.",
        "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
        "The cost of including I(ti) in the pindex is its size |I(ti)|.",
        "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
        "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
        "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
        "We depict the conceptual diagram of the document pruning policy in Figure 4.",
        "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
        "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
        "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
        "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
        "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
        "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
        "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
        "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
        "We refer to this pruning policy as global PR-based pruning (GPR).",
        "Variations of this pruning policy are possible.",
        "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
        "This policy is shown in Figure 8.",
        "We refer to this pruning policy as local PR-based pruning (LPR).",
        "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
        "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
        "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
        "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
        "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
        "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
        "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
        "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
        "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
        "Otherwise, we prune it from IP .",
        "Figure 9 formally describes this algorithm.",
        "The threshold values, τpi and τti, may be selected in a number of different ways.",
        "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
        "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
        "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
        "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
        "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
        "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
        "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
        "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
        "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
        "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
        "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
        "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
        "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
        "The following theorem formally proves the correctness of the algorithm.",
        "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
        "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
        "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
        "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
        "That is, Dis score can never be larger than that of Dk.",
        "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
        "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
        "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
        "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
        "Therefore, r(Di) cannot be larger than r(Dk). 5.",
        "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
        "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
        "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
        "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
        "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
        "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
        "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
        "Some experiments require us to use a particular ranking function.",
        "For these, we use the ranking function similar to the one used in [20].",
        "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
        "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
        "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
        "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
        "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
        "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
        "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
        "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
        "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
        "For example, approximately 73% of the queries can be answered using 30% of the original index.",
        "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
        "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
        "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
        "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
        "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
        "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
        "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
        "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
        "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
        "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
        "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
        "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
        "Later in Section 5.3, we discuss the combination of the two policies.",
        "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
        "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
        "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
        "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
        "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
        "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
        "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
        "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
        "For any index size larger than 37%, LPR performs the best.",
        "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
        "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
        "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
        "The result of the experiment is shown on Figure 14.",
        "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
        "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
        "One interesting question however is how do these policies perform in combination?",
        "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
        "To answer this question, we performed the following experiment.",
        "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
        "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
        "We then calculated the fraction of guaranteed queries in IP .",
        "We repeated the experiment for different values of sh and sv.",
        "The result is shown on Figure 15.",
        "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
        "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
        "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
        "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
        "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
        "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
        "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
        "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
        "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
        "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
        "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
        "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
        "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
        "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
        "The exact ranking functions employed by current search engines are closely guarded secrets.",
        "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
        "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
        "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
        "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
        "There has been a great body of work on top-k result calculation.",
        "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
        "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
        "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
        "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
        "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
        "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
        "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
        "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
        "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
        "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
        "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
        "Vector-space ranking with effective early termination.",
        "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
        "Pruning strategies for mixed-mode querying.",
        "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
        "A. Ribeiro-Neto.",
        "Modern Information Retrieval.",
        "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
        "Evaluating top-k queries over web-accessible databases.",
        "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
        "A document-centric approach to static index pruning in text retrieval systems.",
        "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
        "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
        "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
        "Static index pruning for information retrieval systems.",
        "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
        "Optimizing queries over multimedia repositories.",
        "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
        "Introduction to Algorithms, 2nd Edition.",
        "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
        "Combining fuzzy information: an overview.",
        "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
        "Optimal aggregation algorithms for middleware.",
        "In PODS, 2001. [13] A. Gulli and A. Signorini.",
        "The indexable web is more than 11.5 billion pages.",
        "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
        "Towards efficient multi-feature queries in heterogeneous environments.",
        "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
        "Combating web spam with trustrank.",
        "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
        "An analysis of web documents retrieved and viewed.",
        "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
        "Authoritative sources in a hyperlinked environment.",
        "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
        "Predictive caching and prefetching of query results in search engines.",
        "In WWW, 2003. [19] R. Lempel and S. Moran.",
        "Optimizing result prefetching in web search engines with segmented indices.",
        "ACM Trans.",
        "Inter.",
        "Tech., 4(1), 2004. [20] X.",
        "Long and T. Suel.",
        "Optimized query execution in large search engines with global page ordering.",
        "In VLDB, 2003. [21] X.",
        "Long and T. Suel.",
        "Three-level caching for efficient query processing in large web search engines.",
        "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
        "Building a distributed full-text index for the web.",
        "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
        "Whats new on the web?",
        "The evolution of the web from a search engine perspective.",
        "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
        "Detecting spam web pages through content analysis.",
        "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
        "The pagerank citation ranking: Bringing order to the web.",
        "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
        "Filtered document retrieval with frequency-sorted indexes.",
        "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
        "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
        "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
        "Relevance weighting of search terms.",
        "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
        "Introduction to modern information retrieval.",
        "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
        "Rank-preserving two-level caching for scalable search engines.",
        "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
        "Top-k query evaluation with probabilistic guarantees.",
        "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
        "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
        "In Parallel and Distributed Information Systems, 1993."
    ],
    "translated_text_sentences": [
        "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA.",
        "El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información.",
        "Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados.",
        "Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado.",
        "Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable.",
        "En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios.",
        "Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado.",
        "También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web.",
        "Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1.",
        "INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24].",
        "Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas.",
        "Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet.",
        "Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido.",
        "Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular.",
        "En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes.",
        "Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes.",
        "El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta.",
        "Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados.",
        "Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda.",
        "Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande.",
        "Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24].",
        "Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado.",
        "Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado.",
        "Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20].",
        "Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible.",
        "En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios.",
        "Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado.",
        "Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo.",
        "Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día.",
        "Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad.",
        "SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas.",
        "Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2.",
        "ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente.",
        "Índices invertidos.",
        "Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos.",
        "Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti.",
        "Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc.",
        "El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante.",
        "Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día.",
        "Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a).",
        "El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes.",
        "También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo.",
        "Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga.",
        "En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo.",
        "En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales.",
        "Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel.",
        "En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI.",
        "El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles.",
        "Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1.",
        "Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo.",
        "También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina.",
        "Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF.",
        "Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel.",
        "Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga.",
        "En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF).",
        "Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p.",
        "Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda.",
        "Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles?",
        "Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo.",
        "El algoritmo en la Figura 2 formaliza esta idea.",
        "En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF.",
        "Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2).",
        "De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5).",
        "Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE.",
        "Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP.",
        "Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C?",
        "Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos.",
        "Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF.",
        "¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF?",
        "Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos?",
        "La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1.",
        "Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF.",
        "¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas?",
        "En las próximas secciones, intentaremos abordar estas preguntas. 3.",
        "TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor.",
        "Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF.",
        "Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos?",
        "Para encontrar la respuesta, comenzamos con un ejemplo sencillo.",
        "Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas.",
        "Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas).",
        "También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas.",
        "¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel?",
        "Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel.",
        "En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg.",
        "Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina.",
        "Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia).",
        "Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia).",
        "En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga.",
        "Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2.",
        "Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel.",
        "Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF).",
        "Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP).",
        "En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece.",
        "En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera.",
        "Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas.",
        "Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice.",
        "Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio.",
        "Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1.",
        "Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16.",
        "Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda.",
        "Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s).",
        "De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s).",
        "Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda.",
        "En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4.",
        "En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP.",
        "Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1.",
        "Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta.",
        "Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2.",
        "Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16].",
        "Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente).",
        "Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k.",
        "Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección.",
        "Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice.",
        "El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q.",
        "Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta.",
        "Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta.",
        "La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND).",
        "Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta.",
        "Es sencillo extender nuestros resultados también a la semántica OR.",
        "La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado.",
        "Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta.",
        "Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento.",
        "A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales.",
        "Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno.",
        "Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta.",
        "Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario.",
        "Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15].",
        "Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación.",
        "La combinación exacta de estas partes puede hacerse de varias maneras.",
        "En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta.",
        "Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta.",
        "En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda.",
        "Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos.",
        "Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave.",
        "Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
        "Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes.",
        "En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas.",
        "Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q.",
        "En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF.",
        "La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas.",
        "Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior.",
        "Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas.",
        "Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa).",
        "Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada.",
        "Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9].",
        "En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP.",
        "Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti).",
        "Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|.",
        "Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave.",
        "Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1.",
        "El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|.",
        "Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |.",
        "Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta.",
        "Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista.",
        "Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4.",
        "En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios.",
        "Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP.",
        "En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes.",
        "La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo,",
        "PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp).",
        "La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo.",
        "La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr.",
        "Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp.",
        "Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR).",
        "Variaciones de esta política de poda son posibles.",
        "Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti).",
        "Esta política se muestra en la Figura 8.",
        "Nos referimos a esta política de poda como poda basada en PR local (LPR).",
        "Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera.",
        "Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP.",
        "Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
        "Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp.",
        "Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
        "Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF.",
        "En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr.",
        "Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti).",
        "Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP.",
        "De lo contrario, lo eliminamos de la IP.",
        "La Figura 9 describe formalmente este algoritmo.",
        "Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes.",
        "Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti).",
        "Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado.",
        "Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)).",
        "Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1.",
        "D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)).",
        "D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto.",
        "Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2.",
        "Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3.",
        "D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2).",
        "Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2.",
        "Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes.",
        "Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta.",
        "En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k.",
        "El siguiente teorema prueba formalmente la corrección del algoritmo.",
        "En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia.",
        "Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6.",
        "Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP.",
        "En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk).",
        "Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk.",
        "Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP.",
        "Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
        "Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di).",
        "Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di).",
        "Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5.",
        "EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda.",
        "Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004.",
        "El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar.",
        "En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB.",
        "Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003.",
        "Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas.",
        "Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos.",
        "Algunos experimentos requieren que utilicemos una función de clasificación particular.",
        "Para esto, utilizamos la función de clasificación similar a la utilizada en [20].",
        "Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q.",
        "Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2.",
        "Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos.",
        "Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP.",
        "Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta.",
        "Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11.",
        "El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF.",
        "El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder.",
        "Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original.",
        "Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original.",
        "Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3.",
        "Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas.",
        "La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas.",
        "Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4.",
        "Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas.",
        "Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12.",
        "Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas.",
        "Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice.",
        "Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda.",
        "Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12.",
        "Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%.",
        "Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado.",
        "Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas.",
        "En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3.",
        "Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR).",
        "Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo.",
        "Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo.",
        "Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento.",
        "El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos.",
        "Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice.",
        "La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%.",
        "Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento.",
        "En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo.",
        "Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden.",
        "Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo.",
        "El resultado del experimento se muestra en la Figura 14.",
        "El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo.",
        "En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos.",
        "Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación?",
        "¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF?",
        "Para responder a esta pregunta, realizamos el siguiente experimento.",
        "Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF.",
        "Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P.",
        "Luego calculamos la fracción de consultas garantizadas en IP.",
        "Repetimos el experimento para diferentes valores de sh y sv.",
        "El resultado se muestra en la Figura 15.",
        "El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas.",
        "Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas.",
        "Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien.",
        "Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas.",
        "En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5.",
        "Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6.",
        "El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información.",
        "Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33].",
        "Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado.",
        "Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final.",
        "Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados.",
        "Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados.",
        "Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31].",
        "Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas.",
        "Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados.",
        "En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta.",
        "La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]).",
        "Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26].",
        "Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos.",
        "Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados.",
        "La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8].",
        "Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7.",
        "CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes.",
        "Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados.",
        "En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto.",
        "Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación.",
        "Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados.",
        "En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño.",
        "Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%.",
        "Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web.",
        "REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat.",
        "Clasificación en el espacio vectorial con terminación temprana efectiva.",
        "En SIGIR, 2001. [2] V. N. Anh y A. Moffat.",
        "Estrategias de poda para consultas de modo mixto.",
        "En CIKM, 2006. [3] R. A. Baeza-Yates y B.",
        "A. Ribeiro-Neto.",
        "Recuperación de información moderna.",
        "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian.",
        "Evaluación de consultas top-k sobre bases de datos accesibles a través de la web.",
        "En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke.",
        "Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto.",
        "En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu.",
        "Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo.",
        "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer.",
        "Poda de índices estáticos para sistemas de recuperación de información.",
        "En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano.",
        "Optimizando consultas en repositorios multimedia.",
        "En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest.",
        "Introducción a los Algoritmos, 2da Edición.",
        "MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin.",
        "Combinando información difusa: una visión general.",
        "En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor.",
        "Algoritmos de agregación óptimos para middleware.",
        "En PODS, 2001. [13] A. Gulli y A. Signorini.",
        "La web indexable tiene más de 11.5 mil millones de páginas.",
        "En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling.",
        "Hacia consultas eficientes de múltiples características en entornos heterogéneos.",
        "En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen.",
        "Combatiendo el spam web con trustrank.",
        "En VLDB, 2004. [16] B. J. Jansen y A. Spink.",
        "Un análisis de documentos web recuperados y visualizados.",
        "En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg.",
        "Fuentes autorizadas en un entorno hiperenlazado.",
        "Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran.",
        "Caché predictivo y precarga de resultados de consultas en motores de búsqueda.",
        "En WWW, 2003. [19] R. Lempel y S. Moran.",
        "Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados.",
        "ACM Trans.",
        "\"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish?",
        "Tecnología, 4(1), 2004. [20] X.",
        "Largo y T. Suel.",
        "Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas.",
        "En VLDB, 2003. [21] X.",
        "Largo y T. Suel.",
        "Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño.",
        "En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina.",
        "Construyendo un índice de texto completo distribuido para la web.",
        "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
        "¿Qué hay de nuevo en la web?",
        "La evolución de la web desde la perspectiva de un motor de búsqueda.",
        "En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly.",
        "Detectando páginas web de spam a través del análisis de contenido.",
        "En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd.",
        "El ranking de citas de PageRank: Trayendo orden a la web.",
        "Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis.",
        "Recuperación de documentos filtrados con índices ordenados por frecuencia.",
        "Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos.",
        "El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank.",
        "En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones.",
        "Ponderación de relevancia de términos de búsqueda.",
        "Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill.",
        "Introducción a la recuperación de información moderna.",
        "McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto.",
        "Caché de dos niveles que preserva el orden para motores de búsqueda escalables.",
        "En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel.",
        "Evaluación de consultas Top-k con garantías probabilísticas.",
        "En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina.",
        "Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos.",
        "En Sistemas de Información Paralelos y Distribuidos, 1993."
    ],
    "error_count": 5,
    "keys": {
        "web search engine": {
            "translated_key": "motores de búsqueda web",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in <br>web search engine</br>s with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large <br>web search engine</br>s.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Optimizing result prefetching in <br>web search engine</br>s with segmented indices.",
                "Three-level caching for efficient query processing in large <br>web search engine</br>s."
            ],
            "translated_annotated_samples": [
                "Optimización de la precarga de resultados en <br>motores de búsqueda web</br> con índices segmentados.",
                "Caché de tres niveles para un procesamiento eficiente de consultas en <br>motores de búsqueda web</br> de gran tamaño."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en <br>motores de búsqueda web</br> con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en <br>motores de búsqueda web</br> de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "large-scale inverted index": {
            "translated_key": "índices invertidos a gran escala",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain <br>large-scale inverted index</br>es which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their <br>large-scale inverted index</br>es in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain <br>large-scale inverted index</br>es which are queried thousands of times per second by users eager for information.",
                "CONCLUDING REMARKS Web search engines typically prune their <br>large-scale inverted index</br>es in order to scale to enormous query loads."
            ],
            "translated_annotated_samples": [
                "El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen <br>índices invertidos a gran escala</br> que son consultados miles de veces por segundo por usuarios ansiosos de información.",
                "CONCLUSIONES Los motores de búsqueda web suelen podar sus <br>índices invertidos a gran escala</br> para poder manejar cargas de consultas enormes."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen <br>índices invertidos a gran escala</br> que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus <br>índices invertidos a gran escala</br> para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "query load": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge <br>query load</br>, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the <br>query load</br> of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a <br>query load</br> of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the <br>query load</br> is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the <br>query load</br> of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the <br>query load</br>.",
                "Problem 1 (Optimal index size) Given a <br>query load</br> Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the <br>query load</br> Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the <br>query load</br> and the pruning policy.",
                "For example, even for the same p-index, if the <br>query load</br> changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the <br>query load</br> and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the <br>query load</br>.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the <br>query load</br> Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the <br>query load</br> Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day <br>query load</br>, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "In order to cope with this huge <br>query load</br>, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "We also suppose that one copy of IF can handle the <br>query load</br> of 1000 queries/sec.",
                "That is, the search engine gets a <br>query load</br> of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Example 3 Again, consider a scenario similar to Example 1, where the <br>query load</br> is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the <br>query load</br> of 5000 queries/sec."
            ],
            "translated_annotated_samples": [
                "Para hacer frente a esta gran <br>carga de consultas</br>, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a).",
                "También suponemos que una copia de IF puede manejar la <br>carga de consultas</br> de 1000 consultas por segundo.",
                "Es decir, el motor de búsqueda recibe una <br>carga de consulta</br> de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo.",
                "Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la <br>carga de consultas</br> es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas.",
                "En el primer nivel, necesitamos 5 copias de IP 1 para manejar la <br>carga de consultas</br> de 5000 consultas/seg."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran <br>carga de consultas</br>, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la <br>carga de consultas</br> de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una <br>carga de consulta</br> de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la <br>carga de consultas</br> es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la <br>carga de consultas</br> de 5000 consultas/seg. ",
            "candidates": [],
            "error": [
                [
                    "carga de consultas",
                    "carga de consultas",
                    "carga de consulta",
                    "carga de consultas",
                    "carga de consultas"
                ]
            ]
        },
        "pruned index": {
            "translated_key": "índice podado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this <br>pruned index</br> to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the <br>pruned index</br> we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the <br>pruned index</br>, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the <br>pruned index</br> and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the <br>pruned index</br> most of the time.",
                "We also show how to determine the optimal size of a <br>pruned index</br> and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the <br>pruned index</br>.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the <br>pruned index</br> [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the <br>pruned index</br> if the page did not become part of the <br>pruned index</br> for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the <br>pruned index</br>.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the <br>pruned index</br> most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A <br>pruned index</br> Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, <br>pruned index</br> (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the <br>pruned index</br> alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-<br>pruned index</br> IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the <br>pruned index</br>, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the <br>pruned index</br>.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the <br>pruned index</br> IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a <br>pruned index</br> with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a <br>pruned index</br> we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-<br>pruned index</br> can guarantee 73% of the queries with a size of 30% of the full index, while a document-<br>pruned index</br> can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this <br>pruned index</br> to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the <br>pruned index</br> we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the <br>pruned index</br>, it will be placed behind the results computed from the pruned index.",
                "Our contribution is a number of modifications in the pruning techniques for creating the <br>pruned index</br> and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the <br>pruned index</br> most of the time.",
                "We also show how to determine the optimal size of a <br>pruned index</br> and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the <br>pruned index</br>."
            ],
            "translated_annotated_samples": [
                "Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este <br>índice podado</br> para calcular los primeros lotes de resultados.",
                "Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del <br>índice podado</br>, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el <br>índice podado</br>, se colocará detrás de los resultados calculados a partir del índice podado.",
                "Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el <br>índice podado</br> y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del <br>índice podado</br>.",
                "También mostramos cómo determinar el tamaño óptimo de un <br>índice podado</br> y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web.",
                "Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el <br>índice podado</br>."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este <br>índice podado</br> para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del <br>índice podado</br>, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el <br>índice podado</br>, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el <br>índice podado</br> y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del <br>índice podado</br>. También mostramos cómo determinar el tamaño óptimo de un <br>índice podado</br> y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el <br>índice podado</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "online search market": {
            "translated_key": "mercado de búsqueda en línea",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the <br>online search market</br>, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the <br>online search market</br>, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Given the fierce competition in the <br>online search market</br>, this phenomenon is clearly undesirable.",
                "Given the fierce competition in the <br>online search market</br>, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?"
            ],
            "translated_annotated_samples": [
                "Dada la feroz competencia en el <br>mercado de búsqueda en línea</br>, este fenómeno es claramente indeseable.",
                "Dada la feroz competencia en el <br>mercado de búsqueda en línea</br>, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles?"
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el <br>mercado de búsqueda en línea</br>, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el <br>mercado de búsqueda en línea</br>, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "degradation of result quality": {
            "translated_key": "degradación de la calidad de los resultados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any <br>degradation of result quality</br> due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "In this paper, we study how we can avoid any <br>degradation of result quality</br> due to the pruning-based performance optimization, while still realizing most of its benefit."
            ],
            "translated_annotated_samples": [
                "En este artículo, estudiamos cómo podemos evitar cualquier <br>degradación de la calidad de los resultados</br> debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier <br>degradación de la calidad de los resultados</br> debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "result quality degradation": {
            "translated_key": "degradación de la calidad del resultado",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "pruning-based performance optimization": {
            "translated_key": "optimización del rendimiento basada en la poda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the <br>pruning-based performance optimization</br>, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "In this paper, we study how we can avoid any degradation of result quality due to the <br>pruning-based performance optimization</br>, while still realizing most of its benefit."
            ],
            "translated_annotated_samples": [
                "En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la <br>optimización del rendimiento basada en la poda</br>, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la <br>optimización del rendimiento basada en la poda</br>, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "pruning technique": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the <br>pruning technique</br>s for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the <br>pruning technique</br>s in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the <br>pruning technique</br>s for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced <br>pruning technique</br>s and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe <br>pruning technique</br>s based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new <br>pruning technique</br>s and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two <br>pruning technique</br>s, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Our contribution is a number of modifications in the <br>pruning technique</br>s for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the <br>pruning technique</br>s in [7, 20]) and compute the first batch of answers using the pruned index.",
                "That is, we present a number of simple (yet important) changes in the <br>pruning technique</br>s for creating the pruned index.",
                "These enhanced <br>pruning technique</br>s and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe <br>pruning technique</br>s based on the idea of keeping the postings that contribute the most in the final ranking."
            ],
            "translated_annotated_samples": [
                "Nuestra contribución consiste en una serie de modificaciones en las <br>técnicas de poda</br> para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado.",
                "Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las <br>técnicas de poda</br> en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado.",
                "Es decir, presentamos una serie de cambios simples (pero importantes) en las <br>técnicas de poda</br> para crear el índice podado.",
                "Estas <br>técnicas mejoradas de poda</br> y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día.",
                "Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen <br>técnicas de poda</br> basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las <br>técnicas de poda</br> para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las <br>técnicas de poda</br> en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las <br>técnicas de poda</br> para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas <br>técnicas mejoradas de poda</br> y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen <br>técnicas de poda</br> basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. ",
            "candidates": [],
            "error": [
                [
                    "técnicas de poda",
                    "técnicas de poda",
                    "técnicas de poda",
                    "técnicas mejoradas de poda",
                    "técnicas de poda"
                ]
            ]
        },
        "result computation algorithm": {
            "translated_key": "algoritmo de cálculo de resultados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new <br>result computation algorithm</br> that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new <br>result computation algorithm</br> that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time."
            ],
            "translated_annotated_samples": [
                "Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo <br>algoritmo de cálculo de resultados</br> que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo <br>algoritmo de cálculo de resultados</br> que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "top-matching page": {
            "translated_key": "página con mejor coincidencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the <br>top-matching page</br> according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "That is, even if a page should be placed as the <br>top-matching page</br> according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20]."
            ],
            "translated_annotated_samples": [
                "Es decir, aunque una página deba ser colocada como la <br>página con mejor coincidencia</br> según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la <br>página con mejor coincidencia</br> según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "top search result": {
            "translated_key": "los primeros resultados de búsqueda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the <br>top search result</br>s, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the <br>top search result</br>s, even though we are computing the first batch from the pruned index most of the time."
            ],
            "translated_annotated_samples": [
                "Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en <br>los primeros resultados de búsqueda</br>, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en <br>los primeros resultados de búsqueda</br>, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. \"Inter\" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. \n\nACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "optimal size": {
            "translated_key": "tamaño óptimo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the <br>optimal size</br> of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "<br>optimal size</br> OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the <br>optimal size</br> of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index <br>optimal size</br> s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the <br>optimal size</br> is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "We also show how to determine the <br>optimal size</br> of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "<br>optimal size</br> OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "Given this tradeoff, how should we determine the <br>optimal size</br> of IP in order to maximize the cost saving?",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index <br>optimal size</br> s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "For example, in Figure 3, the <br>optimal size</br> is when s = 0.16."
            ],
            "translated_annotated_samples": [
                "También mostramos cómo determinar el <br>tamaño óptimo</br> de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web.",
                "TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor.",
                "Dado este compromiso, ¿cómo deberíamos determinar el <br>tamaño óptimo</br> de la propiedad intelectual para maximizar el ahorro de costos?",
                "Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas.",
                "Por ejemplo, en la Figura 3, el <br>tamaño óptimo</br> es cuando s = 0.16."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el <br>tamaño óptimo</br> de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el <br>tamaño óptimo</br> de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el <br>tamaño óptimo</br> es cuando s = 0.16. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "invert index": {
            "translated_key": "índice invertido",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "prune": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines <br>prune</br> their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should <br>prune</br> the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we <br>prune</br> IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to <br>prune</br> IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we <br>prune</br> IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should <br>prune</br> the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically <br>prune</br> postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we <br>prune</br> it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically <br>prune</br> their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to <br>prune</br> an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "In order to cope with the vast amounts of query loads, search engines <br>prune</br> their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should <br>prune</br> the index to make sure that the majority of queries are handled by IP alone.",
                "Question 2 How should we <br>prune</br> IF to IP to realize the maximum cost saving?",
                "What will be the optimal way to <br>prune</br> IF to IP , such that C = 1 for a large fraction of queries?",
                "But now, suppose that if we <br>prune</br> IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries)."
            ],
            "translated_annotated_samples": [
                "Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda <br>podan su índice</br> para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados.",
                "Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos <br>podar</br> el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP.",
                "Pregunta 2 ¿Cómo debemos <br>podar</br> IF a IP para lograr el máximo ahorro de costos?",
                "¿Cuál será la forma óptima de <br>podar</br> IF a IP, de manera que C = 1 para una gran fracción de consultas?",
                "Pero ahora, supongamos que si <br>podamos</br> IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas)."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda <br>podan su índice</br> para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos <br>podar</br> el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos <br>podar</br> IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de <br>podar</br> IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si <br>podamos</br> IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). ",
            "candidates": [],
            "error": [
                [
                    "podan su índice",
                    "podar",
                    "podar",
                    "podar",
                    "podamos"
                ]
            ]
        },
        "correctness guarantee": {
            "translated_key": "garantía de corrección",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with <br>correctness guarantee</br> Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with <br>correctness guarantee</br> Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result <br>correctness guarantee</br>. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 <br>correctness guarantee</br> under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the <br>correctness guarantee</br>.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a <br>correctness guarantee</br>, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the <br>correctness guarantee</br> to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [
                "Pruning Policies for Two-Tiered Inverted Index with <br>correctness guarantee</br> Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with <br>correctness guarantee</br> Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result <br>correctness guarantee</br>. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 <br>correctness guarantee</br> under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the <br>correctness guarantee</br>.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a <br>correctness guarantee</br>, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index."
            ],
            "translated_annotated_samples": [
                "Políticas de poda para índice invertido de dos niveles con <br>garantía de corrección</br> Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA.",
                "Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con <br>garantía de corrección</br>. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la <br>garantía de corrección</br> del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo.",
                "Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles?",
                "Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la <br>garantía de corrección</br>.",
                "Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo."
            ],
            "translated_text": "Políticas de poda para índice invertido de dos niveles con <br>garantía de corrección</br> Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con <br>garantía de corrección</br>. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la <br>garantía de corrección</br> del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la <br>garantía de corrección</br>. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}