{
    "id": "I-71",
    "original_text": "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems. Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources. In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in. It hence makes the situation in which the alignment occurs explicit in the model. We resort to Channel Theory to carry out the formalisation. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems. General Terms Theory 1. INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain. It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers. As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web. But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3]. Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate. This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems. Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time. In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information). Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8]. Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances. We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism. Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain. Imagine a situation in which two agents are facing each other in front of a checker board. Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right. Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board. Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment. The same agents situated differently may produce a different alignment. This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12]. This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment. In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation. In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1]. This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information. Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in. We shall therefore consider a scenario with two or more agents situated in an environment. Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state. Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies). We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment. The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment. In Section 2 we describe our formal model for Situated Semantic Alignment (SSA). First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment. Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic. These approximations gradually become more reliable as the method is applied. In Section 3 we report on an application of our method. Conclusions and further work are analyzed in Section 4. Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper. We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2. A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward). We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states. We further assume that each agent is able to observe the environment and has its own perception of it. This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different. According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A). So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system. For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi. Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai. Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities. Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε. The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment. However, the set of types of the power classification includes all possible token configurations potentially described by types. Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε. The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory. The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them. The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}. Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types. We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α. We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types. Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A). The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2. Notice however that these constraints are obvious. As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below. As important as the notion of channel is the concept of distributed logic (see appendix A). Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel. In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion. On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2). On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens). All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic). In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2). Log(E) is the logic of SSA. Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions. Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B). If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B). That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints. This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA. Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely. In this section, we present a method by which agents obtain approximations to Th(Log(E)). We also prove these approximations gradually become more reliable as the method is applied. Agents can obtain approximations to Th(Log(E)) through communication. A1 and A2 communicate by exchanging information about their perceptions of environment states. This information is expressed in terms of their own classification relations. Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not. This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information. Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e . The significant point is that C is a refinement of C (see appendix A). Theorem 2.1 below ensures that the refined channel involves more reliable information. The communication supposedly ends when agents have observed all the environment states. Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)). Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable. Theorem 2.1. Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels. If C is a refinement of C then: 1. Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Proof. Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi . Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1. Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ]. We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ]. We proceed by reductio ad absurdum. Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] . Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ. Let us choose an arbitrary γ ∈ Γ. We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}. Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ. Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ). A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] . Hence Γ Log(C) Δ as we wanted to prove. 2. Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C). Therefore, there exists c token in C such that a1, a2 = ˇf(c). Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}. Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ). Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof. Remark 2.1. Theorem 2.1 asserts that the more refined channel gives more reliable information. Even though its theory has less constraints, it has more normal tokens to which they apply. In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2. Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form. We also choose an infinite numerable set of symbols {cn | n ∈ N}1 . We omit informorphisms superscripts when no confusion arises. Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a). Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E). A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ). We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1. So can A2 do. Since both typ(A1) and typ(A2) are finite, this process eventually finishes. After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication. It is easy to prove that Th(Log(C1 )) = Th(C1 ). The significant point is that both agents know C1 as the result of the communication. Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 . Now, let us assume that E turns to a new state e2 . Agents can proceed as before, exchanging this time information about their perceptions of e2 . Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up. We define C2 so as to take also into account the information provided by the previous stage of communication. On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents. Note this set is chosen with the same cardinality of S. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages. Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 . A1 and A2 knows C2 so they can use these constraints. The key point is that channel C2 is a refinement of C1 . It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3). By Theorem 2.1, C2 constraints are more reliable than C1 constraints. In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment. Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3). Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en . Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable. It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2. At that point, the family of channels {Cn }n∈N would inform of all the communication stages. It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks. But the study of possible termination criteria is outside the scope of this paper and left for future work. From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states. On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper. It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA. Theorem 2.2. The following statements hold: 1. For all n ∈ N, C∗ is a refinement of Cn . 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Proof. 1. It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2. The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3. AN EXAMPLE In the previous section we have described in great detail our formal model for SSA. However, we have not tackled the practical aspect of the model yet. In this section, we give a brushstroke of the pragmatic view of our approach. We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication. Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4). Robots can carry only one package at a time and they can not move through a package. Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have. Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5). We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively. Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary. We assume the reader has all those descriptions in mind. All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other. In order to communicate, agents send messages using some ontology. In our scenario, there coexist two ontologies, the UDRL and LCR ontologies. Both of them are very simple and are just confined to describe what robots observe. Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance. Let us suppose two URDL robots are in a situation like the one depicted in Figure 6. Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request. This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square. Now, problems arise when a LCR robot and a URDL robot try to interoperate. See Figure 7. Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 . Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}. From these, only the following constraints are plausible according to C1 : The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place. C2 also considers the previous information and hence refines C1 . The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic. Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic. Figure 8: Refinement 4. CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states. Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow. Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process. Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities. In the future, our effort will focus on the practical side of the situated semantic alignment problem. We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact. The formal model exposed in this paper will constitute a solid base of future practical results. Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253. Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5. REFERENCES [1] J. Barwise and J. Seligman. Information Flow: The Logic of Distributed Systems. Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia. Local models semantics, or contextual reasoning = locality + compatibility. Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko. Semantic matching. The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer. IF-Map: An ontology-mapping method based on information-flow theory. In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer. Ontology mapping: The sate of the art. The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent. Semantic integration in the Information Flow Framework. In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat. CyC: A large-scale investment in knowledge infrastructure. Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta. PowerMap: Mapping the real Semantic Web on the fly. Proceedings of the ISWC06, 2006. [9] F. McNeill. Dynamic Ontology Refinement. PhD 1284 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou. Progressive ontology alignment for meaning coordination: An information-theoretic foundation. In 4th Int. Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat. A survey of schema-based matching approaches. In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. The Origins of Ontologies and Communication Conventions in Multi-Agent Systems. In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al. ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int. Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A. CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A). If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A). Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) . Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ. A binary relation between subsets of Σ is called a consequence relation on Σ. A theory is a pair T = Σ, where is a consequence relation on Σ. A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1. Identity: α α 2. Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel. A channel can be defined with an arbitrary index set. 3. Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification. A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ. The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ . Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3. NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L). A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L). L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L). Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A). Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }. Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2. Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2. A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr). Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B. CHANNEL THEORY THEOREMS Theorem B.1. The logic generated by a classification is sound and complete. Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A). Theorem B.2. Let L be a logic on a classification B and f : A → B an infomorphism. 1. If L is complete then f−1 [L] is complete. 2. If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285",
    "original_translation": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285",
    "original_sentences": [
        "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
        "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
        "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
        "It hence makes the situation in which the alignment occurs explicit in the model.",
        "We resort to Channel Theory to carry out the formalisation.",
        "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
        "General Terms Theory 1.",
        "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
        "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
        "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
        "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
        "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
        "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
        "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
        "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
        "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
        "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
        "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
        "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
        "Imagine a situation in which two agents are facing each other in front of a checker board.",
        "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
        "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
        "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
        "The same agents situated differently may produce a different alignment.",
        "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
        "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
        "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
        "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
        "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
        "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
        "We shall therefore consider a scenario with two or more agents situated in an environment.",
        "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
        "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
        "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
        "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
        "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
        "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
        "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
        "These approximations gradually become more reliable as the method is applied.",
        "In Section 3 we report on an application of our method.",
        "Conclusions and further work are analyzed in Section 4.",
        "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
        "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
        "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
        "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
        "We further assume that each agent is able to observe the environment and has its own perception of it.",
        "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
        "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
        "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
        "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
        "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
        "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
        "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
        "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
        "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
        "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
        "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
        "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
        "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
        "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
        "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
        "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
        "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
        "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
        "Notice however that these constraints are obvious.",
        "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
        "As important as the notion of channel is the concept of distributed logic (see appendix A).",
        "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
        "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
        "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
        "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
        "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
        "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
        "Log(E) is the logic of SSA.",
        "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
        "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
        "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
        "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
        "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
        "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
        "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
        "We also prove these approximations gradually become more reliable as the method is applied.",
        "Agents can obtain approximations to Th(Log(E)) through communication.",
        "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
        "This information is expressed in terms of their own classification relations.",
        "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
        "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
        "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
        "The significant point is that C is a refinement of C (see appendix A).",
        "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
        "The communication supposedly ends when agents have observed all the environment states.",
        "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
        "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
        "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
        "Theorem 2.1.",
        "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
        "If C is a refinement of C then: 1.",
        "Th(Log(C )) ⊆ Th(Log(C)) 2.",
        "NLog(C ) ⊇ NLog(C) Proof.",
        "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
        "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
        "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
        "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
        "We proceed by reductio ad absurdum.",
        "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
        "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
        "Let us choose an arbitrary γ ∈ Γ.",
        "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
        "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
        "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
        "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
        "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
        "Hence Γ Log(C) Δ as we wanted to prove. 2.",
        "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
        "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
        "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
        "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
        "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
        "Remark 2.1.",
        "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
        "Even though its theory has less constraints, it has more normal tokens to which they apply.",
        "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
        "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
        "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
        "We omit informorphisms superscripts when no confusion arises.",
        "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
        "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
        "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
        "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
        "So can A2 do.",
        "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
        "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
        "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
        "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
        "The significant point is that both agents know C1 as the result of the communication.",
        "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
        "Now, let us assume that E turns to a new state e2 .",
        "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
        "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
        "We define C2 so as to take also into account the information provided by the previous stage of communication.",
        "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
        "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
        "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
        "A1 and A2 knows C2 so they can use these constraints.",
        "The key point is that channel C2 is a refinement of C1 .",
        "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
        "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
        "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
        "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
        "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
        "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
        "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
        "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
        "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
        "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
        "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
        "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
        "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
        "Theorem 2.2.",
        "The following statements hold: 1.",
        "For all n ∈ N, C∗ is a refinement of Cn . 2.",
        "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
        "Proof. 1.",
        "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
        "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
        "Cn 1282 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
        "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
        "However, we have not tackled the practical aspect of the model yet.",
        "In this section, we give a brushstroke of the pragmatic view of our approach.",
        "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
        "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
        "Robots can carry only one package at a time and they can not move through a package.",
        "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
        "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
        "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
        "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
        "We assume the reader has all those descriptions in mind.",
        "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
        "In order to communicate, agents send messages using some ontology.",
        "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
        "Both of them are very simple and are just confined to describe what robots observe.",
        "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
        "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
        "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
        "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
        "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
        "See Figure 7.",
        "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
        "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
        "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
        "C2 also considers the previous information and hence refines C1 .",
        "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
        "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
        "Figure 8: Refinement 4.",
        "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
        "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
        "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
        "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
        "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
        "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
        "The formal model exposed in this paper will constitute a solid base of future practical results.",
        "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
        "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
        "REFERENCES [1] J. Barwise and J. Seligman.",
        "Information Flow: The Logic of Distributed Systems.",
        "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
        "Local models semantics, or contextual reasoning = locality + compatibility.",
        "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
        "Semantic matching.",
        "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
        "IF-Map: An ontology-mapping method based on information-flow theory.",
        "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
        "Ontology mapping: The sate of the art.",
        "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
        "Semantic integration in the Information Flow Framework.",
        "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
        "CyC: A large-scale investment in knowledge infrastructure.",
        "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
        "PowerMap: Mapping the real Semantic Web on the fly.",
        "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
        "Dynamic Ontology Refinement.",
        "PhD 1284 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
        "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
        "In 4th Int.",
        "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
        "A survey of schema-based matching approaches.",
        "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
        "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
        "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
        "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
        "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
        "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
        "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
        "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
        "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
        "A binary relation between subsets of Σ is called a consequence relation on Σ.",
        "A theory is a pair T = Σ, where is a consequence relation on Σ.",
        "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
        "Identity: α α 2.",
        "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
        "A channel can be defined with an arbitrary index set. 3.",
        "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
        "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
        "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
        "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
        "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
        "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
        "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
        "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
        "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
        "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
        "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
        "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
        "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
        "CHANNEL THEORY THEOREMS Theorem B.1.",
        "The logic generated by a classification is sound and complete.",
        "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
        "Theorem B.2.",
        "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
        "If L is complete then f−1 [L] is complete. 2.",
        "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
    ],
    "translated_text_sentences": [
        "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente.",
        "La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas.",
        "En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando.",
        "Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo.",
        "Recurremos a la Teoría de Canales para llevar a cabo la formalización.",
        "Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones.",
        "Teoría de Términos Generales 1.",
        "INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular.",
        "Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento.",
        "Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica.",
        "Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida.",
        "Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen.",
        "Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos.",
        "La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución.",
        "Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial).",
        "Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8].",
        "Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas.",
        "Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación.",
        "Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio.",
        "Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas.",
        "El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho.",
        "Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas.",
        "Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular.",
        "Los mismos agentes situados de manera diferente pueden producir una alineación diferente.",
        "Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12].",
        "Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno.",
        "En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica.",
        "En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman.",
        "Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información.",
        "Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando.",
        "Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno.",
        "Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado.",
        "Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes).",
        "Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno.",
        "La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno.",
        "En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA).",
        "Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno.",
        "En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida.",
        "Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método.",
        "En la Sección 3 informamos sobre una aplicación de nuestro método.",
        "Las conclusiones y trabajos futuros se analizan en la Sección 4.",
        "Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento.",
        "No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2.",
        "Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa).",
        "Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados.",
        "Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él.",
        "Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes.",
        "Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A).",
        "Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema.",
        "Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi.",
        "Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai.",
        "Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas.",
        "Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε.",
        "La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno.",
        "Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos.",
        "Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε.",
        "La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman.",
        "El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos.",
        "El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}.",
        "La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes.",
        "Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α.",
        "Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes.",
        "Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A).",
        "La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2.",
        "Sin embargo, hay que tener en cuenta que estas restricciones son obvias.",
        "Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación.",
        "Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A).",
        "Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal.",
        "En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica.",
        "Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2).",
        "Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2).",
        "Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica).",
        "En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2).",
        "Log(E) es la lógica de SSA.",
        "El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno.",
        "Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B).",
        "Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B).",
        "Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes.",
        "Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA.",
        "Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente.",
        "En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)).",
        "También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método.",
        "Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación.",
        "A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno.",
        "Esta información se expresa en términos de sus propias relaciones de clasificación.",
        "Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son.",
        "Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa.",
        "Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e .",
        "El punto significativo es que C es un refinamiento de C (ver apéndice A).",
        "El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable.",
        "La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno.",
        "Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
        "El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)).",
        "El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables.",
        "Teorema 2.1.",
        "Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales.",
        "Si C es un refinamiento de C entonces: 1.",
        "Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2.",
        "NLog(C ) ⊇ NLog(C) Prueba.",
        "Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi.",
        "Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1.",
        "Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ].",
        "Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ].",
        "Procedemos por reducción al absurdo.",
        "Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ].",
        "Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ.",
        "Elijamos un γ arbitrario ∈ Γ.",
        "Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}.",
        "Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
        "Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ.",
        "Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ).",
        "Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ].",
        "Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2.",
        "Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C).",
        "Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c).",
        "Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}.",
        "Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C).",
        "Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba.",
        "Observación 2.1.",
        "El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable.",
        "Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica.",
        "En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2.",
        "Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar.",
        "También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}.",
        "Omitimos los superíndices de los informorfismos cuando no surge confusión.",
        "Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a).",
        "La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E).",
        "La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1).",
        "Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1.",
        "Así puede hacer A2.",
        "Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina.",
        "Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2).",
        "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación.",
        "Es fácil demostrar que Th(Log(C1)) = Th(C1).",
        "El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación.",
        "Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1.",
        "Ahora, supongamos que E cambia a un nuevo estado e2.",
        "Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2.",
        "Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}.",
        "Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación.",
        "Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes.",
        "Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores.",
        "Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2.",
        "A1 y A2 conocen C2, por lo que pueden usar estas restricciones.",
        "El punto clave es que el canal C2 es un refinamiento de C1.",
        "Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3).",
        "Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1.",
        "En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento.",
        "La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3).",
        "La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en.",
        "Recuerda que hemos asumido que S es infinitamente numerable.",
        "Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2.",
        "En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación.",
        "Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas.",
        "Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros.",
        "Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno.",
        "Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento.",
        "Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA.",
        "Teorema 2.2.",
        "Las siguientes afirmaciones son válidas: 1.",
        "Para todo n ∈ N, C∗ es un refinamiento de Cn. 2.",
        "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
        "Prueba. 1.",
        "Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2.",
        "La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
        "Cn 1282 La Sexta Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3.",
        "En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA.",
        "Sin embargo, aún no hemos abordado el aspecto práctico del modelo.",
        "En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque.",
        "Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación.",
        "Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4).",
        "Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete.",
        "Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen.",
        "Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5).",
        "Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente.",
        "Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario.",
        "Suponemos que el lector tiene todas esas descripciones en mente.",
        "Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí.",
        "Para comunicarse, los agentes envían mensajes utilizando alguna ontología.",
        "En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR.",
        "Ambos son muy simples y se limitan a describir lo que los robots observan.",
        "Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda.",
        "Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6.",
        "El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud.",
        "Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2.",
        "Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar.",
        "Ver la Figura 7.",
        "El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1.",
        "Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
        "De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional.",
        "En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2.",
        "C2 también considera la información previa y, por lo tanto, perfecciona C1.",
        "La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida.",
        "Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida.",
        "Figura 8: Refinamiento 4.",
        "CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados.",
        "Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información.",
        "Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación.",
        "En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas.",
        "En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada.",
        "Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo.",
        "El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos.",
        "Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253.",
        "Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo.",
        "REFERENCIAS [1] J. Barwise y J. Seligman.",
        "Flujo de información: La lógica de los sistemas distribuidos.",
        "Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia.",
        "La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad.",
        "Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko.",
        "Coincidencia semántica.",
        "La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer.",
        "IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información.",
        "En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer.",
        "Mapeo de ontologías: El estado del arte.",
        "La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent.",
        "Integración semántica en el Marco de Flujo de Información.",
        "En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat.",
        "CyC: Una inversión a gran escala en infraestructura de conocimiento.",
        "Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta.",
        "PowerMap: Mapeando la verdadera Web Semántica sobre la marcha.",
        "Actas de la ISWC06, 2006. [9] F. McNeill.",
        "Refinamiento de Ontología Dinámica.",
        "PhD 1284 La Sexta Internacional.",
        "Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou.",
        "Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información.",
        "En la 4ta Int.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat.",
        "Una encuesta de enfoques de coincidencia basados en esquemas.",
        "En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
        "Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente.",
        "En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros.",
        "ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A.",
        "Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A).",
        "Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A).",
        "Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
        "Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ.",
        "Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ.",
        "Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ.",
        "Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1.",
        "Identidad: α α 2.",
        "Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario.",
        "Un canal se puede definir con un conjunto de índices arbitrario.",
        "Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación.",
        "Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ.",
        "La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ.",
        "Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3.",
        "NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L).",
        "Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L).",
        "L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L).",
        "Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A).",
        "Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}.",
        "Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2.",
        "Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2.",
        "Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr).",
        "El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B.",
        "TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1.",
        "La lógica generada por una clasificación es sólida y completa.",
        "Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A).",
        "Teorema B.2.",
        "Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1.",
        "Si L es completo, entonces f−1 [L] es completo. 2.",
        "Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares.",
        "El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285"
    ],
    "error_count": 4,
    "keys": {
        "ontology": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT <br>ontology</br> matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most <br>ontology</br> matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An <br>ontology</br> is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of <br>ontology</br> matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most <br>ontology</br> matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require <br>ontology</br> matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those <br>ontology</br> fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an <br>ontology</br> and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered <br>ontology</br> (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the <br>ontology</br> of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some <br>ontology</br>.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :<br>ontology</br> URDL-<br>ontology</br> :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :<br>ontology</br> LCR-<br>ontology</br> :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: <br>ontology</br> mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most <br>ontology</br> matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete <br>ontology</br> negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An <br>ontology</br>-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "<br>ontology</br> mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic <br>ontology</br> Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive <br>ontology</br> alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal <br>ontology</br> Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT <br>ontology</br> matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most <br>ontology</br> matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "INTRODUCTION An <br>ontology</br> is commonly defined as a specification of the conceptualisation of a particular domain.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of <br>ontology</br> matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most <br>ontology</br> matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require <br>ontology</br> matching to be locally performed during run-time."
            ],
            "translated_annotated_samples": [
                "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de <br>ontología</br>s es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente.",
                "La mayoría de los mecanismos de coincidencia de <br>ontología</br>s, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas.",
                "INTRODUCCIÓN Una <br>ontología</br> se define comúnmente como una especificación de la conceptualización de un dominio particular.",
                "Pero la proliferación de muchas <br>ontología</br>s diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de <br>ontología</br>s que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida.",
                "La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la <br>coincidencia de ontologías</br> se realice localmente durante el tiempo de ejecución."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de <br>ontología</br>s es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de <br>ontología</br>s, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una <br>ontología</br> se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas <br>ontología</br>s diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de <br>ontología</br>s que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la <br>coincidencia de ontologías</br> se realice localmente durante el tiempo de ejecución. ",
            "candidates": [],
            "error": [
                [
                    "ontología",
                    "ontología",
                    "ontología",
                    "ontología",
                    "ontología",
                    "coincidencia de ontologías"
                ]
            ]
        },
        "multi-agent system": {
            "translated_key": "sistemas multiagente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as <br>multi-agent system</br>s, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as <br>multi-agent system</br>s, federated databases, or the Semantic Web."
            ],
            "translated_annotated_samples": [
                "Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como <br>sistemas multiagente</br>, bases de datos federadas o la Web Semántica."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como <br>sistemas multiagente</br>, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "federated database": {
            "translated_key": "bases de datos federadas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, <br>federated database</br>s, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, <br>federated database</br>s, or the Semantic Web."
            ],
            "translated_annotated_samples": [
                "Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, <br>bases de datos federadas</br> o la Web Semántica."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, <br>bases de datos federadas</br> o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "semantic web": {
            "translated_key": "Web Semántica",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the <br>semantic web</br>.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real <br>semantic web</br> on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the <br>semantic web</br>.",
                "PowerMap: Mapping the real <br>semantic web</br> on the fly."
            ],
            "translated_annotated_samples": [
                "Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la <br>Web Semántica</br>.",
                "PowerMap: Mapeando la verdadera <br>Web Semántica</br> sobre la marcha."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la <br>Web Semántica</br>. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera <br>Web Semántica</br> sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "knowledge-based system": {
            "translated_key": "sistemas basados en el conocimiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating <br>knowledge-based system</br>s or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "Furthermore, matching often has been carried out at design-time, before integrating <br>knowledge-based system</br>s or making them interoperate."
            ],
            "translated_annotated_samples": [
                "Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar <br>sistemas basados en el conocimiento</br> o hacer que interoperen."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar <br>sistemas basados en el conocimiento</br> o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "disjoint union": {
            "translated_key": "unión disjunta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the <br>disjoint union</br> of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the <br>disjoint union</br> because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the <br>disjoint union</br> of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the <br>disjoint union</br> because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types."
            ],
            "translated_annotated_samples": [
                "Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la <br>unión disjunta</br> de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α.",
                "Damos importancia a tomar la <br>unión disjunta</br> porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la <br>unión disjunta</br> de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la <br>unión disjunta</br> porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "sum infomorphism": {
            "translated_key": "sum infomorfismo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the <br>sum infomorphism</br>, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the <br>sum infomorphism</br>, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below."
            ],
            "translated_annotated_samples": [
                "Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del <br>sum infomorfismo</br>, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del <br>sum infomorfismo</br>, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "constraint": {
            "translated_key": "restricción",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following <br>constraint</br>: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above <br>constraint</br> should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only <br>constraint</br> from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this <br>constraint</br> is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a <br>constraint</br> of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a <br>constraint</br> of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following <br>constraint</br>: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above <br>constraint</br> should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "The only <br>constraint</br> from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this <br>constraint</br> is an element of the theory of the distributed logic.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a <br>constraint</br> of the theory T. T is regular if it satisfies: 1.",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a <br>constraint</br> of Th(L)."
            ],
            "translated_annotated_samples": [
                "Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente <br>restricción</br>: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La <br>restricción</br> anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2.",
                "La única <br>restricción</br> de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta <br>restricción</br> es un elemento de la teoría de la lógica distribuida.",
                "Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una <br>restricción</br> de la teoría T. T es regular si cumple: 1.",
                "L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una <br>restricción</br> de Th(L)."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente <br>restricción</br>: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La <br>restricción</br> anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única <br>restricción</br> de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta <br>restricción</br> es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de refinamientos del canal de información que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una <br>restricción</br> de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una <br>restricción</br> de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "information-channel refinement": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of <br>information-channel refinement</br>s in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of <br>information-channel refinement</br>s that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of <br>information-channel refinement</br>s in the sense of Barwise and Seligmans theory of information flow [1].",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of <br>information-channel refinement</br>s that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states."
            ],
            "translated_annotated_samples": [
                "En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de <br>refinamientos de canal de información</br> en el sentido de la teoría del flujo de información de Barwise y Seligman.",
                "CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de <br>refinamientos del canal de información</br> que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de <br>refinamientos de canal de información</br> en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de <br>refinamientos del canal de información</br> que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    "refinamientos de canal de información",
                    "refinamientos del canal de información"
                ]
            ]
        },
        "distributed logic": {
            "translated_key": "lógica distribuida",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the <br>distributed logic</br> generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this <br>distributed logic</br>.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of <br>distributed logic</br> (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the <br>distributed logic</br>, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the <br>distributed logic</br>.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the <br>distributed logic</br>.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "<br>distributed logic</br>: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the <br>distributed logic</br> of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the <br>distributed logic</br> generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this <br>distributed logic</br>.",
                "As important as the notion of channel is the concept of <br>distributed logic</br> (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the <br>distributed logic</br>, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the <br>distributed logic</br>."
            ],
            "translated_annotated_samples": [
                "Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la <br>lógica distribuida</br> generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno.",
                "En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta <br>lógica distribuida</br>.",
                "Tan importante como la noción de canal es el concepto de <br>lógica distribuida</br> (ver apéndice A).",
                "Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la <br>lógica distribuida</br>, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal.",
                "La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la <br>lógica distribuida</br>."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de refinamientos de canal de información en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la <br>lógica distribuida</br> generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta <br>lógica distribuida</br>. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de <br>lógica distribuida</br> (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la <br>lógica distribuida</br>, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la <br>lógica distribuida</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "semantic alignment": {
            "translated_key": "alineación semántica",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated <br>semantic alignment</br> Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the <br>semantic alignment</br> of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a <br>semantic alignment</br> procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a <br>semantic alignment</br> of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that <br>semantic alignment</br> of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their <br>semantic alignment</br>, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated <br>semantic alignment</br> as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the <br>semantic alignment</br> that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated <br>semantic alignment</br> (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of <br>semantic alignment</br> as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise <br>semantic alignment</br> using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to <br>semantic alignment</br>, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines <br>semantic alignment</br> in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated <br>semantic alignment</br> problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "A Formal Model for Situated <br>semantic alignment</br> Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the <br>semantic alignment</br> of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "In this paper, we present a formal model for a <br>semantic alignment</br> procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a <br>semantic alignment</br> of ontological entities as output [3].",
                "We claim that <br>semantic alignment</br> of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Their <br>semantic alignment</br>, however, will only be valid in the scope of their interaction within this particular situation or environment."
            ],
            "translated_annotated_samples": [
                "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la <br>alineación semántica</br> de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente.",
                "En este documento, presentamos un modelo formal para un procedimiento de <br>alineación semántica</br> que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando.",
                "Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una <br>alineación semántica</br> de entidades ontológicas como salida.",
                "Sostenemos que la <br>alineación semántica</br> de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación.",
                "Su <br>alineación semántica</br>, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la <br>alineación semántica</br> de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de <br>alineación semántica</br> que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una <br>alineación semántica</br> de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la <br>alineación semántica</br> de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su <br>alineación semántica</br>, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "distribute logic": {
            "translated_key": "distribuir la lógica",
            "is_in_text": false,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "channel refinement": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Formal Model for Situated Semantic Alignment Manuel Atencia Marco Schorlemmer IIIA, Artificial Intelligence Research Institute CSIC, Spanish National Research Council Bellaterra (Barcelona), Catalonia, Spain {manu, marco}@iiia.csic.es ABSTRACT Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications, and therefore to enable their interoperability in distributed environments such as multiagent systems.",
                "Most ontology matching mechanisms, however, assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources.",
                "In this paper, we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in.",
                "It hence makes the situation in which the alignment occurs explicit in the model.",
                "We resort to Channel Theory to carry out the formalisation.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-coherence and coordination, multiagent systems; D.2.12 [Software Engineering]: Interoperability-data mapping; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-semantic networks, relation systems.",
                "General Terms Theory 1.",
                "INTRODUCTION An ontology is commonly defined as a specification of the conceptualisation of a particular domain.",
                "It fixes the vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.",
                "As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments, such as multi-agent systems, federated databases, or the Semantic Web.",
                "But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies. [5, 11] Until recently, most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output [3].",
                "Furthermore, matching often has been carried out at design-time, before integrating knowledge-based systems or making them interoperate.",
                "This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.",
                "Multi-agent communication, peer-to-peer information sharing, and webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.",
                "In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential information).",
                "Certainly, there exist efforts to efficiently match ontological entities at run-time, taking only those ontology fragment that are necessary for the task at hand [10, 13, 9, 8].",
                "Nevertheless, the techniques used by these systems to establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.",
                "We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment mechanism.",
                "Even two agents with identical conceptualisation capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.",
                "Imagine a situation in which two agents are facing each other in front of a checker board.",
                "Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may conceptualise the same figure as situated on the right.",
                "Although the conceptualisation of left and right is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.",
                "Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.",
                "The same agents situated differently may produce a different alignment.",
                "This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].",
                "This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment.",
                "In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.",
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-<br>channel refinement</br>s in the sense of Barwise and Seligmans theory of information flow [1].",
                "This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.",
                "Analogously, the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in.",
                "We shall therefore consider a scenario with two or more agents situated in an environment.",
                "Each agent will have its own viewpoint of the environment so that, if the environment is in a concrete state, both agents may have different perceptions of this state.",
                "Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions (and which constitute the agents respective ontologies).",
                "We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents viewpoint of the environment.",
                "The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.",
                "In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).",
                "First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents viewpoints of the environment.",
                "Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.",
                "These approximations gradually become more reliable as the method is applied.",
                "In Section 3 we report on an application of our method.",
                "Conclusions and further work are analyzed in Section 4.",
                "Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.",
                "We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 2.",
                "A FORMAL MODEL FOR SSA 2.1 The Logic of SSA Consider a scenario with two agents A1 and A2 situated in an environment E (the generalization to any numerable set of agents is straightforward).",
                "We associate a numerable set S of states to E and, at any given instant, we suppose E to be in one of these states.",
                "We further assume that each agent is able to observe the environment and has its own perception of it.",
                "This ability is faithfully captured by a surjective function seei : S → Pi, where i ∈ {1, 2}, and typically see1 and see2 are different.",
                "According to Channel Theory, information is only viable where there is a systematic way of classifying some range of things as being this way or that, in other words, where there is a classification (see appendix A).",
                "So in order to be within the framework of Channel Theory, we must associate classifications to the components of our system.",
                "For each i ∈ {1, 2}, we consider a classification Ai that models Ais viewpoint of E. First, tok(Ai) is composed of Ais perceptions of E states, that is, tok(Ai) = Pi.",
                "Second, typ(Ai) contains the syntactic entities by which Ai describes its perceptions, the ones constituting the ontology of Ai.",
                "Finally, |=Ai synthesizes how Ai relates its perceptions with these syntactic entities.",
                "Now, with the aim of associating environment E with a classification E we choose the power classification of S as E, which is the classification whose set of types is equal to 2S , whose tokens are the elements of S, and for which a token e is of type ε if e ∈ ε.",
                "The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since, in general, there is no global conceptualisation of the environment.",
                "However, the set of types of the power classification includes all possible token configurations potentially described by types.",
                "Thus tok(E) = S, typ(E) = 2S and e |=E ε if and only if e ∈ ε.",
                "The notion of channel (see appendix A) is fundamental in Barwise and Seligmans theory.",
                "The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms (see appendix A) which provide a way of moving information between them.",
                "The information flow of the scenario under consideration is accurately described by channel E = {fi : Ai → E}i∈{1,2} defined as follows: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each α ∈ typ(Ai) • ˇfi(e) = seei(e) for each e ∈ tok(E) where i ∈ {1, 2}.",
                "Definition of ˇfi seems natural while ˆfi is defined in such a way that the fundamental property of the infomorphisms is fulfilled: ˇfi(e) |=Ai α iff seei(e) |=Ai α (by definition of ˇfi) iff e ∈ ˆfi(α) (by definition of ˆfi) iff e |=E ˆfi(α) (by definition of |=E) The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1279 Consequently, E is the core of channel E and a state e ∈ tok(E) connects agents perceptions ˇf1(e) and ˇf2(e) (see Figure 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figure 1: Channel E E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E. We want to obtain meaningful relations among agents syntactic entities, that is, agents types.",
                "We state that meaningfulness must be in accord with E. The sum operation (see appendix A) gives us a way of putting the two agents classifications of channel E together into a single classification, namely A1 +A2, and also the two infomorphisms together into a single infomorphism, f1 +f2 : A1 + A2 → E. A1 + A2 assembles agents classifications in a very coarse way. tok(A1 + A2) is the cartesian product of tok(A1) and tok(A2), that is, tok(A1 + A2) = { p1, p2 | pi ∈ Pi}, so a token of A1 + A2 is a pair of agents perceptions with no restrictions. typ(A1 + A2) is the disjoint union of typ(A1) and typ(A2), and p1, p2 is of type i, α if pi is of type α.",
                "We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents types.",
                "Now, Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics (see appendix A).",
                "The theory generated by the sum classification, Th(A1 + A2), and hence its logic generated, Log(A1 + A2), involve all those constraints among agents types valid according to A1 +A2.",
                "Notice however that these constraints are obvious.",
                "As we stated above, meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism, f = f1 + f2, where: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} for each i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) for each e ∈ tok(E) Meaningful constraints among agents types are in accord with channel E because they are computed making use of f as we expound below.",
                "As important as the notion of channel is the concept of distributed logic (see appendix A).",
                "Given a channel C and a logic L on its core, DLogC(L) represents the reasoning about relations among the components of C justified by L. If L = Log(C), the distributed logic, we denoted by Log(C), captures in a logical fashion the information flow inherent in the channel.",
                "In our case, Log(E) explains the relationship between the agents viewpoints of the environment in a logical fashion.",
                "On the one hand, constraints of Th(Log(E)) are defined by: Γ Log(E) Δ if ˆf[Γ] Log(E) ˆf[Δ] (1) where Γ, Δ ⊆ typ(A1 + A2).",
                "On the other hand, the set of normal tokens, NLog(E), is equal to the range of function ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Therefore, a normal token is a pair of agents perceptions that are restricted by coming from the same environment state (unlike A1 + A2 tokens).",
                "All constraints of Th(Log(E)) are satisfied by all normal tokens (because of being a logic).",
                "In this particular case, this condition is also sufficient (the proof is straightforward); as alternative to (1) we have: Γ Log(E) Δ iff for all e ∈ tok(E), if (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] then (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) where Γ, Δ ⊆ typ(A1 + A2).",
                "Log(E) is the logic of SSA.",
                "Th(Log(E)) comprises the most meaningful constraints among agents types in accord with channel E. In other words, the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions.",
                "Log(E) is complete since Log(E) is complete but it is not necessarily sound because although Log(E) is sound, ˇf is not surjective in general (see appendix B).",
                "If Log(E) is also sound then Log(E) = Log(A1 +A2) (see appendix B).",
                "That means there is no significant relation between agents points of view of the environment according to E. It is just the fact that Log(E) is unsound what allows a significant relation between the agents viewpoints.",
                "This relation is expressed at the type level in terms of constraints by Th(Log(E)) and at the token level by NLog(E). 2.2 Approaching the logic of SSA through communication We have dubbed Log(E) the logic of SSA.",
                "Th(Log(E)) comprehends the most meaningful constraints among agents types according to E. The problem is that neither agent can make use of this theory because they do not know E completely.",
                "In this section, we present a method by which agents obtain approximations to Th(Log(E)).",
                "We also prove these approximations gradually become more reliable as the method is applied.",
                "Agents can obtain approximations to Th(Log(E)) through communication.",
                "A1 and A2 communicate by exchanging information about their perceptions of environment states.",
                "This information is expressed in terms of their own classification relations.",
                "Specifically, if E is in a concrete state e, we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not.",
                "This exchange generates a channel C = {fi : Ai → 1280 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) C}i∈{1,2} and Th(Log(C)) contains the constraints among agents types justified by the fact that agents have observed e. Now, if E turns to another state e and agents proceed as before, another channel C = {fi : Ai → C }i∈{1,2} gives account of the new situation considering also the previous information.",
                "Th(Log(C )) comprises the constraints among agents types justified by the fact that agents have observed e and e .",
                "The significant point is that C is a refinement of C (see appendix A).",
                "Theorem 2.1 below ensures that the refined channel involves more reliable information.",
                "The communication supposedly ends when agents have observed all the environment states.",
                "Again this situation can be modeled by a channel, call it C∗ = {f∗ i : Ai → C∗ }i∈{1,2}.",
                "Theorem 2.2 states that Th(Log(C∗ )) = Th(Log(E)).",
                "Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th(Log(E)) gradually more reliable.",
                "Theorem 2.1.",
                "Let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels.",
                "If C is a refinement of C then: 1.",
                "Th(Log(C )) ⊆ Th(Log(C)) 2.",
                "NLog(C ) ⊇ NLog(C) Proof.",
                "Since C is a refinement of C then there exists a refinement infomorphism r from C to C; so fi = r ◦ fi .",
                "Let A =def A1 + A2, f =def f1 + f2 and f =def f1 + f2. 1.",
                "Let Γ and Δ be subsets of typ(A) and assume that Γ Log(C ) Δ, which means ˆf [Γ] C ˆf [Δ].",
                "We have to prove Γ Log(C) Δ, or equivalently, ˆf[Γ] C ˆf[Δ].",
                "We proceed by reductio ad absurdum.",
                "Suppose c ∈ tok(C) does not satisfy the sequent ˆf[Γ], ˆf[Δ] .",
                "Then c |=C ˆf(γ) for all γ ∈ Γ and c |=C ˆf(δ) for all δ ∈ Δ.",
                "Let us choose an arbitrary γ ∈ Γ.",
                "We have that γ = i, α for some α ∈ typ(Ai) and i ∈ {1, 2}.",
                "Thus ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)).",
                "Therefore: c |=C ˆf(γ) iff c |=C ˆr( ˆfi (α)) iff ˇr(c) |=C ˆfi (α) iff ˇr(c) |=C ˆf ( i, α ) iff ˇr(c) |=C ˆf (γ) Consequently, ˇr(c) |=C ˆf (γ) for all γ ∈ Γ.",
                "Since ˆf [Γ] C ˆf [Δ] then there exists δ∗ ∈ Δ such that ˇr(c) |=C ˆf (δ∗ ).",
                "A sequence of equivalences similar to the above one justifies c |=C ˆf(δ∗ ), contradicting that c is a counterexample to ˆf[Γ], ˆf[Δ] .",
                "Hence Γ Log(C) Δ as we wanted to prove. 2.",
                "Let a1, a2 ∈ tok(A) and assume a1, a2 ∈ NLog(C).",
                "Therefore, there exists c token in C such that a1, a2 = ˇf(c).",
                "Then we have ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), for i ∈ {1, 2}.",
                "Hence a1, a2 = ˇf (ˇr(c)) and a1, a2 ∈ NLog(C ).",
                "Consequently, NLog(C ) ⊇ NLog(C) which concludes the proof.",
                "Remark 2.1.",
                "Theorem 2.1 asserts that the more refined channel gives more reliable information.",
                "Even though its theory has less constraints, it has more normal tokens to which they apply.",
                "In the remainder of the section, we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2.",
                "Let us assume that typ(Ai) is finite for i ∈ {1, 2} and S is infinite numerable, though the finite case can be treated in a similar form.",
                "We also choose an infinite numerable set of symbols {cn | n ∈ N}1 .",
                "We omit informorphisms superscripts when no confusion arises.",
                "Types are usually denoted by greek letters and tokens by latin letters so if f is an infomorphism, f(α) ≡ ˆf(α) and f(a) ≡ ˇf(a).",
                "Agents communication starts from the observation of E. Let us suppose that E is in state e1 ∈ S = tok(E).",
                "A1s perception of e1 is f1(e1 ) and A2s perception of e1 is f2(e1 ).",
                "We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1(e1 ) according to its classification A1.",
                "So can A2 do.",
                "Since both typ(A1) and typ(A2) are finite, this process eventually finishes.",
                "After this communication a channel C1 = {f1 i : Ai → C1 }i=1,2 arises (see Figure 2).",
                "C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figure 2: The first communication stage On the one hand, C1 is defined by: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α if fi(e1 ) |=Ai α (for every i, α ∈ typ(A1 + A2)) On the other hand, f1 i , with i ∈ {1, 2}, is defined by: • f1 i (α) = i, α (for every α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) represents the reasoning about the first stage of communication.",
                "It is easy to prove that Th(Log(C1 )) = Th(C1 ).",
                "The significant point is that both agents know C1 as the result of the communication.",
                "Hence they can compute separately theory Th(C1 ) = typ(C1 ), C1 which contains the constraints among agents types justified by the fact that agents have observed e1 .",
                "Now, let us assume that E turns to a new state e2 .",
                "Agents can proceed as before, exchanging this time information about their perceptions of e2 .",
                "Another channel C2 = {f2 i : Ai → C2 }i∈{1,2} comes up.",
                "We define C2 so as to take also into account the information provided by the previous stage of communication.",
                "On the one hand, C2 is defined by: • tok(C2 ) = {c1 , c2 } 1 We write these symbols with superindices because we limit the use of subindices for what concerns to agents.",
                "Note this set is chosen with the same cardinality of S. The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1281 • typ(C2 ) = typ(A1 + A2) • ck |=C2 i, α if fi(ek ) |=Ai α (for every k ∈ {1, 2} and i, α ∈ typ(A1 + A2)) On the other hand, f2 i , with i ∈ {1, 2}, is defined by: • f2 i (α) = i, α (for every α ∈ typ(Ai)) • f2 i (ck ) = fi(ek ) (for every k ∈ {1, 2}) Log(C2 ) represents the reasoning about the former and the later communication stages.",
                "Th(Log(C2 )) is equal to Th(C2 ) = typ(C2 ), C2 , then it contains the constraints among agents types justified by the fact that agents have observed e1 and e2 .",
                "A1 and A2 knows C2 so they can use these constraints.",
                "The key point is that channel C2 is a refinement of C1 .",
                "It is easy to check that f1 defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism (see at the bottom of Figure 3).",
                "By Theorem 2.1, C2 constraints are more reliable than C1 constraints.",
                "In the general situation, once the states e1 , e2 , . . . , en−1 (n ≥ 2) have been observed and a new state en appears, channel Cn = {fn i : Ai → Cn }i∈{1,2} informs about agents communication up to that moment.",
                "Cn definition is similar to the previous ones and analogous remarks can be made (see at the top of Figure 3).",
                "Theory Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contains the constraints among agents types justified by the fact that agents have observed e1 , e2 , . . . , en .",
                "Cn fn−1 \u0015\u0015 A1 fn−1 1 99PPPPPPPPPPPPP fn 1 UUnnnnnnnnnnnnn f2 1 %%44444444444444444444444444 f1 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, A2 fn 2 ggPPPPPPPPPPPPP fn−1 2 wwnnnnnnnnnnnnn f2 2 ÕÕ              f1 2 ØØ\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012\u0012 Cn−1 \u0015\u0015 . . . \u0015\u0015 C2 f1 \u0015\u0015 C1 Figure 3: Agents communication Remember we have assumed that S is infinite numerable.",
                "It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2.",
                "At that point, the family of channels {Cn }n∈N would inform of all the communication stages.",
                "It is therefore up to the agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks.",
                "But the study of possible termination criteria is outside the scope of this paper and left for future work.",
                "From a theoretical point of view, however, we can consider the channel C∗ = {f∗ i : Ai → C∗ }i∈{1,2} which informs of the end of the communication after observing all environment states.",
                "On the one hand, C∗ is defined by: • tok(C∗ ) = {cn | n ∈ N} • typ(C∗ ) = typ(A1 + A2) • cn |=C∗ i, α if fi(en ) |=Ai α (for n ∈ N and i, α ∈ typ(A1 + A2)) On the other hand, f∗ i , with i ∈ {1, 2}, is defined by: • f∗ i (α) = i, α (for α ∈ typ(Ai)) • f∗ i (cn ) = fi(en ) (for n ∈ N) Theorem below constitutes the cornerstone of the model exposed in this paper.",
                "It ensures, together with Theorem 2.1, that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA.",
                "Theorem 2.2.",
                "The following statements hold: 1.",
                "For all n ∈ N, C∗ is a refinement of Cn . 2.",
                "Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )).",
                "Proof. 1.",
                "It is easy to prove that for each n ∈ N, gn defined as the identity function on types and the inclusion function on tokens is a refinement infomorphism from C∗ to Cn . 2.",
                "The second equality is straightforward; the first one follows directly from: cn |=C∗ i, α iff ˇfi(en ) |=Ai α (by definition of |=C∗ ) iff en |=E ˆfi(α) (because fi is infomorphim) iff en |=E ˆf( i, α ) (by definition of ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ?????????????????",
                "Cn 1282 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "AN EXAMPLE In the previous section we have described in great detail our formal model for SSA.",
                "However, we have not tackled the practical aspect of the model yet.",
                "In this section, we give a brushstroke of the pragmatic view of our approach.",
                "We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication.",
                "Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination (Figure 4).",
                "Robots can carry only one package at a time and they can not move through a package.",
                "Figure 4: The scenario Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have.",
                "Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front (see Figure 5).",
                "We call them URDL (shortened form of Up-Right-Down-Left) and LCR (abbreviation for Left-Center-Right) robots respectively.",
                "Describing the environment states as well as the robots perception functions is rather tedious and even unnecessary.",
                "We assume the reader has all those descriptions in mind.",
                "All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other.",
                "In order to communicate, agents send messages using some ontology.",
                "In our scenario, there coexist two ontologies, the UDRL and LCR ontologies.",
                "Both of them are very simple and are just confined to describe what robots observe.",
                "Figure 5: Robots field of vision When a robot carrying a package finds another package obstructing its way, it can either go around it or, if there is another robot in its visual field, ask it for assistance.",
                "Let us suppose two URDL robots are in a situation like the one depicted in Figure 6.",
                "Robot1 (the one carrying a package) decides to ask Robot2 for assistance and sends a request.",
                "This request is written below as a KQML message and it should be interpreted intuitively as: Robot2, pick up the package located in my Up square, knowing that you are located in my Up-Right square. ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology URDL-ontology :content (pick up U(Package) because UR(Robot2) ´ Figure 6: Robot assistance Robot2 understands the content of the request and it can use a rule represented by the following constraint: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Package) 2, U(Package) The above constraint should be interpreted intuitively as: if Robot2 is situated in Robot1s Up-Right square, Robot1 is situated in Robot2s Up-Left square and a package is located in Robot1s Up square, then a package is located in Robot2s Up square.",
                "Now, problems arise when a LCR robot and a URDL robot try to interoperate.",
                "See Figure 7.",
                "Robot1 sends a request of the form: ` request :sender Robot1 :receiver Robot2 :language Packages distribution-language :ontology LCR-ontology :content (pick up R(Robot2) because C(Package) ´ Robot2 does not understand the content of the request but they decide to begin a process of alignment -corresponding with a channel C1 .",
                "Once finished, Robot2 searches in Th(C1 ) for constraints similar to the expected one, that is, those of the form: 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, λ(Package) where λ ∈ {U, R, D, L, UR, DR, DL, UL}.",
                "From these, only the following constraints are plausible according to C1 : The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1283 Figure 7: Ontology mismatch 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, U(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, L(Package) 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C1 2, DR(Package) If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8, a new process of alignment -corresponding with a channel C2 - takes place.",
                "C2 also considers the previous information and hence refines C1 .",
                "The only constraint from the above ones that remains plausible according to C2 is : 1, R(Robot2) , 2, UL(Robot1) , 1, C(Package) C2 2, U(Package) Notice that this constraint is an element of the theory of the distributed logic.",
                "Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic.",
                "Figure 8: Refinement 4.",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-<br>channel refinement</br>s that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states.",
                "Before us, Kent [6] and Kalfoglou and Schorlemmer [4, 10] have applied Channel Theory to formalise semantic alignment using also Barwise and Seligmans insight to focus on tokens as the enablers of information flow.",
                "Their approach to semantic alignment, however, like most ontology matching mechanisms developed to date (regardless of whether they follow a functional, design-time-based approach, or an interaction-based, runtime-based approach), still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process.",
                "Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities.",
                "In the future, our effort will focus on the practical side of the situated semantic alignment problem.",
                "We plan to further refine the model presented here (e.g., to include pragmatic issues such as termination criteria for the alignment process) and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact.",
                "The formal model exposed in this paper will constitute a solid base of future practical results.",
                "Acknowledgements This work is supported under the UPIC project, sponsored by Spains Ministry of Education and Science under grant number TIN2004-07461-C02- 02 and also under the OpenKnowledge Specific Targeted Research Project (STREP), sponsored by the European Commission under contract number FP6-027253.",
                "Marco Schorlemmer is supported by a Ram´on y Cajal Research Fellowship from Spains Ministry of Education and Science, partially funded by the European Social Fund. 5.",
                "REFERENCES [1] J. Barwise and J. Seligman.",
                "Information Flow: The Logic of Distributed Systems.",
                "Cambridge University Press, 1997. [2] C. Ghidini and F. Giunchiglia.",
                "Local models semantics, or contextual reasoning = locality + compatibility.",
                "Artificial Intelligence, 127(2):221-259, 2001. [3] F. Giunchiglia and P. Shvaiko.",
                "Semantic matching.",
                "The Knowledge Engineering Review, 18(3):265-280, 2004. [4] Y. Kalfoglou and M. Schorlemmer.",
                "IF-Map: An ontology-mapping method based on information-flow theory.",
                "In Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou and M. Schorlemmer.",
                "Ontology mapping: The sate of the art.",
                "The Knowledge Engineering Review, 18(1):1-31, 2003. [6] R. E. Kent.",
                "Semantic integration in the Information Flow Framework.",
                "In Semantic Interoperability and Integration, Dagstuhl Seminar Proceedings 04391, 2005. [7] D. Lenat.",
                "CyC: A large-scale investment in knowledge infrastructure.",
                "Communications of the ACM, 38(11), 1995. [8] V. L´opez, M. Sabou, and E. Motta.",
                "PowerMap: Mapping the real Semantic Web on the fly.",
                "Proceedings of the ISWC06, 2006. [9] F. McNeill.",
                "Dynamic Ontology Refinement.",
                "PhD 1284 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) thesis, School of Informatics, The University of Edinburgh, 2006. [10] M. Schorlemmer and Y. Kalfoglou.",
                "Progressive ontology alignment for meaning coordination: An information-theoretic foundation.",
                "In 4th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2005. [11] P. Shvaiko and J. Euzenat.",
                "A survey of schema-based matching approaches.",
                "In Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels.",
                "The Origins of Ontologies and Communication Conventions in Multi-Agent Systems.",
                "In Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen et al.",
                "ANEMONE: An Effective Minimal Ontology Negotiation Environment In 5th Int.",
                "Joint Conf. on Autonomous Agents and Multiagent Systems, 2006 APPENDIX A.",
                "CHANNEL THEORY TERMS Classification: is a tuple A = tok(A), typ(A), |=A where tok(A) is a set of tokens, typ(A) is a set of types and |=A is a binary relation between tok(A) and typ(A).",
                "If a |=A α then a is said to be of type α. Infomorphism: f : A → B from classifications A to B is a contravariant pair of functions f = ˆf, ˇf , where ˆf : typ(A) → typ(B) and ˇf : tok(B) → tok(A), satisfying the following fundamental property: ˇf(b) |=A α iff b |=B ˆf(α) for each token b ∈ tok(B) and each type α ∈ typ(A).",
                "Channel: consists of two infomorphisms C = {fi : Ai → C}i∈{1,2} with a common codomain C, called the core of C. C tokens are called connections and a connection c is said to connect tokens ˇf1(c) and ˇf2(c).2 Sum: given classifications A and B, the sum of A and B, denoted by A + B, is the classification with tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) and b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 and γ ∈ typ(A) or i = 2 and γ ∈ typ(B)} and relation |=A+B defined by: a, b |=A+B 1, α if a |=A α a, b |=A+B 2, β if b |=B β Given infomorphisms f : A → C and g : B → C, the sum f + g : A + B → C is defined on types by ˆ(f + g)( 1, α ) = ˆf(α) and ˆ(f + g)( 2, β ) = ˆg(β), and on tokens by ˇ(f + g)(c) = ˇf(c), ˇg(c) .",
                "Theory: given a set Σ, a sequent of Σ is a pair Γ, Δ of subsets of Σ.",
                "A binary relation between subsets of Σ is called a consequence relation on Σ.",
                "A theory is a pair T = Σ, where is a consequence relation on Σ.",
                "A sequent Γ, Δ of Σ for which Γ Δ is called a constraint of the theory T. T is regular if it satisfies: 1.",
                "Identity: α α 2.",
                "Weakening: if Γ Δ, then Γ, Γ Δ, Δ 2 In fact, this is the definition of a binary channel.",
                "A channel can be defined with an arbitrary index set. 3.",
                "Global Cut: if Γ, Π0 Δ, Π1 for each partition Π0, Π1 of Π (i.e., Π0 ∪ Π1 = Π and Π0 ∩ Π1 = ∅), then Γ Δ for all α ∈ Σ and all Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Theory generated by a classification: let A be a classification.",
                "A token a ∈ tok(A) satisfies a sequent Γ, Δ of typ(A) provided that if a is of every type in Γ then it is of some type in Δ.",
                "The theory generated by A, denoted by Th(A), is the theory typ(A), A where Γ A Δ if every token in A satisfies Γ, Δ .",
                "Local logic: is a tuple L = tok(L), typ(L), |=L , L , NL where: 1. tok(L), typ(L), |=L is a classification denoted by Cla(L), 2. typ(L), L is a regular theory denoted by Th(L), 3.",
                "NL is a subset of tok(L), called the normal tokens of L, which satisfy all constraints of Th(L).",
                "A local logic L is sound if every token in Cla(L) is normal, that is, NL = tok(L).",
                "L is complete if every sequent of typ(L) satisfied by every normal token is a constraint of Th(L).",
                "Local logic generated by a classification: given a classification A, the local logic generated by A, written Log(A), is the local logic on A (i.e., Cla(Log(A)) = A), with Th(Log(A)) = Th(A) and such that all its tokens are normal, i.e., NLog(A) = tok(A).",
                "Inverse image: given an infomorphism f : A → B and a local logic L on B, the inverse image of L under f, denoted f−1 [L], is the local logic on A such that Γ f−1[L] Δ if ˆf[Γ] L ˆf[Δ] and Nf−1[L] = ˇf[NL ] = {a ∈ tok(A) | a = ˇf(b) for some b ∈ NL }.",
                "Distributed logic: let C = {fi : Ai → C}i∈{1,2} be a channel and L a local logic on its core C, the distributed logic of C generated by L, written DLogC(L), is the inverse image of L under the sum f1 + f2.",
                "Refinement: let C = {fi : Ai → C}i∈{1,2} and C = {fi : Ai → C }i∈{1,2} be two channels with the same component classifications A1 and A2.",
                "A refinement infomorphism from C to C is an infomorphism r : C → C such that for each i ∈ {1, 2}, fi = r ◦fi (i.e., ˆfi = ˆr ◦ ˆfi and ˇfi = ˇfi ◦ˇr).",
                "Channel C is a refinement of C if there exists a refinement infomorphism r from C to C. B.",
                "CHANNEL THEORY THEOREMS Theorem B.1.",
                "The logic generated by a classification is sound and complete.",
                "Furthermore, given a classification A and a logic L on A, L is sound and complete if and only if L = Log(A).",
                "Theorem B.2.",
                "Let L be a logic on a classification B and f : A → B an infomorphism. 1.",
                "If L is complete then f−1 [L] is complete. 2.",
                "If L is sound and ˇf is surjective then f−1 [L] is sound. 3 All theories considered in this paper are regular.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1285"
            ],
            "original_annotated_samples": [
                "In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-<br>channel refinement</br>s in the sense of Barwise and Seligmans theory of information flow [1].",
                "CONCLUSIONS AND FURTHER WORK In this paper we have exposed a formal model of semantic alignment as a sequence of information-<br>channel refinement</br>s that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states."
            ],
            "translated_annotated_samples": [
                "En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de <br>refinamientos de canal de información</br> en el sentido de la teoría del flujo de información de Barwise y Seligman.",
                "CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de <br>refinamientos del canal de información</br> que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados."
            ],
            "translated_text": "Un Modelo Formal para la Alineación Semántica Situada Manuel Atencia Marco Schorlemmer IIIA, Instituto de Investigación en Inteligencia Artificial CSIC, Consejo Superior de Investigaciones Científicas Bellaterra (Barcelona), Cataluña, España {manu, marco}@iiia.csic.es RESUMEN El emparejamiento de ontologías es actualmente una tecnología clave para lograr la alineación semántica de entidades ontológicas utilizadas por aplicaciones basadas en conocimiento, y por lo tanto para permitir su interoperabilidad en entornos distribuidos como sistemas multiagente. La mayoría de los mecanismos de coincidencia de ontologías, sin embargo, asumen que la coincidencia previa a la integración y se basan en la semántica que ha sido codificada a priori en jerarquías de conceptos o fuentes externas. En este documento, presentamos un modelo formal para un procedimiento de alineación semántica que alinea de forma incremental las conceptualizaciones diferentes de dos o más agentes en relación con su percepción respectiva del entorno o dominio en el que están actuando. Por lo tanto, hace explícita la situación en la que se produce el alineamiento en el modelo. Recurremos a la Teoría de Canales para llevar a cabo la formalización. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-coherencia y coordinación, sistemas multiagente; D.2.12 [Ingeniería de Software]: Interoperabilidad-mapeo de datos; I.2.4 [Inteligencia Artificial]: Formalismos y Métodos de Representación del Conocimiento-redes semánticas, sistemas de relaciones. Teoría de Términos Generales 1. INTRODUCCIÓN Una ontología se define comúnmente como una especificación de la conceptualización de un dominio particular. Fija el vocabulario utilizado por los ingenieros del conocimiento para denotar conceptos y sus relaciones, y restringe la interpretación de este vocabulario al significado originalmente pretendido por los ingenieros del conocimiento. Como tal, las ontologías han sido ampliamente adoptadas como una tecnología clave que puede favorecer el intercambio de conocimientos en entornos distribuidos, como sistemas multiagente, bases de datos federadas o la Web Semántica. Pero la proliferación de muchas ontologías diversas causadas por diferentes conceptualizaciones incluso del mismo dominio, y su posterior especificación utilizando terminología variada, ha resaltado la necesidad de técnicas de emparejamiento de ontologías que sean capaces de calcular relaciones semánticas entre entidades de ontologías diseñadas de forma separada. Hasta hace poco, la mayoría de los mecanismos de emparejamiento de ontologías desarrollados hasta ahora han adoptado un enfoque funcional clásico para el problema de la heterogeneidad semántica, en el que el emparejamiento de ontologías se ve como un proceso que toma dos o más ontologías como entrada y produce una alineación semántica de entidades ontológicas como salida. Además, la coincidencia se ha llevado a cabo frecuentemente en el momento del diseño, antes de integrar sistemas basados en el conocimiento o hacer que interoperen. Esto podría haber sido exitoso para dominios claramente delimitados y estables y para sistemas distribuidos cerrados, pero es insostenible e incluso indeseable para el tipo de aplicaciones que actualmente se despliegan en sistemas abiertos. La comunicación entre múltiples agentes, el intercambio de información entre pares y la composición de servicios web son de naturaleza descentralizada, dinámica y abierta, y requieren que la coincidencia de ontologías se realice localmente durante el tiempo de ejecución. Además, en muchas situaciones las ontologías de pares ni siquiera están abiertas para su inspección (por ejemplo, cuando se basan en información confidencial comercial). Ciertamente, existen esfuerzos para emparejar eficientemente entidades ontológicas en tiempo de ejecución, tomando solo aquel fragmento de la ontología que es necesario para la tarea en cuestión [10, 13, 9, 8]. Sin embargo, las técnicas utilizadas por estos sistemas para establecer las relaciones semánticas entre entidades ontológicas, aunque se apliquen en tiempo de ejecución, aún explotan taxonomías de conceptos previamente definidas tal como se representan en las estructuras basadas en grafos de las ontologías a emparejar, utilizan fuentes externas previamente existentes como tesauros (por ejemplo, WordNet) y ontologías de nivel superior (por ejemplo, CyC o SUMO), o recurren a repositorios de conocimiento adicionales o instancias compartidas. Sostenemos que la alineación semántica de la terminología ontológica es en última instancia relativa a la situación particular en la que se lleva a cabo la alineación, y que esta situación debería ser explícita e incorporada en el mecanismo de alineación. Incluso dos agentes con capacidades de conceptualización idénticas, y utilizando exactamente el mismo vocabulario para especificar sus respectivas conceptualizaciones, pueden no lograr interoperar en una situación concreta debido a su percepción diferente del dominio. Imagina una situación en la que dos agentes se enfrentan frente a un tablero de damas. El agente A1 puede conceptualizar una figura en el tablero como situada en el margen izquierdo del tablero, mientras que el agente A2 puede conceptualizar la misma figura como situada en el margen derecho. Aunque la conceptualización de izquierda y derecha se realice de la misma manera por ambos agentes, y aunque ambos utilicen los términos izquierda y derecha en su comunicación, aún necesitarán alinear sus respectivos vocabularios si desean comunicarse con éxito acciones que cambien la posición de las figuras en el tablero de damas. Su alineación semántica, sin embargo, solo será válida en el ámbito de su interacción dentro de esta situación o entorno particular. Los mismos agentes situados de manera diferente pueden producir una alineación diferente. Este escenario es reminiscente de aquellos en los que un grupo de agentes distribuidos se adaptan para formar una ontología y un léxico compartido de manera emergente y descentralizada, con solo interacciones locales y sin autoridad de control central [12]. Este tipo de emergencia autoorganizada de significado compartido se basa en última instancia en la interacción física de los agentes con el entorno. En este artículo, sin embargo, abordamos el caso en el que los agentes ya están dotados de una ontología diseñada de arriba hacia abajo (incluso puede ser la misma), la cual no adaptan ni refinan, pero para la cual desean encontrar las relaciones semánticas con ontologías separadas de otros agentes en función de su comunicación dentro de una situación específica. En particular, proporcionamos un modelo formal que formaliza el alineamiento semántico situado como una secuencia de <br>refinamientos de canal de información</br> en el sentido de la teoría del flujo de información de Barwise y Seligman. Esta teoría es particularmente útil para nuestro empeño porque modela el flujo de información que ocurre en sistemas distribuidos debido a las situaciones particulares -o tokens- que llevan información. Análogamente, la alineación semántica que permitirá que la información fluya finalmente será llevada por la situación particular en la que los agentes están actuando. Por lo tanto, consideraremos un escenario con dos o más agentes situados en un entorno. Cada agente tendrá su propio punto de vista del entorno, de modo que, si el entorno se encuentra en un estado concreto, ambos agentes pueden tener percepciones diferentes de este estado. Debido a estas diferencias, puede haber una discrepancia en el significado de las entidades sintácticas con las que los agentes describen sus percepciones (y que constituyen las respectivas ontologías de los agentes). Sostenemos que estas entidades sintácticas pueden estar relacionadas de acuerdo con la semántica intrínseca proporcionada por la relación existente entre el punto de vista de los agentes del entorno. La existencia de esta relación está justificada precisamente por el hecho de que los agentes están situados y observan el mismo entorno. En la Sección 2 describimos nuestro modelo formal para el Alineamiento Semántico Situado (SSA). Primero, en la Sección 2.1 asociamos un canal al escenario bajo consideración y mostramos cómo la lógica distribuida generada por este canal proporciona las relaciones lógicas entre los puntos de vista de los agentes del entorno. En segundo lugar, en la Sección 2.2 presentamos un método mediante el cual los agentes obtienen aproximaciones de esta lógica distribuida. Estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. En la Sección 3 informamos sobre una aplicación de nuestro método. Las conclusiones y trabajos futuros se analizan en la Sección 4. Finalmente, un apéndice resume los términos y teoremas de la teoría de Canales utilizados a lo largo del documento. No asumimos ningún conocimiento de la Teoría de Canales; reiteramos definiciones básicas y teoremas en el apéndice, pero cualquier exposición detallada de la teoría está fuera del alcance de este documento. 2. Un modelo formal para SSA 2.1 La lógica de SSA Considere un escenario con dos agentes A1 y A2 situados en un entorno E (la generalización a cualquier conjunto numerable de agentes es directa). Asociamos un conjunto numerable S de estados a E y, en cualquier instante dado, suponemos que E se encuentra en uno de estos estados. Suponemos además que cada agente es capaz de observar el entorno y tiene su propia percepción de él. Esta habilidad es capturada fielmente por una función sobreyectiva seei: S → Pi, donde i ∈ {1, 2}, y típicamente see1 y see2 son diferentes. Según la Teoría del Canal, la información solo es viable donde existe una forma sistemática de clasificar cierto rango de cosas como siendo de una manera u otra, en otras palabras, donde hay una clasificación (ver apéndice A). Por lo tanto, para estar dentro del marco de la Teoría de Canales, debemos asociar clasificaciones a los componentes de nuestro sistema. Para cada i ∈ {1, 2}, consideramos una clasificación Ai que modela el punto de vista de Ai sobre E. Primero, tok(Ai) está compuesto por las percepciones de Ai sobre los estados de E, es decir, tok(Ai) = Pi. Segundo, typ(Ai) contiene las entidades sintácticas mediante las cuales Ai describe sus percepciones, las que constituyen la ontología de Ai. Finalmente, |=Ai sintetiza cómo Ai relaciona sus percepciones con estas entidades sintácticas. Ahora, con el objetivo de asociar el entorno E con una clasificación E, elegimos la clasificación de potencia de S como E, que es la clasificación cuyo conjunto de tipos es igual a 2S, cuyos tokens son los elementos de S, y para la cual un token e es de tipo ε si e ∈ ε. La razón para tomar la clasificación de poder es porque no hay entidades sintácticas que puedan desempeñar el papel de tipos para E, ya que, en general, no hay una conceptualización global del entorno. Sin embargo, el conjunto de tipos de la clasificación de potencia incluye todas las posibles configuraciones de tokens potencialmente descritas por tipos. Por lo tanto, tok(E) = S, typ(E) = 2S y e |=E ε si y solo si e ∈ ε. La noción de canal (ver apéndice A) es fundamental en la teoría de Barwise y Seligman. El flujo de información entre los componentes de un sistema distribuido se modela en términos de un canal y las relaciones entre estos componentes se expresan a través de infomorfismos (ver apéndice A) que proporcionan una forma de mover información entre ellos. El flujo de información del escenario bajo consideración está descrito con precisión por el canal E = {fi : Ai → E}i∈{1,2} definido de la siguiente manera: • ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada α ∈ typ(Ai) • ˇfi(e) = seei(e) para cada e ∈ tok(E) donde i ∈ {1, 2}. La definición de ˇfi parece natural mientras que ˆfi se define de tal manera que se cumple la propiedad fundamental de los infomorfismos: ˇfi(e) |=Ai α si y solo si seei(e) |=Ai α (por definición de ˇfi) si y solo si e ∈ ˆfi(α) (por definición de ˆfi) si y solo si e |=E ˆfi(α) (por definición de |=E) El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1279. Por consiguiente, E es el núcleo del canal E y un estado e ∈ tok(E) conecta las percepciones de los agentes ˇf1(e) y ˇf2(e) (ver Figura 1). typ(E) typ(A1) ˆf1 99ttttttttt typ(A2) ˆf2 eeJJJJJJJJJ tok(E) |=E \u001f \u001f \u001f \u001f \u001f \u001f \u001f ˇf1yyttttttttt ˇf2 %%JJJJJJJJJ tok(A1) |=A1 \u001f \u001f \u001f \u001f \u001f \u001f \u001f tok(A2) |=A2 \u001f \u001f \u001f \u001f \u001f \u001f \u001f Figura 1: Canal E E explica el flujo de información de nuestro escenario debido a que los agentes A1 y A2 están situados y perciben el mismo entorno E. Queremos obtener relaciones significativas entre las entidades sintácticas de los agentes, es decir, los tipos de agentes. Declaramos que la significatividad debe estar en concordancia con E. La operación de suma (ver apéndice A) nos brinda una forma de combinar las clasificaciones de los dos agentes del canal E en una sola clasificación, es decir, A1 + A2, y también de combinar las dos infomorfismos en un solo infomorfismo, f1 + f2: A1 + A2 → E. A1 + A2 ensambla las clasificaciones de los agentes de una manera muy general. tok(A1 + A2) es el producto cartesiano de tok(A1) y tok(A2), es decir, tok(A1 + A2) = {p1, p2 | pi ∈ Pi}, por lo que un token de A1 + A2 es un par de percepciones de agentes sin restricciones. typ(A1 + A2) es la unión disjunta de typ(A1) y typ(A2), y p1, p2 es de tipo i, α si pi es de tipo α. Damos importancia a tomar la unión disjunta porque A1 y A2 podrían usar tipos idénticos con el propósito de describir sus respectivas percepciones de E. La clasificación A1 + A2 parece ser el lugar natural en el que buscar relaciones entre los tipos de agentes. Ahora, la Teoría de Canales proporciona una forma de hacer explícitas todas estas relaciones de manera lógica mediante teorías y lógicas locales (ver apéndice A). La teoría generada por la clasificación de la suma, Th(A1 + A2), y por ende su lógica generada, Log(A1 + A2), involucran todas aquellas restricciones entre los tipos de agentes válidos de acuerdo a A1 + A2. Sin embargo, hay que tener en cuenta que estas restricciones son obvias. Como hemos indicado anteriormente, la significatividad debe estar en concordancia con el canal E. Las clasificaciones A1 + A2 y E están conectadas a través del sum infomorfismo, f = f1 + f2, donde: • ˆf( i, α ) = ˆfi(α) = {e ∈ tok(E) | seei(e) |=Ai α} para cada i, α ∈ typ(A1 + A2) • ˇf(e) = ˇf1(e), ˇf2(e) = see1(e), see2(e) para cada e ∈ tok(E) Las restricciones significativas entre los tipos de agentes están en concordancia con el canal E porque se calculan utilizando f como explicamos a continuación. Tan importante como la noción de canal es el concepto de lógica distribuida (ver apéndice A). Dada un canal C y una lógica L en su núcleo, DLogC(L) representa el razonamiento sobre las relaciones entre los componentes de C justificado por L. Si L = Log(C), la lógica distribuida, denotada por Log(C), captura de manera lógica el flujo de información inherente en el canal. En nuestro caso, Log(E) explica la relación entre los puntos de vista de los agentes del entorno de manera lógica. Por un lado, las restricciones de Th(Log(E)) están definidas por: Γ Log(E) Δ si ˆf[Γ] Log(E) ˆf[Δ] (1) donde Γ, Δ ⊆ typ(A1 + A2). Por otro lado, el conjunto de tokens normales, NLog(E), es igual al rango de la función ˇf: NLog(E) = ˇf[tok(E)] = { see1(e), see2(e) | e ∈ tok(E)} Por lo tanto, un token normal es un par de percepciones de agentes que están restringidas por provenir del mismo estado del entorno (a diferencia de los tokens A1 + A2). Todos los límites de Th(Log(E)) son cumplidos por todos los tokens normales (debido a ser una lógica). En este caso particular, esta condición también es suficiente (la demostración es directa); como alternativa a (1) tenemos: Γ Log(E) Δ si y solo si para todo e ∈ tok(E), si (∀ i, γ ∈ Γ)[seei(e) |=Ai γ] entonces (∃ j, δ ∈ Δ)[seej(e) |=Aj δ] (2) donde Γ, Δ ⊆ typ(A1 + A2). Log(E) es la lógica de SSA. El Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes de acuerdo con el canal E. En otras palabras, la lógica de SSA contiene y también justifica las relaciones más significativas entre esas entidades sintácticas que los agentes utilizan para describir sus propias percepciones del entorno. Log(E) es completo ya que Log(E) es completo, pero no necesariamente es válido porque aunque Log(E) es válido, ˇf no es sobreyectiva en general (ver apéndice B). Si Log(E) también es válido, entonces Log(E) = Log(A1 + A2) (ver apéndice B). Eso significa que no hay una relación significativa entre los puntos de vista de los agentes sobre el entorno según E. Es simplemente el hecho de que Log(E) sea insostenible lo que permite una relación significativa entre los puntos de vista de los agentes. Esta relación se expresa a nivel de tipo en términos de restricciones por Th(Log(E)) y a nivel de token por NLog(E). 2.2 Acercándonos a la lógica de la SSA a través de la comunicación. Hemos denominado Log(E) a la lógica de la SSA. Th(Log(E)) comprende las restricciones más significativas entre los tipos de agentes según E. El problema es que ninguno de los agentes puede hacer uso de esta teoría porque no conocen E completamente. En esta sección, presentamos un método mediante el cual los agentes obtienen aproximaciones a Th(Log(E)). También demostramos que estas aproximaciones se vuelven gradualmente más confiables a medida que se aplica el método. Los agentes pueden obtener aproximaciones a Th(Log(E)) a través de la comunicación. A1 y A2 se comunican intercambiando información sobre sus percepciones de los estados del entorno. Esta información se expresa en términos de sus propias relaciones de clasificación. Específicamente, si E se encuentra en un estado concreto e, asumimos que los agentes pueden comunicarse entre sí qué tipos son satisfechos por sus respectivas percepciones de e y cuáles no lo son. Este intercambio genera un canal C = {fi : Ai → 1280 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) C}i∈{1,2} y Th(Log(C)) contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e. Ahora, si E cambia a otro estado e y los agentes proceden como antes, otro canal C = {fi : Ai → C }i∈{1,2} da cuenta de la nueva situación considerando también la información previa. Th(Log(C )) comprende las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e y e . El punto significativo es que C es un refinamiento de C (ver apéndice A). El Teorema 2.1 a continuación asegura que el canal refinado implica información más confiable. La comunicación supuestamente termina cuando los agentes han observado todos los estados del entorno. Nuevamente esta situación puede ser modelada por un canal, llámelo C∗ = {f∗ i : Ai → C∗ }i∈{1,2}. El teorema 2.2 establece que Th(Log(C∗ )) = Th(Log(E)). El Teorema 2.1 y el Teorema 2.2 aseguran que aplicando el método, los agentes pueden obtener aproximaciones a Th(Log(E)) gradualmente más confiables. Teorema 2.1. Sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales. Si C es un refinamiento de C entonces: 1. Th(Log(C )) ⊆ Th(Log(C)) 2.\nLa traducción al español es: Th(Log(C )) ⊆ Th(Log(C)) 2. NLog(C ) ⊇ NLog(C) Prueba. Dado que C es un refinamiento de C, entonces existe un refinamiento infomorfismo r de C a C; por lo tanto, fi = r ◦ fi. Sea A =def A1 + A2, f =def f1 + f2 y f =def f1 + f2. 1. Sean Γ y Δ subconjuntos de typ(A) y supongamos que Γ Log(C) Δ, lo cual significa que ˆf [Γ] ⊂ ˆf [Δ]. Tenemos que demostrar Γ Log(C) Δ, o equivalentemente, ˆf[Γ] C ˆf[Δ]. Procedemos por reducción al absurdo. Supongamos que c ∈ tok(C) no satisface el secuente ˆf[Γ], ˆf[Δ]. Entonces c |=C ˆf(γ) para todo γ ∈ Γ y c |=C ˆf(δ) para todo δ ∈ Δ. Elijamos un γ arbitrario ∈ Γ. Tenemos que γ = i, α para algún α ∈ typ(Ai) e i ∈ {1, 2}. Por lo tanto ˆf(γ) = ˆf( i, α ) = ˆfi(α) = ˆr ◦ ˆfi (α) = ˆr( ˆfi (α)). Por lo tanto: c |=C ˆf(γ) si y solo si c |=C ˆr( ˆfi (α)) si y solo si ˇr(c) |=C ˆfi (α) si y solo si ˇr(c) |=C ˆf ( i, α ) si y solo si ˇr(c) |=C ˆf (γ). En consecuencia, ˇr(c) |=C ˆf (γ) para todo γ ∈ Γ. Dado que ˆf [Γ] ⊂ ˆf [Δ], entonces existe δ∗ ∈ Δ tal que ˇr(c) |=C ˆf (δ∗ ). Una secuencia de equivalencias similar a la anterior justifica que c |=C ˆf(δ∗), contradiciendo que c sea un contraejemplo para ˆf[Γ], ˆf[Δ]. Por lo tanto, Γ Log(C) Δ como queríamos demostrar. 2. Permita que a1, a2 ∈ tok(A) y suponga que a1, a2 ∈ NLog(C). Por lo tanto, existe un token c en C tal que a1, a2 = ˇf(c). Entonces tenemos ai = ˇfi(c) = ˇfi ◦ ˇr(c) = ˇfi (ˇr(c)), para i ∈ {1, 2}. Por lo tanto, a1, a2 = ˇf (ˇr(c)) y a1, a2 ∈ NLog(C). Por consiguiente, NLog(C) ⊇ NLog(C), lo que concluye la prueba. Observación 2.1. El Teorema 2.1 afirma que el canal más refinado proporciona información más confiable. Aunque su teoría tiene menos restricciones, tiene más tokens normales a los que se aplica. En el resto de la sección, describimos explícitamente el proceso de comunicación y concluimos con la prueba del Teorema 2.2. Supongamos que typ(Ai) es finito para i ∈ {1, 2} y S es numerable infinito, aunque el caso finito se puede tratar de forma similar. También elegimos un conjunto numerable infinito de símbolos {cn | n ∈ N}. Omitimos los superíndices de los informorfismos cuando no surge confusión. Los tipos suelen ser representados por letras griegas y los tokens por letras latinas, por lo que si f es un infomorfismo, f(α) ≡ ˆf(α) y f(a) ≡ ˇf(a). La comunicación de los agentes comienza a partir de la observación de E. Supongamos que E se encuentra en el estado e1 ∈ S = tok(E). La percepción de A1 de e1 es f1(e1) y la percepción de A2 de e1 es f2(e1). Damos por sentado que A1 puede comunicar a A2 aquellos tipos que están y no están satisfechos por f1(e1) según su clasificación A1. Así puede hacer A2. Dado que tanto typ(A1) como typ(A2) son finitos, este proceso eventualmente termina. Después de esta comunicación surge un canal C1 = {f1 i : Ai → C1 }i=1,2 (ver Figura 2). C1 A1 f1 1 ==|||||||| A2 f1 2 aaCCCCCCCC Figura 2: La primera etapa de comunicación Por un lado, C1 está definido por: • tok(C1 ) = {c1 } • typ(C1 ) = typ(A1 + A2) • c1 |=C1 i, α si fi(e1 ) |=Ai α (para todo i, α ∈ typ(A1 + A2)) Por otro lado, f1 i , con i ∈ {1, 2}, está definido por: • f1 i (α) = i, α (para todo α ∈ typ(Ai)) • f1 i (c1 ) = fi(e1 ) Log(C1 ) representa el razonamiento sobre la primera etapa de comunicación. Es fácil demostrar que Th(Log(C1)) = Th(C1). El punto significativo es que ambos agentes conocen C1 como resultado de la comunicación. Por lo tanto, pueden calcular por separado la teoría Th(C1) = typ(C1), C1 que contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1. Ahora, supongamos que E cambia a un nuevo estado e2. Los agentes pueden proceder como antes, intercambiando esta vez información sobre sus percepciones de e2. Aparece otro canal C2 = {f2 i : Ai → C2 }i∈{1,2}. Definimos C2 de manera que también tenga en cuenta la información proporcionada por la etapa previa de comunicación. Por un lado, C2 está definido por: • tok(C2) = {c1, c2} Escribimos estos símbolos con superíndices porque limitamos el uso de subíndices en lo que respecta a los agentes. Ten en cuenta que este conjunto se elige con la misma cardinalidad que S. El Sexto Congreso Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1281 • typ(C2) = typ(A1 + A2) • ck |=C2 i, α si fi(ek) |=Ai α (para todo k ∈ {1, 2} e i, α ∈ typ(A1 + A2)) Por otro lado, f2 i, con i ∈ {1, 2}, está definido por: • f2 i (α) = i, α (para todo α ∈ typ(Ai)) • f2 i (ck) = fi(ek) (para todo k ∈ {1, 2}) Log(C2) representa el razonamiento sobre las etapas de comunicación anteriores y posteriores. Th(Log(C2)) es igual a Th(C2) = typ(C2), C2, entonces contiene las restricciones entre los tipos de agentes justificadas por el hecho de que los agentes han observado e1 y e2. A1 y A2 conocen C2, por lo que pueden usar estas restricciones. El punto clave es que el canal C2 es un refinamiento de C1. Es fácil comprobar que f1, definida como la función identidad en tipos y la función de inclusión en tokens, es un infomorfismo de refinamiento (ver en la parte inferior de la Figura 3). Según el Teorema 2.1, las restricciones C2 son más confiables que las restricciones C1. En la situación general, una vez que los estados e1, e2, ..., en−1 (n ≥ 2) han sido observados y aparece un nuevo estado en, el canal Cn = {fn i : Ai → Cn }i∈{1,2} informa sobre la comunicación de los agentes hasta ese momento. La definición de Cn es similar a las anteriores y se pueden hacer observaciones análogas (ver en la parte superior de la Figura 3). La teoría Th(Log(Cn )) = Th(Cn ) = typ(Cn ), Cn contiene las restricciones entre los tipos de agentes justificados por el hecho de que los agentes han observado e1 , e2 , . . . , en. Recuerda que hemos asumido que S es infinitamente numerable. Por lo tanto, no es práctico permitir que la comunicación termine cuando todos los estados del entorno han sido observados por A1 y A2. En ese punto, la familia de canales {Cn}n∈N informaría de todas las etapas de comunicación. Por lo tanto, corresponde a los agentes decidir cuándo dejar de comunicarse si se ha alcanzado una aproximación lo suficientemente buena para los propósitos de sus respectivas tareas. Pero el estudio de posibles criterios de terminación está fuera del alcance de este documento y se deja para trabajos futuros. Desde un punto de vista teórico, sin embargo, podemos considerar el canal C∗ = {f∗ i : Ai → C∗ }i∈{1,2} que informa del final de la comunicación después de observar todos los estados del entorno. Por un lado, C∗ está definido por: • tok(C∗) = {cn | n ∈ N} • typ(C∗) = typ(A1 + A2) • cn |=C∗ i, α si fi(en) |=Ai α (para n ∈ N e i, α ∈ typ(A1 + A2)) Por otro lado, f∗ i, con i ∈ {1, 2}, está definido por: • f∗ i (α) = i, α (para α ∈ typ(Ai)) • f∗ i (cn) = fi(en) (para n ∈ N) El teorema a continuación constituye la piedra angular del modelo expuesto en este documento. Junto con el Teorema 2.1, se asegura que en cada etapa de comunicación los agentes obtengan una teoría que se aproxime más ala teoría generada por la lógica de SSA. Teorema 2.2. Las siguientes afirmaciones son válidas: 1. Para todo n ∈ N, C∗ es un refinamiento de Cn. 2. Th(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). \n\nTh(Log(E)) = Th(C∗ ) = Th(Log(C∗ )). Prueba. 1. Es fácil demostrar que para cada n ∈ N, gn definido como la función identidad en tipos y la función de inclusión en tokens es un infomorfismo de refinamiento de C∗ a Cn. 2. La segunda igualdad es directa; la primera sigue directamente de: cn |=C∗ i, α si y solo si ˇfi(en ) |=Ai α (por definición de |=C∗ ) si y solo si en |=E ˆfi(α) (porque fi es un infomorfismo) si y solo si en |=E ˆf( i, α ) (por definición de ˆf) E C∗ gn \u0015\u0015 A1 fn 1 99OOOOOOOOOOOOO f∗ 1 UUooooooooooooo f1 cc A2 f∗ 2 ggOOOOOOOOOOOOO fn 2 wwooooooooooooo f2 ????????????????? Cn 1282 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. En el apartado anterior hemos descrito con gran detalle nuestro modelo formal para SSA. Sin embargo, aún no hemos abordado el aspecto práctico del modelo. En esta sección, damos un breve resumen de la visión pragmática de nuestro enfoque. Estudiamos un ejemplo muy simple y explicamos cómo los agentes pueden utilizar esas aproximaciones de la lógica de SSA que pueden obtener a través de la comunicación. Reflexionemos sobre un sistema que consiste en robots ubicados en una cuadrícula bidimensional en busca de paquetes con el objetivo de moverlos a un destino específico (Figura 4). Los robots solo pueden transportar un paquete a la vez y no pueden moverse a través de un paquete. Figura 4: El escenario Robots tienen una vista parcial del dominio y existen dos tipos de robots según el campo visual que poseen. Algunos robots son capaces de observar los ocho cuadrados adyacentes, pero otros solo observan los tres cuadrados que tienen delante (ver Figura 5). Los llamamos robots URDL (forma abreviada de Arriba-Derecha-Abajo-Izquierda) y LCR (abreviatura de Izquierda-Centro-Derecha) respectivamente. Describir los estados del entorno y las funciones de percepción de los robots es bastante tedioso e incluso innecesario. Suponemos que el lector tiene todas esas descripciones en mente. Todos los robots en el sistema deben ser capaces de resolver problemas de distribución de paquetes de forma cooperativa comunicando sus intenciones entre sí. Para comunicarse, los agentes envían mensajes utilizando alguna ontología. En nuestro escenario, coexisten dos ontologías, las ontologías UDRL y LCR. Ambos son muy simples y se limitan a describir lo que los robots observan. Figura 5: Campo de visión de los robots. Cuando un robot que lleva un paquete encuentra otro paquete obstruyendo su camino, puede rodearlo o, si hay otro robot en su campo visual, pedirle ayuda. Supongamos que dos robots URDL se encuentran en una situación como la que se muestra en la Figura 6. El Robot1 (el que lleva un paquete) decide pedir ayuda al Robot2 y envía una solicitud. Esta solicitud está escrita a continuación como un mensaje KQML y debe interpretarse intuitivamente como: Robot2, recoge el paquete ubicado en mi cuadrado de Arriba, sabiendo que estás ubicado en mi cuadrado de Arriba-Derecha. ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología URDL :contenido (recoger U(Paquete) porque UR(Robot2) ´ Figura 6: Asistencia de robot Robot2 entiende el contenido de la solicitud y puede usar una regla representada por la siguiente restricción: 1, UR(Robot2) , 2, UL(Robot1) , 1, U(Paquete) 2, U(Paquete) La restricción anterior debe interpretarse intuitivamente como: si Robot2 está situado en el cuadrado de Arriba-Derecha de Robot1, Robot1 está situado en el cuadrado de Arriba-Izquierda de Robot2 y un paquete está ubicado en el cuadrado de Arriba de Robot1, entonces un paquete está ubicado en el cuadrado de Arriba de Robot2. Ahora, surgen problemas cuando un robot LCR y un robot URDL intentan interoperar. Ver la Figura 7. El Robot1 envía una solicitud en la forma: ` solicitud :emisor Robot1 :receptor Robot2 :idioma Distribución de paquetes :ontología Ontología LCR :contenido (recoger R(Robot2) porque C(Paquete) ´ Robot2 no entiende el contenido de la solicitud pero deciden comenzar un proceso de alineación -correspondiente con un canal C1. Una vez finalizado, Robot2 busca en Th(C1) restricciones similares a la esperada, es decir, aquellas de la forma: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C1 2, λ(Package) donde λ ∈ {U, R, D, L, UR, DR, DL, UL}. De estos, solo las siguientes restricciones son plausibles según C1: El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1283 Figura 7: Desajuste de ontología 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, U(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, L(Paquete) 1, R(Robot2), 2, UL(Robot1), 1, C(Paquete) C1 2, DR(Paquete) Si posteriormente ambos robots que adoptan los mismos roles participan en una situación como la que se muestra en la Figura 8, se lleva a cabo un nuevo proceso de alineación, correspondiente a un canal C2. C2 también considera la información previa y, por lo tanto, perfecciona C1. La única restricción de las anteriores que sigue siendo plausible según C2 es: 1, R(Robot2), 2, UL(Robot1), 1, C(Package) C2 2, U(Package). Nótese que esta restricción es un elemento de la teoría de la lógica distribuida. Los agentes se comunican para cooperar con éxito y el éxito está garantizado utilizando restricciones de la lógica distribuida. Figura 8: Refinamiento 4. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo hemos expuesto un modelo formal de alineación semántica como una secuencia de <br>refinamientos del canal de información</br> que son relativos a los estados particulares del entorno en el que dos agentes se comunican y alinean sus respectivas conceptualizaciones de estos estados. Antes que nosotros, Kent [6] y Kalfoglou y Schorlemmer [4, 10] han aplicado la Teoría del Canal para formalizar la alineación semántica utilizando también la perspicacia de Barwise y Seligman para centrarse en los tokens como los facilitadores del flujo de información. Su enfoque para la alineación semántica, sin embargo, al igual que la mayoría de los mecanismos de coincidencia de ontologías desarrollados hasta la fecha (independientemente de si siguen un enfoque funcional basado en el diseño temporal o un enfoque basado en la interacción en tiempo de ejecución), aún define la alineación semántica en términos de decisiones de diseño a priori, como la taxonomía de conceptos de las ontologías o las fuentes externas incorporadas en el proceso de alineación. En cambio, el modelo que hemos presentado en este artículo hace explícitas las condiciones particulares del entorno en el que se encuentran los agentes y están intentando alinear gradualmente sus entidades ontológicas. En el futuro, nuestro esfuerzo se centrará en el lado práctico del problema de alineación semántica situada. Planeamos refinar aún más el modelo presentado aquí (por ejemplo, para incluir cuestiones pragmáticas como criterios de terminación para el proceso de alineación) y diseñar protocolos concretos de negociación de ontologías basados en este modelo que los agentes puedan llevar a cabo. El modelo formal expuesto en este documento constituirá una base sólida para futuros resultados prácticos. Agradecimientos Este trabajo ha sido apoyado en el marco del proyecto UPIC, patrocinado por el Ministerio de Educación y Ciencia de España bajo el número de subvención TIN2004-07461-C02-02 y también en el marco del Proyecto de Investigación Específica y Dirigida OpenKnowledge (STREP), patrocinado por la Comisión Europea bajo el número de contrato FP6-027253. Marco Schorlemmer cuenta con una Beca de Investigación Ramón y Cajal del Ministerio de Educación y Ciencia de España, parcialmente financiada por el Fondo Social Europeo. REFERENCIAS [1] J. Barwise y J. Seligman. Flujo de información: La lógica de los sistemas distribuidos. Cambridge University Press, 1997. [2] C. Ghidini y F. Giunchiglia. La semántica de modelos locales, o razonamiento contextual = localidad + compatibilidad. Inteligencia Artificial, 127(2):221-259, 2001. [3] F. Giunchiglia y P. Shvaiko. Coincidencia semántica. La revisión de Ingeniería del Conocimiento, 18(3):265-280, 2004. [4] Y. Kalfoglou y M. Schorlemmer. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, LNCS 2800, 2003. [5] Y. Kalfoglou y M. Schorlemmer. Mapeo de ontologías: El estado del arte. La Revisión de Ingeniería del Conocimiento, 18(1):1-31, 2003. [6] R. E. Kent. Integración semántica en el Marco de Flujo de Información. En Interoperabilidad Semántica e Integración, Actas del Seminario de Dagstuhl 04391, 2005. [7] D. Lenat. CyC: Una inversión a gran escala en infraestructura de conocimiento. Comunicaciones de la ACM, 38(11), 1995. [8] V. López, M. Sabou y E. Motta. PowerMap: Mapeando la verdadera Web Semántica sobre la marcha. Actas de la ISWC06, 2006. [9] F. McNeill. Refinamiento de Ontología Dinámica. PhD 1284 La Sexta Internacional. Tesis de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), Escuela de Informática, Universidad de Edimburgo, 2006. [10] M. Schorlemmer y Y. Kalfoglou. Alineación ontológica progresiva para la coordinación de significados: Una base teórica de la información. En la 4ta Int. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2005. [11] P. Shvaiko y J. Euzenat. Una encuesta de enfoques de coincidencia basados en esquemas. En el Journal on Data Semantics IV, LNCS 3730, 2005. [12] L. Steels. Los Orígenes de las Ontologías y Convenciones de Comunicación en Sistemas Multiagente. En Journal of Autonomous Agents and Multi-Agent Systems, 1(2), 169-194, 1998. [13] J. van Diggelen y otros. ANEMONE: Un Entorno de Negociación de Ontologías Mínimas Efectivo en la 5ª Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente, 2006 APÉNDICE A. Términos de la teoría de canales Clasificación: es una tupla A = tok(A), typ(A), |=A donde tok(A) es un conjunto de tokens, typ(A) es un conjunto de tipos y |=A es una relación binaria entre tok(A) y typ(A). Si a |=A α entonces se dice que a es de tipo α. Infomorfismo: f : A → B de clasificaciones A a B es un par covariante de funciones f = ˆf, ˇf, donde ˆf : typ(A) → typ(B) y ˇf : tok(B) → tok(A), satisfaciendo la siguiente propiedad fundamental: ˇf(b) |=A α si y solo si b |=B ˆf(α) para cada token b ∈ tok(B) y cada tipo α ∈ typ(A). Canal: consiste en dos infomorfismos C = {fi : Ai → C}i∈{1,2} con un codominio común C, llamado núcleo de C. Los tokens de C se llaman conexiones y se dice que una conexión c conecta los tokens ˇf1(c) y ˇf2(c). Suma: dadas las clasificaciones A y B, la suma de A y B, denotada por A + B, es la clasificación con tok(A + B) = tok(A) × tok(B) = { a, b | a ∈ tok(A) y b ∈ tok(B)}, typ(A + B) = typ(A) typ(B) = { i, γ | i = 1 y γ ∈ typ(A) o i = 2 y γ ∈ typ(B)} y la relación |=A+B definida por: a, b |=A+B 1, α si a |=A α a, b |=A+B 2, β si b |=B β Dados los infomorfismos f : A → C y g : B → C, la suma f + g : A + B → C está definida en los tipos por ˆ(f + g)( 1, α ) = ˆf(α) y ˆ(f + g)( 2, β ) = ˆg(β), y en los tokens por ˇ(f + g)(c) = ˇf(c), ˇg(c) . Teoría: dado un conjunto Σ, un secuente de Σ es un par Γ, Δ de subconjuntos de Σ. Una relación binaria entre subconjuntos de Σ se llama una relación de consecuencia en Σ. Una teoría es un par T = Σ, donde es una relación de consecuencia en Σ. Un secuente Γ, Δ de Σ para el cual Γ Δ es llamado una restricción de la teoría T. T es regular si cumple: 1. Identidad: α α 2. Debilitamiento: si Γ Δ, entonces Γ, Γ Δ, Δ 2 De hecho, esta es la definición de un canal binario. Un canal se puede definir con un conjunto de índices arbitrario. Corte global: si Γ, Π0 Δ, Π1 para cada partición Π0, Π1 de Π (es decir, Π0 ∪ Π1 = Π y Π0 ∩ Π1 = ∅), entonces Γ Δ para todo α ∈ Σ y todo Γ, Γ , Δ, Δ , Π ⊆ Σ.3 Teoría generada por una clasificación: sea A una clasificación. Un token a ∈ tok(A) satisface un secuente Γ, Δ de typ(A) siempre que si a es de cada tipo en Γ entonces es de algún tipo en Δ. La teoría generada por A, denotada por Th(A), es la teoría typ(A), A donde Γ A Δ si cada token en A satisface Γ, Δ. Lógica local: es una tupla L = tok(L), typ(L), |=L , L , NL donde: 1. tok(L), typ(L), |=L es una clasificación denotada por Cla(L), 2. typ(L), L es una teoría regular denotada por Th(L), 3. NL es un subconjunto de tok(L), llamado los tokens normales de L, que cumplen con todas las restricciones de Th(L). Una lógica local L es válida si cada ficha en Cla(L) es normal, es decir, NL = tok(L). L es completo si cada secuencia de tipo(L) satisfecha por cada token normal es una restricción de Th(L). Lógica local generada por una clasificación: dada una clasificación A, la lógica local generada por A, escrita Log(A), es la lógica local en A (es decir, Cla(Log(A)) = A), con Th(Log(A)) = Th(A) y tal que todos sus tokens son normales, es decir, NLog(A) = tok(A). Imagen inversa: dado un infomorfismo f: A → B y una lógica local L en B, la imagen inversa de L bajo f, denotada f−1 [L], es la lógica local en A tal que Γ f−1[L] Δ si ˆf[Γ] L ˆf[Δ] y Nf−1[L] = ˇf[NL] = {a ∈ tok(A) | a = ˇf(b) para algún b ∈ NL}. Lógica distribuida: sea C = {fi : Ai → C}i∈{1,2} un canal y L una lógica local en su núcleo C, la lógica distribuida de C generada por L, escrita como DLogC(L), es la imagen inversa de L bajo la suma f1 + f2. Refinamiento: sean C = {fi : Ai → C}i∈{1,2} y C = {fi : Ai → C}i∈{1,2} dos canales con las mismas clasificaciones de componentes A1 y A2. Un infomorfismo de refinamiento de C a C es un infomorfismo r: C → C tal que para cada i ∈ {1, 2}, fi = r ◦ fi (es decir, ˆfi = ˆr ◦ ˆfi y ˇfi = ˇfi ◦ ˇr). El canal C es una refinación de C si existe un refinamiento infomorfismo r de C a C. B. TEOREMAS DE LA TEORÍA DE CANALES Teorema B.1. La lógica generada por una clasificación es sólida y completa. Además, dado un conjunto de clasificación A y una lógica L en A, L es correcta y completa si y solo si L = Log(A). Teorema B.2. Sea L una lógica en una clasificación B y f : A → B un infomorfismo. 1. Si L es completo, entonces f−1 [L] es completo. 2. Si L es acústico y ˇf es sobreyectivo, entonces f−1 [L] es acústico. Todas las teorías consideradas en este documento son regulares. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1285 ",
            "candidates": [],
            "error": [
                [
                    "refinamientos de canal de información",
                    "refinamientos del canal de información"
                ]
            ]
        }
    }
}