{
    "id": "H-41",
    "original_text": "HITS on the Web: How does it Compare? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text. We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements. The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges. We found that HITS outperforms PageRank, but is about as effective as web-page in-degree. The same holds true when any of the link-based features are combined with the text retrieval algorithm. Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1. INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web. The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query. However, it remains unclear today whether there are practical benefits of HITS over other link graph measures. This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links. This, at least to some degree, takes the link graph into account, in a query-dependent manner. Comparing HITS to PageRank or in-degree empirically is no easy task. There are two main difficulties: scale and relevance. Scale is important because link-based features are known to improve in quality as the document graph grows. If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web. However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult. Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse. To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment. Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text. This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments. However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature. This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text. The remainder of this paper is structured as follows: Section 2 surveys related work. Section 3 describes the data sets we used in our study. Section 4 reviews the performance measures we used. Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments. Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2. RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms. The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research. There are numerous attempts at improving the effectiveness of HITS and PageRank. Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few. Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others. Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank. For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18]. Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published. We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank. Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query. A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google. By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3. OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges. Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages. These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs. Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded. The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10. Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links. As we will see, this property affects the computational cost of HITS. Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average. It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs. In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental). Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms. Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines. This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query. Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features. Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community. A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents. For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4. MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP. The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank). Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12]. NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges. The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j. The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query. Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG. The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set. The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant. The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set. Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise. The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results. The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) . The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set. The above definitions of MRR and MAP rely on the notion of a relevant result. We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant. For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings. Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions. Recall that over 99% of documents are unlabeled. We chose to treat all these documents as irrelevant to the query. For some queries, however, not all relevant documents have been judged. This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized. This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment. On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5. COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author. The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u. However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score. In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2. Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it. In the limit, the random walker is at node v with probability R(v). One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links. One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph. We chose the alternative approach of introducing a single phantom node. Each sink node has an edge to the phantom node, and the phantom node has an edge to itself. In practice, PageRank scores can be computed using power iteration. Since PageRank is query-independent, the computation can be performed off-line ahead of query time. This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time. In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank. The computation consists of two distinct phases. In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way. Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer. The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores. The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers. Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster. Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation. The second phase performs the actual PageRank power iteration. Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory. We represent PageRank scores as 64-bit floating point numbers. PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection. We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph. We used a damping factor of 0.15, and performed 200 power iterations. Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS. A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log. As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs. These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6. HITS HITS, unlike PageRank, is a query-dependent ranking algorithm. HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence. Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links. But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous. For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set. Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant. Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B. In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate. Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u. So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links. The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t. P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s . For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages. This is done using the following algorithm: 1. For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2. Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1. In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge. Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques. In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short. SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges. On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS). The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request. We implemented the HITS algorithm using the SHS infrastructure. We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id). We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain). Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set. Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements. We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value. For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time. The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7. EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q). Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set. We are specifically interested in evaluating the usefulness of HITS and other link-based features. In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs. We call this ranking with isolated features. Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined. Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100. Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores. Each graph is associated with one performance measure. The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme. The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off. The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure. Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24]. BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts. BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text. This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24]. BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F. Figure 2 shows the NDCG, MRR, and MAP measures of these features. Again all performance measures (and for all rank-thresholds we explored) agree. As expected, BM25F outperforms all link-based features by a large margin. The link-based features are divided into two groups, with a noticeable performance drop between the groups. The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores). In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links. Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links. The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all. On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising. A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set. Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores. However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons. First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance. Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches. Therefore, one must consider the effect of link-based features in combination with textual features. Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance. For this reason, we have studied the combination of the link-based features above with BM25F. All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned. We chose transform functions that we empirically determined to be well-suited. Table 1 shows the chosen transform functions. This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8]. We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions. We explored the pairwise combination of BM25F with every link-based scoring function. Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations. Regardless of the performance measure applied, we can make the following general observations: 1. Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2. The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3. The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used. However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster. Finally, we investigated whether certain features are better for some queries than for others. Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features. The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q. Unfortunately, the query set available to us did not contain this information. Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q. The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other. However, while not perfect, this approximation is at least directionally correct. We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket. In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F. Figure 4 shows the MAP@10 for all 13 query specificity buckets. Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries. The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries). BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14). By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8. CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F). Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP. Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores. HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering. A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little. We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes. There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road. Future work includes evaluation of different parameterizations of PageRank and HITS. In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not. Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA. Finally, we are planning to experiment with more complex feature combinations. 9. REFERENCES [1] B. Amento, L. Terveen, and W. Hill. Does authority mean quality? Predicting expert quality ratings of web documents. In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli. Inside PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal. Finding authorities and hubs from link structures on the World Wide Web. In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas. Link analysis ranking: algorithms, theory, and experiments. ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page. The anatomy of a large-scale hypertextual Web search engine. Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005. ACM Press. [7] D. Cohn and H. Chang. Learning to probabilistically identify authoritative documents. In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor. Relevance weighting for query independent evidence. In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield. Citation analysis as a tool in journal evaluation. Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina. Web spam taxonomy. In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam with TrustRank. In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic. Real life information retrieval: a study of user queries on the web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub. Extrapolation methods for accelerating PageRank computations. In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler. Bibliographic coupling between scientific papers. American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg. Authoritative sources in a hyperlinked environment. In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer. Deeper inside PageRank. Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran. The stochastic approach for link-structure analysis (SALSA) and the TKC effect. Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan. Stable algorithms for link analysis. In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the web. Technical report, Stanford Digital Library Technologies Project, 1998. [22] J. A. Tomlin. A new paradigm for ranking pages on the World Wide Web. In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking. Predicting fame and fortune: Pagerank or indegree? In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson. Microsoft Cambridge at TREC-13: Web and HARD tracks. In Proc. of the 13th Text Retrieval Conference, 2004.",
    "original_translation": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004.",
    "original_sentences": [
        "HITS on the Web: How does it Compare?",
        "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
        "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
        "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
        "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
        "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
        "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
        "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
        "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
        "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
        "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
        "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
        "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
        "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
        "Comparing HITS to PageRank or in-degree empirically is no easy task.",
        "There are two main difficulties: scale and relevance.",
        "Scale is important because link-based features are known to improve in quality as the document graph grows.",
        "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
        "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
        "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
        "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
        "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
        "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
        "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
        "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
        "The remainder of this paper is structured as follows: Section 2 surveys related work.",
        "Section 3 describes the data sets we used in our study.",
        "Section 4 reviews the performance measures we used.",
        "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
        "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
        "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
        "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
        "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
        "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
        "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
        "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
        "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
        "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
        "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
        "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
        "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
        "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
        "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
        "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
        "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
        "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
        "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
        "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
        "As we will see, this property affects the computational cost of HITS.",
        "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
        "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
        "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
        "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
        "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
        "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
        "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
        "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
        "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
        "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
        "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
        "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
        "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
        "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
        "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
        "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
        "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
        "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
        "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
        "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
        "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
        "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
        "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
        "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
        "The above definitions of MRR and MAP rely on the notion of a relevant result.",
        "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
        "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
        "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
        "Recall that over 99% of documents are unlabeled.",
        "We chose to treat all these documents as irrelevant to the query.",
        "For some queries, however, not all relevant documents have been judged.",
        "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
        "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
        "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
        "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
        "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
        "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
        "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
        "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
        "In the limit, the random walker is at node v with probability R(v).",
        "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
        "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
        "We chose the alternative approach of introducing a single phantom node.",
        "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
        "In practice, PageRank scores can be computed using power iteration.",
        "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
        "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
        "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
        "The computation consists of two distinct phases.",
        "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
        "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
        "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
        "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
        "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
        "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
        "The second phase performs the actual PageRank power iteration.",
        "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
        "We represent PageRank scores as 64-bit floating point numbers.",
        "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
        "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
        "We used a damping factor of 0.15, and performed 200 power iterations.",
        "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
        "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
        "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
        "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
        "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
        "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
        "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
        "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
        "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
        "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
        "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
        "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
        "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
        "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
        "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
        "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
        "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
        "This is done using the following algorithm: 1.",
        "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
        "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
        "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
        "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
        "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
        "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
        "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
        "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
        "We implemented the HITS algorithm using the SHS infrastructure.",
        "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
        "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
        "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
        "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
        "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
        "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
        "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
        "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
        "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
        "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
        "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
        "We call this ranking with isolated features.",
        "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
        "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
        "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
        "Each graph is associated with one performance measure.",
        "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
        "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
        "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
        "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
        "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
        "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
        "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
        "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
        "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
        "Again all performance measures (and for all rank-thresholds we explored) agree.",
        "As expected, BM25F outperforms all link-based features by a large margin.",
        "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
        "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
        "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
        "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
        "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
        "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
        "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
        "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
        "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
        "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
        "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
        "Therefore, one must consider the effect of link-based features in combination with textual features.",
        "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
        "For this reason, we have studied the combination of the link-based features above with BM25F.",
        "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
        "We chose transform functions that we empirically determined to be well-suited.",
        "Table 1 shows the chosen transform functions.",
        "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
        "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
        "We explored the pairwise combination of BM25F with every link-based scoring function.",
        "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
        "Regardless of the performance measure applied, we can make the following general observations: 1.",
        "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
        "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
        "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
        "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
        "Finally, we investigated whether certain features are better for some queries than for others.",
        "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
        "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
        "Unfortunately, the query set available to us did not contain this information.",
        "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
        "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
        "However, while not perfect, this approximation is at least directionally correct.",
        "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
        "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
        "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
        "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
        "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
        "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
        "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
        "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
        "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
        "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
        "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
        "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
        "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
        "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
        "Future work includes evaluation of different parameterizations of PageRank and HITS.",
        "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
        "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
        "Finally, we are planning to experiment with more complex feature combinations. 9.",
        "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
        "Does authority mean quality?",
        "Predicting expert quality ratings of web documents.",
        "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
        "Inside PageRank.",
        "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
        "Finding authorities and hubs from link structures on the World Wide Web.",
        "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
        "Link analysis ranking: algorithms, theory, and experiments.",
        "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
        "The anatomy of a large-scale hypertextual Web search engine.",
        "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
        "Learning to rank using gradient descent.",
        "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
        "ACM Press. [7] D. Cohn and H. Chang.",
        "Learning to probabilistically identify authoritative documents.",
        "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
        "Relevance weighting for query independent evidence.",
        "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
        "Citation analysis as a tool in journal evaluation.",
        "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
        "Web spam taxonomy.",
        "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
        "Combating web spam with TrustRank.",
        "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
        "Real life information retrieval: a study of user queries on the web.",
        "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
        "Cumulated gain-based evaluation of IR techniques.",
        "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
        "Extrapolation methods for accelerating PageRank computations.",
        "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
        "Bibliographic coupling between scientific papers.",
        "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
        "Authoritative sources in a hyperlinked environment.",
        "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
        "Authoritative sources in a hyperlinked environment.",
        "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
        "Deeper inside PageRank.",
        "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
        "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
        "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
        "Stable algorithms for link analysis.",
        "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
        "The PageRank citation ranking: Bringing order to the web.",
        "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
        "A. Tomlin.",
        "A new paradigm for ranking pages on the World Wide Web.",
        "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
        "Predicting fame and fortune: Pagerank or indegree?",
        "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
        "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
        "In Proc. of the 13th Text Retrieval Conference, 2004."
    ],
    "translated_text_sentences": [
        "HITS en la web: ¿Cómo se compara?",
        "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
        "Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla.",
        "Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada.",
        "La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces.",
        "Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web.",
        "Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto.",
        "Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1.",
        "Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web.",
        "Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada.",
        "Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces.",
        "Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes.",
        "Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta.",
        "Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil.",
        "Hay dos dificultades principales: escala y relevancia.",
        "La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos.",
        "Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web.",
        "Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil.",
        "La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará.",
        "Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos.",
        "Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla.",
        "Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas.",
        "Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple.",
        "Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla.",
        "El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados.",
        "La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio.",
        "La sección 4 revisa las medidas de rendimiento que utilizamos.",
        "Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala.",
        "La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales.",
        "TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21].",
        "La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores.",
        "Hay numerosos intentos de mejorar la efectividad de HITS y PageRank.",
        "Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos.",
        "Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros.",
        "Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank.",
        "Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18].",
        "Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad.",
        "Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank.",
        "Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta.",
        "Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google.",
        "Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL.",
        "NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos.",
        "Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML.",
        "Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL.",
        "Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas.",
        "El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10.",
        "Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes.",
        "Como veremos, esta propiedad afecta el costo computacional de HITS.",
        "Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio.",
        "Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados.",
        "De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial).",
        "Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes.",
        "Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda.",
        "Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario.",
        "Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características.",
        "Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información.",
        "Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes.",
        "Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4.",
        "En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP.",
        "La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo).",
        "Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12].",
        "Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos.",
        "El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j.",
        "El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta.",
        "Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio.",
        "El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados.",
        "El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante.",
        "El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas.",
        "Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario.",
        "La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango.",
        "La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i).",
        "La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas.",
        "Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante.",
        "Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes.",
        "Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos.",
        "De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes.",
        "Recuerda que más del 99% de los documentos no tienen etiquetas.",
        "Decidimos tratar todos estos documentos como irrelevantes para la consulta.",
        "Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes.",
        "Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas.",
        "Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación.",
        "Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5.",
        "CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A.",
        "La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u.",
        "Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero.",
        "Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2.",
        "Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él.",
        "En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v).",
        "Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente.",
        "Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo.",
        "Elegimos la alternativa de introducir un único nodo fantasma.",
        "Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo.",
        "En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia.",
        "Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta.",
        "Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta.",
        "Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank.",
        "La computación consta de dos fases distintas.",
        "En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso.",
        "Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits.",
        "Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank.",
        "El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados.",
        "La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación.",
        "Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida.",
        "La segunda fase realiza la iteración de potencia de PageRank real.",
        "Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria.",
        "Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits.",
        "Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP.",
        "Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web.",
        "Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia.",
        "A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS.",
        "Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas.",
        "Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados.",
        "Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6.",
        "HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta.",
        "HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática.",
        "Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente.",
        "Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme.",
        "Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados.",
        "Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático.",
        "Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B.",
        "Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces.",
        "Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u.",
        "Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios.",
        "El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto.",
        "La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s.",
        "Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias.",
        "Esto se hace utilizando el siguiente algoritmo: 1.",
        "Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2.",
        "Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1.",
        "En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería.",
        "Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas.",
        "Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen.",
        "SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas.",
        "En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS).",
        "El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC.",
        "Implementamos el algoritmo HITS utilizando la infraestructura SHS.",
        "Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id).",
        "Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio).",
        "Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz.",
        "Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo.",
        "Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo.",
        "Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez.",
        "La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio.",
        "RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q).",
        "Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas.",
        "Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces.",
        "En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes.",
        "Llamamos a este ranking con características aisladas.",
        "Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos.",
        "Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100.",
        "La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS.",
        "Cada gráfico está asociado con una medida de rendimiento.",
        "El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces.",
        "El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena.",
        "El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento.",
        "Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24].",
        "BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados.",
        "BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje.",
        "Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24].",
        "BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F.",
        "La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características.",
        "Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden.",
        "Como era de esperar, BM25F supera con creces todas las características basadas en enlaces.",
        "Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos.",
        "El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS).",
        "En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces.",
        "Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih).",
        "El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto.",
        "Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas.",
        "Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados.",
        "Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS.",
        "Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones.",
        "Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia.",
        "En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual.",
        "Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales.",
        "De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general.",
        "Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F.",
        "Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado.",
        "Elegimos funciones de transformación que determinamos empíricamente que son adecuadas.",
        "La Tabla 1 muestra las funciones de transformación elegidas.",
        "Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8].",
        "Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera.",
        "Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces.",
        "La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características.",
        "Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1.",
        "La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual.",
        "La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3.",
        "Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10.",
        "Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida.",
        "Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras.",
        "Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación.",
        "La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q.",
        "Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información.",
        "Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q.",
        "La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí.",
        "Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales.",
        "Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo.",
        "Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F.",
        "La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta.",
        "Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas.",
        "Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas).",
        "BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14).",
        "En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales.",
        "CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F).",
        "La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP.",
        "Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS.",
        "Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio.",
        "Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco.",
        "Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos.",
        "Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino.",
        "El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS.",
        "En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no.",
        "Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA.",
        "Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9.",
        "REFERENCIAS [1] B. Amento, L. Terveen y W. Hill.",
        "¿Significa autoridad calidad?",
        "Prediciendo las calificaciones de calidad de expertos de documentos web.",
        "En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli.",
        "Dentro de PageRank.",
        "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal.",
        "Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web.",
        "En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas.",
        "Clasificación de análisis de enlaces: algoritmos, teoría y experimentos.",
        "ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page.",
        "La anatomía de un motor de búsqueda web hipertextual a gran escala.",
        "Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender.",
        "Aprendiendo a clasificar utilizando descenso de gradiente.",
        "En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005.",
        "ACM Press. [7] D. Cohn y H. Chang.",
        "Aprendiendo a identificar de manera probabilística documentos autoritativos.",
        "En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor.",
        "Ponderación de relevancia para evidencia independiente de la consulta.",
        "En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield.",
        "Análisis de citas como herramienta en la evaluación de revistas.",
        "Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina.",
        "Taxonomía del spam en la web.",
        "En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen.",
        "Combatiendo el spam web con TrustRank.",
        "En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic.",
        "Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web.",
        "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen.",
        "Evaluación basada en la ganancia acumulada de técnicas de recuperación de información.",
        "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub.",
        "Métodos de extrapolación para acelerar los cálculos de PageRank.",
        "En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler.",
        "Acoplamiento bibliográfico entre artículos científicos.",
        "Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
        "Fuentes autorizadas en un entorno hiperenlazado.",
        "En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg.",
        "Fuentes autorizadas en un entorno hiperenlazado.",
        "Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer.",
        "Más profundo dentro de PageRank.",
        "Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran.",
        "El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC.",
        "Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan.",
        "Algoritmos estables para análisis de enlaces.",
        "En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd.",
        "El ranking de citas PageRank: Trayendo orden a la web.",
        "Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J.",
        "A. Tomlin.",
        "Un nuevo paradigma para clasificar páginas en la World Wide Web.",
        "En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking.",
        "¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada?",
        "En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson.",
        "Microsoft Cambridge en TREC-13: pistas Web y HARD.",
        "En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004."
    ],
    "error_count": 7,
    "keys": {
        "ranking": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based <br>ranking</br> algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is <br>ranking</br> at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for <br>ranking</br> web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based <br>ranking</br> algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based <br>ranking</br> algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing <br>ranking</br> algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various <br>ranking</br> algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect <br>ranking</br> scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a <br>ranking</br> by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-<br>ranking</br> relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-<br>ranking</br> results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial <br>ranking</br> algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent <br>ranking</br> algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based <br>ranking</br> algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this <br>ranking</br> with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art <br>ranking</br> function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for <br>ranking</br> at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall <br>ranking</br> function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different <br>ranking</br> features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all <br>ranking</br> functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based <br>ranking</br> algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective <br>ranking</br> features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based <br>ranking</br> schemes.",
                "There are many possible variants of these schemes, and many other link-based <br>ranking</br> algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based <br>ranking</br> algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis <br>ranking</br>: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation <br>ranking</br>: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for <br>ranking</br> pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based <br>ranking</br> algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is <br>ranking</br> at the top of the ten or so documents that a user will peruse.",
                "RELATED WORK The idea of using hyperlink analysis for <br>ranking</br> web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "Query-dependent link-based <br>ranking</br> algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based <br>ranking</br> algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others."
            ],
            "translated_annotated_samples": [
                "Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de <br>clasificación</br> basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla.",
                "La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es <br>clasificar</br> en la parte superior de los diez o más documentos que un usuario examinará.",
                "TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para <br>clasificar</br> los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21].",
                "Los algoritmos de <br>clasificación</br> basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos.",
                "Los algoritmos de <br>clasificación</br> basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de <br>clasificación</br> basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es <br>clasificar</br> en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para <br>clasificar</br> los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de <br>clasificación</br> basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de <br>clasificación</br> basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. ",
            "candidates": [],
            "error": [
                [
                    "clasificación",
                    "clasificar",
                    "clasificar",
                    "clasificación",
                    "clasificación"
                ]
            ]
        },
        "pagerank": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms <br>pagerank</br>, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and <br>pagerank</br> have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to <br>pagerank</br> or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the <br>pagerank</br> and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and <br>pagerank</br> [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses <br>pagerank</br>, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and <br>pagerank</br>.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by <br>pagerank</br> include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and <br>pagerank</br>.",
                "For example, Borodin et al. [3] investigated various theoretical properties of <br>pagerank</br>, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of <br>pagerank</br> scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of <br>pagerank</br> and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of <br>pagerank</br>.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING <br>pagerank</br> ON A LARGE WEB GRAPH <br>pagerank</br> is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard <br>pagerank</br>: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, <br>pagerank</br> can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing <br>pagerank</br> is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, <br>pagerank</br> scores can be computed using power iteration.",
                "Since <br>pagerank</br> is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute <br>pagerank</br> scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of <br>pagerank</br>.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute <br>pagerank</br> scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the <br>pagerank</br> scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual <br>pagerank</br> power iteration.",
                "Both the link data and the current <br>pagerank</br> vector reside on disk and are read in a streaming fashion; while the new <br>pagerank</br> vector is maintained in memory.",
                "We represent <br>pagerank</br> scores as 64-bit floating point numbers.",
                "<br>pagerank</br> contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard <br>pagerank</br> scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the <br>pagerank</br> vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final <br>pagerank</br> vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each <br>pagerank</br> vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed <br>pagerank</br> score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike <br>pagerank</br>, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all <br>pagerank</br> hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all <br>pagerank</br> hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: <br>pagerank</br>, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 <br>pagerank</br> hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 <br>pagerank</br> hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, <br>pagerank</br>, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform <br>pagerank</br> under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published <br>pagerank</br> algorithm for many years, and that this has led to anomalies in the web graph that affect <br>pagerank</br>, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s <br>pagerank</br> T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (<br>pagerank</br>, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm <br>pagerank</br> degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with <br>pagerank</br> or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: <br>pagerank</br>, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and <br>pagerank</br> and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular <br>pagerank</br> and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms <br>pagerank</br>, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, <br>pagerank</br>, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of <br>pagerank</br> and HITS.",
                "In particular, we would like to study the impact of changes to the <br>pagerank</br> damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond <br>pagerank</br> and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside <br>pagerank</br>.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating <br>pagerank</br> computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside <br>pagerank</br>.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The <br>pagerank</br> citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: <br>pagerank</br> or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "We found that HITS outperforms <br>pagerank</br>, but is about as effective as web-page in-degree.",
                "INTRODUCTION Link graph features such as in-degree and <br>pagerank</br> have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "Comparing HITS to <br>pagerank</br> or in-degree empirically is no easy task.",
                "Sections 5 and 6 describe the <br>pagerank</br> and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and <br>pagerank</br> [5, 21] algorithms."
            ],
            "translated_annotated_samples": [
                "Descubrimos que HITS supera a <br>PageRank</br>, pero es tan efectivo como el grado de entrada de la página web.",
                "Las características del grafo de enlaces, como el grado de entrada y el <br>PageRank</br>, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web.",
                "Comparar HITS con <br>PageRank</br> o con el grado de entrada empíricamente no es una tarea fácil.",
                "Las secciones 5 y 6 describen con más detalle los <br>algoritmos PageRank</br> y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala.",
                "TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y <br>PageRank</br> [5, 21]."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a <br>PageRank</br>, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el <br>PageRank</br>, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con <br>PageRank</br> o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los <br>algoritmos PageRank</br> y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y <br>PageRank</br> [5, 21]. ",
            "candidates": [],
            "error": [
                [
                    "PageRank",
                    "PageRank",
                    "PageRank",
                    "algoritmos PageRank",
                    "PageRank"
                ]
            ]
        },
        "mean reciprocal rank": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the <br>mean reciprocal rank</br>, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The <br>mean reciprocal rank</br> (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "We quantified their effectiveness using three common performance measures: the <br>mean reciprocal rank</br>, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The <br>mean reciprocal rank</br> (MRR) of a query set is the average reciprocal rank of all queries in the query set."
            ],
            "translated_annotated_samples": [
                "Medimos su efectividad utilizando tres medidas comunes de rendimiento: la <br>clasificación recíproca media</br>, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada.",
                "El <br>rango recíproco promedio</br> (MRR) de un conjunto de consultas es el <br>rango recíproco promedio</br> de todas las consultas en el conjunto de consultas."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la <br>clasificación recíproca media</br>, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El <br>rango recíproco promedio</br> (MRR) de un conjunto de consultas es el <br>rango recíproco promedio</br> de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    "clasificación recíproca media",
                    "rango recíproco promedio",
                    "rango recíproco promedio"
                ]
            ]
        },
        "mean average precision": {
            "translated_key": "precisión media promedio",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the <br>mean average precision</br>, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The <br>mean average precision</br> (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the <br>mean average precision</br>, and the normalized discounted cumulative gain measurements.",
                "The <br>mean average precision</br> (MAP) of a query set is the mean of the average precisions of all queries in the query set."
            ],
            "translated_annotated_samples": [
                "Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la <br>precisión media promedio</br> y las mediciones normalizadas de ganancia acumulada descontada.",
                "La <br>precisión media promedio</br> (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la <br>precisión media promedio</br> y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La <br>precisión media promedio</br> (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "normalized discounted cumulative gain measurement": {
            "translated_key": "mediciones normalizadas de ganancia acumulada descontada",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the <br>normalized discounted cumulative gain measurement</br>s.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the <br>normalized discounted cumulative gain measurement</br>s."
            ],
            "translated_annotated_samples": [
                "Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las <br>mediciones normalizadas de ganancia acumulada descontada</br>."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las <br>mediciones normalizadas de ganancia acumulada descontada</br>. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "breadth-first search crawl": {
            "translated_key": "rastreo de búsqueda en anchura",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a <br>breadth-first search crawl</br> of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "The evaluation is based on two large data sets: a <br>breadth-first search crawl</br> of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges."
            ],
            "translated_annotated_samples": [
                "La evaluación se basa en dos grandes conjuntos de datos: un <br>rastreo de búsqueda en anchura</br> de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un <br>rastreo de búsqueda en anchura</br> de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "query specificity": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between <br>query specificity</br> and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by <br>query specificity</br>. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 <br>query specificity</br> buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "Finally, we studied the relationship between <br>query specificity</br> and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by <br>query specificity</br>. ferent performance measures used.",
                "Figure 4 shows the MAP@10 for all 13 <br>query specificity</br> buckets."
            ],
            "translated_annotated_samples": [
                "Finalmente, estudiamos la relación entre la <br>especificidad de la consulta</br> y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas.",
                "Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10.",
                "La Figura 4 muestra el MAP@10 para los 13 grupos de <br>especificidad de consulta</br>."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la <br>especificidad de la consulta</br> y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de <br>especificidad de consulta</br>. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    "especificidad de la consulta",
                    "especificidad de consulta"
                ]
            ]
        },
        "feature selection": {
            "translated_key": "selección de características",
            "is_in_text": false,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "link graph": {
            "translated_key": "grafo de enlaces",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION <br>link graph</br> features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other <br>link graph</br> measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the <br>link graph</br> into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "INTRODUCTION <br>link graph</br> features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "However, it remains unclear today whether there are practical benefits of HITS over other <br>link graph</br> measures.",
                "This, at least to some degree, takes the <br>link graph</br> into account, in a query-dependent manner."
            ],
            "translated_annotated_samples": [
                "Las características del <br>grafo de enlaces</br>, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web.",
                "Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de <br>grafo de enlaces</br>.",
                "Esto, al menos en cierta medida, tiene en cuenta el <br>grafo de enlaces</br>, de manera dependiente de la consulta."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del <br>grafo de enlaces</br>, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de <br>grafo de enlaces</br>. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el <br>grafo de enlaces</br>, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "scale and relevance": {
            "translated_key": "escala y relevancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: <br>scale and relevance</br>.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "There are two main difficulties: <br>scale and relevance</br>."
            ],
            "translated_annotated_samples": [
                "Hay dos dificultades principales: <br>escala y relevancia</br>."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: <br>escala y relevancia</br>. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "link-based feature": {
            "translated_key": "característica basada en enlaces",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent <br>link-based feature</br>.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a <br>link-based feature</br> that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a <br>link-based feature</br> that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of <br>link-based feature</br> matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent <br>link-based feature</br>.",
                "Otherwise, we may find a <br>link-based feature</br> that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a <br>link-based feature</br> that is weak in isolation but significantly improves overall performance.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of <br>link-based feature</br> matters relatively little."
            ],
            "translated_annotated_samples": [
                "Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la <br>característica basada en enlaces</br> más simple.",
                "De lo contrario, podríamos encontrar una <br>característica basada en enlaces</br> que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una <br>característica basada en enlaces</br> que es débil de forma aislada pero mejora significativamente el rendimiento general.",
                "Una combinación lineal de cualquier <br>característica basada en enlaces</br> con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una <br>característica basada en enlaces</br> entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la <br>característica basada en enlaces</br> más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una <br>característica basada en enlaces</br> que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una <br>característica basada en enlaces</br> que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier <br>característica basada en enlaces</br> con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una <br>característica basada en enlaces</br> entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "hyperlink analysis": {
            "translated_key": "análisis de hipervínculos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using <br>hyperlink analysis</br> for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "RELATED WORK The idea of using <br>hyperlink analysis</br> for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms."
            ],
            "translated_annotated_samples": [
                "TRABAJO RELACIONADO La idea de utilizar el <br>análisis de hipervínculos</br> para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el <br>análisis de hipervínculos</br> para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "quantitative measure": {
            "translated_key": "medidas cuantitativas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed <br>quantitative measure</br>s, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "Amento et al. [1] employed <br>quantitative measure</br>s, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query."
            ],
            "translated_annotated_samples": [
                "Amento et al. [1] emplearon <br>medidas cuantitativas</br>, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon <br>medidas cuantitativas</br>, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "crawled web page": {
            "translated_key": "páginas web rastreadas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of <br>crawled web page</br>s is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "The mean out-degree of <br>crawled web page</br>s is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10."
            ],
            "translated_annotated_samples": [
                "El grado medio de salida de las <br>páginas web rastreadas</br> es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las <br>páginas web rastreadas</br> es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "rank": {
            "translated_key": "rango",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal <br>rank</br>, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents <br>rank</br> increases (assuming that the best document has the lowest <br>rank</br>).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular <br>rank</br>-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at <br>rank</br> j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal <br>rank</br> (RR) of the ranked result set of a query is defined to be the reciprocal value of the <br>rank</br> of the highest-ranking relevant document in the result set.",
                "The RR at <br>rank</br>-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal <br>rank</br> (MRR) of a query set is the average reciprocal <br>rank</br> of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at <br>rank</br> i is relevant and 0 otherwise.",
                "The precision P(j) at <br>rank</br> j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at <br>rank</br>-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of <br>rank</br>-thresholds; we report results here at <br>rank</br> 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the <br>rank</br> may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to <br>rank</br> the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to <br>rank</br> relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all <br>rank</br>-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to <br>rank</br> using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "We quantified their effectiveness using three common performance measures: the mean reciprocal <br>rank</br>, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents <br>rank</br> increases (assuming that the best document has the lowest <br>rank</br>).",
                "The discounted cumulative gain at a particular <br>rank</br>-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at <br>rank</br> j.",
                "The reciprocal <br>rank</br> (RR) of the ranked result set of a query is defined to be the reciprocal value of the <br>rank</br> of the highest-ranking relevant document in the result set.",
                "The RR at <br>rank</br>-threshold T is defined to be 0 if none of the highestranking T documents is relevant."
            ],
            "translated_annotated_samples": [
                "Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada.",
                "La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su <br>rango</br> (asumiendo que el mejor documento tiene el <br>rango</br> más bajo).",
                "El beneficio acumulado descontado en un umbral de <br>rango</br> particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el <br>rango</br> j.",
                "El <br>rango</br> recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del <br>rango</br> del documento relevante de mayor rango en el conjunto de resultados.",
                "El RR en el umbral de <br>rango</br> T se define como 0 si ninguno de los T documentos de mayor <br>rango</br> es relevante."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su <br>rango</br> (asumiendo que el mejor documento tiene el <br>rango</br> más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de <br>rango</br> particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el <br>rango</br> j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El <br>rango</br> recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del <br>rango</br> del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de <br>rango</br> T se define como 0 si ninguno de los T documentos de mayor <br>rango</br> es relevante. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "hit": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 <br>hit</br>s-aut-all <br>hit</br>s-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih <br>hit</br>s-aut-id-25 <br>hit</br>s-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all <br>hit</br>s-aut-ih-100 <br>hit</br>s-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) <br>hit</br>s-aut-* T(s) = log(s + 3 · 10−8 ) <br>hit</br>s-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id <br>hit</br>s-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 <br>hit</br>s-aut-all <br>hit</br>s-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih <br>hit</br>s-aut-id-25 <br>hit</br>s-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all <br>hit</br>s-aut-ih-100 <br>hit</br>s-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) <br>hit</br>s-aut-* T(s) = log(s + 3 · 10−8 ) <br>hit</br>s-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id <br>hit</br>s-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used."
            ],
            "translated_annotated_samples": [
                "A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 <br>hit</br>s-aut-all <br>hit</br>s-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS.",
                "Entre otras cosas, el <br>grafo</br> web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el <br>grafo</br> no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas.",
                "BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo <br>hit</br>s-aut-ih-100 <br>hit</br>s-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F.",
                "En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual.",
                "Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en <br>enlaces entrantes</br> son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 <br>hit</br>s-aut-all <br>hit</br>s-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el <br>grafo</br> web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el <br>grafo</br> no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo <br>hit</br>s-aut-ih-100 <br>hit</br>s-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en <br>enlaces entrantes</br> son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. ",
            "candidates": [],
            "error": [
                [
                    "hit",
                    "hit",
                    "grafo",
                    "grafo",
                    "hit",
                    "hit",
                    "enlaces entrantes"
                ]
            ]
        },
        "bm25f": {
            "translated_key": "BM25F",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas <br>bm25f</br> performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 <br>bm25f</br> degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 <br>bm25f</br> hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: <br>bm25f</br>[24].",
                "<br>bm25f</br> is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "<br>bm25f</br> is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "<br>bm25f</br> has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 <br>bm25f</br> NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, <br>bm25f</br> outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function <br>bm25f</br> T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with <br>bm25f</br>.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of <br>bm25f</br>), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of <br>bm25f</br> with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and MAP measures of these feature combinations, together with a baseline <br>bm25f</br> score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with <br>bm25f</br> results in a substantial performance improvement over <br>bm25f</br> in isolation. 2.",
                "The combination of <br>bm25f</br> with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of <br>bm25f</br> with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of <br>bm25f</br> with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of <br>bm25f</br> with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and <br>bm25f</br>.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "<br>bm25f</br> performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (<br>bm25f</br>).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with <br>bm25f</br> produces a significant improvement in performance, and there is a clear difference between combining <br>bm25f</br> with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas <br>bm25f</br> performs better for specific queries.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 <br>bm25f</br> degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 <br>bm25f</br> hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: <br>bm25f</br>[24].",
                "<br>bm25f</br> is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "<br>bm25f</br> is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text."
            ],
            "translated_annotated_samples": [
                "Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que <br>BM25F</br> funciona mejor para consultas específicas.",
                "Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas.",
                "Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: <br>BM25F</br>[24].",
                "<br>BM25F</br> es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados.",
                "BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que <br>BM25F</br> funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: <br>BM25F</br>[24]. <br>BM25F</br> es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "mrr": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, <br>mrr</br>, and MAP.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (<br>mrr</br>) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of <br>mrr</br> and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and <br>mrr</br> values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and <br>mrr</br> values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result <br>mrr</br>@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random <br>mrr</br>@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f <br>mrr</br>@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, <br>mrr</br>, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, <br>mrr</br>, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, <br>mrr</br>, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, <br>mrr</br>, and MAP.",
                "The mean reciprocal rank (<br>mrr</br>) of a query set is the average reciprocal rank of all queries in the query set.",
                "The above definitions of <br>mrr</br> and MAP rely on the notion of a relevant result.",
                "For reasons of space, we only report MAP and <br>mrr</br> values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, MAP, and <br>mrr</br> values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions."
            ],
            "translated_annotated_samples": [
                "En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, <br>MRR</br> y MAP.",
                "El <br>rango recíproco promedio</br> (MRR) de un conjunto de consultas es el <br>rango recíproco promedio</br> de todas las consultas en el conjunto de consultas.",
                "Las definiciones anteriores de <br>MRR</br> y MAP se basan en la noción de un resultado relevante.",
                "Por razones de espacio, solo informamos los valores de MAP y <br>MRR</br> calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos.",
                "De manera similar, calculamos los valores de NDCG, MAP y <br>MRR</br> para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, <br>MRR</br> y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El <br>rango recíproco promedio</br> (MRR) de un conjunto de consultas es el <br>rango recíproco promedio</br> de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de <br>MRR</br> y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y <br>MRR</br> calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y <br>MRR</br> para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. ",
            "candidates": [],
            "error": [
                [
                    "MRR",
                    "rango recíproco promedio",
                    "rango recíproco promedio",
                    "MRR",
                    "MRR",
                    "MRR"
                ]
            ]
        },
        "map": {
            "translated_key": "MAP",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and <br>map</br>.",
                "The normalized discounted cumulative gains (NDCG) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "NDCG values are normalized to be between 0 and 1, with 1 being the NDCG of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The NDCG is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean NDCG.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (<br>map</br>) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and <br>map</br> rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report <br>map</br> and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, <br>map</br>, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result <br>map</br>@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random <br>map</br>@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to <br>map</br> a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to <br>map</br> a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f <br>map</br>@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the NDCG, MRR, and <br>map</br> measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the NDCG, MRR, and <br>map</br> measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 <br>map</br>@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the <br>map</br>@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: NDCG, MRR, and <br>map</br>.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: NDCG, MRR, and <br>map</br>.",
                "The mean average precision (<br>map</br>) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and <br>map</br> rely on the notion of a relevant result.",
                "For reasons of space, we only report <br>map</br> and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed NDCG, <br>map</br>, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions."
            ],
            "translated_annotated_samples": [
                "En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y <br>MAP</br>.",
                "La precisión media promedio (<br>MAP</br>) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas.",
                "Las definiciones anteriores de MRR y <br>MAP</br> se basan en la noción de un resultado relevante.",
                "Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos.",
                "De manera similar, calculamos los valores de NDCG, <br>MAP</br> y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y <br>MAP</br>. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (<br>MAP</br>) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y <br>MAP</br> se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, <br>MAP</br> y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ndcg": {
            "translated_key": "NDCG",
            "is_in_text": true,
            "original_annotated_sentences": [
                "HITS on the Web: How does it Compare?",
                "Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo!",
                "Research Barcelona Ocata 1 Barcelona 08003, Spain hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, UK mitaylor@microsoft.com ABSTRACT This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, when used in combination with a state-ofthe-art text retrieval algorithm exploiting anchor text.",
                "We quantified their effectiveness using three common performance measures: the mean reciprocal rank, the mean average precision, and the normalized discounted cumulative gain measurements.",
                "The evaluation is based on two large data sets: a breadth-first search crawl of 463 million web pages containing 17.6 billion hyperlinks and referencing 2.9 billion distinct URLs; and a set of 28,043 queries sampled from a query log, each query having on average 2,383 results, about 17 of which were labeled by judges.",
                "We found that HITS outperforms PageRank, but is about as effective as web-page in-degree.",
                "The same holds true when any of the link-based features are combined with the text retrieval algorithm.",
                "Finally, we studied the relationship between query specificity and the effectiveness of selected features, and found that link-based features perform better for general queries, whereas BM25F performs better for specific queries.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Information Storage and Retrieval-search process, selection process General Terms Algorithms, Measurement, Experimentation 1.",
                "INTRODUCTION Link graph features such as in-degree and PageRank have been shown to significantly improve the performance of text retrieval algorithms on the web.",
                "The HITS algorithm is also believed to be of interest for web search; to some degree, one may expect HITS to be more informative that other link-based features because it is query-dependent: it tries to measure the interest of pages with respect to a given query.",
                "However, it remains unclear today whether there are practical benefits of HITS over other link graph measures.",
                "This is even more true when we consider that modern retrieval algorithms used on the web use a document representation which incorporates the documents anchor text, i.e. the text of incoming links.",
                "This, at least to some degree, takes the link graph into account, in a query-dependent manner.",
                "Comparing HITS to PageRank or in-degree empirically is no easy task.",
                "There are two main difficulties: scale and relevance.",
                "Scale is important because link-based features are known to improve in quality as the document graph grows.",
                "If we carry out a small experiment, our conclusions wont carry over to large graphs such as the web.",
                "However, computing HITS efficiently on a graph the size of a realistic web crawl is extraordinarily difficult.",
                "Relevance is also crucial because we cannot measure the performance of a feature in the absence of human judgments: what is crucial is ranking at the top of the ten or so documents that a user will peruse.",
                "To our knowledge, this paper is the first attempt to evaluate HITS at a large scale and compare it to other link-based features with respect to human evaluated judgment.",
                "Our results confirm many of the intuitions we have about link-based features and their relationship to text retrieval methods exploiting anchor text.",
                "This is reassuring: in the absence of a theoretical model capable of tying these measures with relevance, the only way to validate our intuitions is to carry out realistic experiments.",
                "However, we were quite surprised to find that HITS, a query-dependent feature, is about as effective as web page in-degree, the most simpleminded query-independent link-based feature.",
                "This continues to be true when the link-based features are combined with a text retrieval algorithm exploiting anchor text.",
                "The remainder of this paper is structured as follows: Section 2 surveys related work.",
                "Section 3 describes the data sets we used in our study.",
                "Section 4 reviews the performance measures we used.",
                "Sections 5 and 6 describe the PageRank and HITS algorithms in more detail, and sketch the computational infrastructure we employed to carry out large scale experiments.",
                "Section 7 presents the results of our evaluations, and Section 8 offers concluding remarks. 2.",
                "RELATED WORK The idea of using hyperlink analysis for ranking web search results arose around 1997, and manifested itself in the HITS [16, 17] and PageRank [5, 21] algorithms.",
                "The popularity of these two algorithms and the phenomenal success of the Google search engine, which uses PageRank, have spawned a large amount of subsequent research.",
                "There are numerous attempts at improving the effectiveness of HITS and PageRank.",
                "Query-dependent link-based ranking algorithms inspired by HITS include SALSA [19], Randomized HITS [20], and PHITS [7], to name a few.",
                "Query-independent link-based ranking algorithms inspired by PageRank include TrafficRank [22], BlockRank [14], and TrustRank [11], and many others.",
                "Another line of research is concerned with analyzing the mathematical properties of HITS and PageRank.",
                "For example, Borodin et al. [3] investigated various theoretical properties of PageRank, HITS, SALSA, and PHITS, including their similarity and stability, while Bianchini et al. [2] studied the relationship between the structure of the web graph and the distribution of PageRank scores, and Langville and Meyer examined basic properties of PageRank such as existence and uniqueness of an eigenvector and convergence of power iteration [18].",
                "Given the attention that has been paid to improving the effectiveness of PageRank and HITS, and the thorough studies of the mathematical properties of these algorithms, it is somewhat surprising that very few evaluations of their effectiveness have been published.",
                "We are aware of two studies that have attempted to formally evaluate the effectiveness of HITS and of PageRank.",
                "Amento et al. [1] employed quantitative measures, but based their experiments on the result sets of just 5 queries and the web-graph induced by topical crawls around the result set of each query.",
                "A more recent study by Borodin et al. [4] is based on 34 queries, result sets of 200 pages per query obtained from Google, and a neighborhood graph derived by retrieving 50 in-links per result from Google.",
                "By contrast, our study is based on over 28,000 queries and a web graph covering 2.9 billion URLs. 3.",
                "OUR DATA SETS Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.",
                "Our web graph is based on a web crawl that was conducted in a breadth-first-search fashion, and successfully retrieved 463,685,607 HTML pages.",
                "These pages contain 17,672,011,890 hyperlinks (after eliminating duplicate hyperlinks embedded in the same web page), which refer to a total of 2,897,671,002 URLs.",
                "Thus, at the end of the crawl there were 2,433,985,395 URLs in the frontier set of the crawler that had been discovered, but not yet downloaded.",
                "The mean out-degree of crawled web pages is 38.11; the mean in-degree of discovered pages (whether crawled or not) is 6.10.",
                "Also, it is worth pointing out that there is a lot more variance in in-degrees than in out-degrees; some popular pages have millions of incoming links.",
                "As we will see, this property affects the computational cost of HITS.",
                "Our query set was produced by sampling 28,043 queries from the MSN Search query log, and retrieving a total of 66,846,214 result URLs for these queries (using commercial search engine technology), or about 2,838 results per query on average.",
                "It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.",
                "In fact, only 9,525,566 of the result URLs (about 14.25%) were covered by the graph. 485,656 of the results in the query set (about 0.73% of all results, or about 17.3 results per query) were rated by human judges as to their relevance to the given query, and labeled on a six-point scale (the labels being definitive, excellent, good, fair, bad and detrimental).",
                "Results were selected for judgment based on their commercial search engine placement; in other words, the subset of labeled results is not random, but biased towards documents considered relevant by pre-existing ranking algorithms.",
                "Involving a human in the evaluation process is extremely cumbersome and expensive; however, human judgments are crucial for the evaluation of search engines.",
                "This is so because no document features have been found yet that can effectively estimate the relevance of a document to a user query.",
                "Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.",
                "Evaluating the retrieval results from document scores and human judgments is not trivial and has been the subject of many investigations in the IR community.",
                "A good performance measure should correlate with user satisfaction, taking into account that users will dislike having to delve deep in the results to find relevant documents.",
                "For this reason, standard correlation measures (such as the correlation coefficient between the score and the judgment of a document), or order correlation measures (such as Kendall tau between the score and judgment induced orders) are not adequate. 4.",
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: <br>ndcg</br>, MRR, and MAP.",
                "The normalized discounted cumulative gains (<br>ndcg</br>) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "Such a measure is particularly appropriate for search engines, as studies have shown that search engine users rarely consider anything beyond the first few results [12].",
                "<br>ndcg</br> values are normalized to be between 0 and 1, with 1 being the <br>ndcg</br> of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The discounted cumulative gain at a particular rank-threshold T (DCG@T) is defined to be PT j=1 1 log(1+j) 2r(j) − 1 , where r(j) is the rating (0=detrimental, 1=bad, 2=fair, 3=good, 4=excellent, and 5=definitive) at rank j.",
                "The <br>ndcg</br> is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean <br>ndcg</br>.",
                "The reciprocal rank (RR) of the ranked result set of a query is defined to be the reciprocal value of the rank of the highest-ranking relevant document in the result set.",
                "The RR at rank-threshold T is defined to be 0 if none of the highestranking T documents is relevant.",
                "The mean reciprocal rank (MRR) of a query set is the average reciprocal rank of all queries in the query set.",
                "Given a ranked set of n results, let rel(i) be 1 if the result at rank i is relevant and 0 otherwise.",
                "The precision P(j) at rank j is defined to be 1 j Pj i=1 rel(i), i.e. the fraction of the relevant results among the j highest-ranking results.",
                "The average precision (AP) at rank-threshold k is defined to be Pk i=1 P (i)rel(i) Pn i=1 rel(i) .",
                "The mean average precision (MAP) of a query set is the mean of the average precisions of all queries in the query set.",
                "The above definitions of MRR and MAP rely on the notion of a relevant result.",
                "We investigated two definitions of relevance: One where all documents rated fair or better were deemed relevant, and one were all documents rated good or better were deemed relevant.",
                "For reasons of space, we only report MAP and MRR values computed using the latter definition; using the former definition does not change the qualitative nature of our findings.",
                "Similarly, we computed <br>ndcg</br>, MAP, and MRR values for a wide range of rank-thresholds; we report results here at rank 10; again, changing the rank-threshold never led us to different conclusions.",
                "Recall that over 99% of documents are unlabeled.",
                "We chose to treat all these documents as irrelevant to the query.",
                "For some queries, however, not all relevant documents have been judged.",
                "This introduces a bias into our evaluation: features that bring new documents to the top of the rank may be penalized.",
                "This will be more acute for features less correlated to the pre-existing commercial ranking algorithms used to select documents for judgment.",
                "On the other hand, most queries have few perfect relevant documents (i.e. home page or item searches) and they will most often be within the judged set. 5.",
                "COMPUTING PAGERANK ON A LARGE WEB GRAPH PageRank is a query-independent measure of the importance of web pages, based on the notion of peer-endorsement: A hyperlink from page A to page B is interpreted as an endorsement of page Bs content by page As author.",
                "The following recursive definition captures this notion of endorsement: R(v) = X (u,v)∈E R(u) Out(u) where R(v) is the score (importance) of page v, (u, v) is an edge (hyperlink) from page u to page v contained in the edge set E of the web graph, and Out(u) is the out-degree (number of embedded hyperlinks) of page u.",
                "However, this definition suffers from a severe shortcoming: In the fixedpoint of this recursive equation, only edges that are part of a strongly-connected component receive a non-zero score.",
                "In order to overcome this deficiency, Page et al. grant each page a guaranteed minimum score, giving rise to the definition of standard PageRank: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) where |V | is the size of the vertex set (the number of known web pages), and d is a damping factor, typically set to be between 0.1 and 0.2.",
                "Assuming that scores are normalized to sum up to 1, PageRank can be viewed as the stationary probability distribution of a random walk on the web graph, where at each step of the walk, the walker with probability 1 − d moves from its current node u to a neighboring node v, and with probability d selects a node uniformly at random from all nodes in the graph and jumps to it.",
                "In the limit, the random walker is at node v with probability R(v).",
                "One issue that has to be addressed when implementing PageRank is how to deal with sink nodes, nodes that do not have any outgoing links.",
                "One possibility would be to select another node uniformly at random and transition to it; this is equivalent to adding edges from each sink nodes to all other nodes in the graph.",
                "We chose the alternative approach of introducing a single phantom node.",
                "Each sink node has an edge to the phantom node, and the phantom node has an edge to itself.",
                "In practice, PageRank scores can be computed using power iteration.",
                "Since PageRank is query-independent, the computation can be performed off-line ahead of query time.",
                "This property has been key to PageRanks success, since it is a challenging engineering problem to build a system that can perform any non-trivial computation on the web graph at query time.",
                "In order to compute PageRank scores for all 2.9 billion nodes in our web graph, we implemented a distributed version of PageRank.",
                "The computation consists of two distinct phases.",
                "In the first phase, the link files produced by the web crawler, which contain page URLs and their associated link URLs in textual form, are partitioned among the machines in the cluster used to compute PageRank scores, and converted into a more compact format along the way.",
                "Specifically, URLs are partitioned across the machines in the cluster based on a hash of the URLs host component, and each machine in the cluster maintains a table mapping the URL to a 32-bit integer.",
                "The integers are drawn from a densely packed space, so as to make suitable indices into the array that will later hold the PageRank scores.",
                "The system then translates our log of pages and their associated hyperlinks into a compact representation where both page URLs and link URLs are represented by their associated 32-bit integers.",
                "Hashing the host component of the URLs guarantees that all URLs from the same host are assigned to the same machine in our scoring cluster.",
                "Since over 80% of all hyperlinks on the web are relative (that is, are between two pages on the same host), this property greatly reduces the amount of network communication required by the second stage of the distributed scoring computation.",
                "The second phase performs the actual PageRank power iteration.",
                "Both the link data and the current PageRank vector reside on disk and are read in a streaming fashion; while the new PageRank vector is maintained in memory.",
                "We represent PageRank scores as 64-bit floating point numbers.",
                "PageRank contributions to pages assigned to remote machines are streamed to the remote machine via a TCP connection.",
                "We used a three-machine cluster, each machine equipped with 16 GB of RAM, to compute standard PageRank scores for all 2.9 billion URLs that were contained in our web graph.",
                "We used a damping factor of 0.15, and performed 200 power iterations.",
                "Starting at iteration 165, the L∞ norm of the change in the PageRank vector from one iteration to the next had stopped decreasing, indicating that we had reached as much of a fixed point as the limitations of 64-bit floating point arithmetic would allow. 0.07 0.08 0.09 0.10 0.11 1 10 100 Number of back-links sampled per result <br>ndcg</br>@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Number of back-links sampled per result MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Number of back-links sampled per result MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figure 1: Effectiveness of authority scores computed using different parameterizations of HITS.",
                "A post-processing phase uses the final PageRank vectors (one per machine) and the table mapping URLs to 32-bit integers (representing indices into each PageRank vector) to score the result URL in our query log.",
                "As mentioned above, our web graph covered 9,525,566 of the 66,846,214 result URLs.",
                "These URLs were annotated with their computed PageRank score; all other URLs received a score of 0. 6.",
                "HITS HITS, unlike PageRank, is a query-dependent ranking algorithm.",
                "HITS (which stands for Hypertext Induced Topic Search) is based on the following two intuitions: First, hyperlinks can be viewed as topical endorsements: A hyperlink from a page u devoted to topic T to another page v is likely to endorse the authority of v with respect to topic T. Second, the result set of a particular query is likely to have a certain amount of topical coherence.",
                "Therefore, it makes sense to perform link analysis not on the entire web graph, but rather on just the neighborhood of pages contained in the result set, since this neighborhood is more likely to contain topically relevant links.",
                "But while the set of nodes immediately reachable from the result set is manageable (given that most pages have only a limited number of hyperlinks embedded into them), the set of pages immediately leading to the result set can be enormous.",
                "For this reason, Kleinberg suggests sampling a fixed-size random subset of the pages linking to any high-indegree page in the result set.",
                "Moreover, Kleinberg suggests considering only links that cross host boundaries, the rationale being that links between pages on the same host (intrinsic links) are likely to be navigational or nepotistic and not topically relevant.",
                "Given a web graph (V, E) with vertex set V and edge set E ⊆ V × V , and the set of result URLs to a query (called the root set R ⊆ V ) as input, HITS computes a neighborhood graph consisting of a base set B ⊆ V (the root set and some of its neighboring vertices) and some of the edges in E induced by B.",
                "In order to formalize the definition of the neighborhood graph, it is helpful to first introduce a sampling operator and the concept of a linkselection predicate.",
                "Given a set A, the notation Sn[A] draws n elements uniformly at random from A; Sn[A] = A if |A| ≤ n. A link section predicate P takes an edge (u, v) ∈ E. In this study, we use the following three link section predicates: all(u, v) ⇔ true ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ domain(u) = domain(v) where host(u) denotes the host of URL u, and domain(u) denotes the domain of URL u.",
                "So, all is true for all links, whereas ih is true only for inter-host links, and id is true only for inter-domain links.",
                "The outlinked-set OP of the root set R w.r.t. a linkselection predicate P is defined to be: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} The inlinking-set IP s of the root set R w.r.t. a link-selection predicate P and a sampling value s is defined to be: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] The base set BP s of the root set R w.r.t.",
                "P and s is defined to be: BP s = R ∪ IP s ∪ OP The neighborhood graph (BP s , NP s ) has the base set BP s as its vertex set and an edge set NP s containing those edges in E that are covered by BP s and permitted by P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)} To simplify notation, we write B to denote BP s , and N to denote NP s .",
                "For each node u in the neighborhood graph, HITS computes two scores: an authority score A(u), estimating how authoritative u is on the topic induced by the query, and a hub score H(u), indicating whether u is a good reference to many authoritative pages.",
                "This is done using the following algorithm: 1.",
                "For all u ∈ B do H(u) := q 1 |B| , A(u) := q 1 |B| . 2.",
                "Repeat until H and A converge: (a) For all v ∈ B : A (v) := P (u,v)∈N H(u) (b) For all u ∈ B : H (u) := P (u,v)∈N A(v) (c) H := H 2, A := A 2 where X 2 normalizes the vector X to unit length in euclidean space, i.e. the squares of its elements sum up to 1.",
                "In practice, implementing a system that can compute HITS within the time constraints of a major search engine (where the peak query load is in the thousands of queries per second, and the desired query response time is well below one second) is a major engineering challenge.",
                "Among other things, the web graph cannot reasonably be stored on disk, since .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.20 0.25 bm25f degree-in-id degree-in-ih hits-aut-id-25 hits-aut-ih-100 degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random <br>ndcg</br>@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007 .007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 bm25f hits-aut-id-9 degree-in-id hits-aut-ih-15 degree-in-ih degree-in-all pagerank hits-aut-all-100 hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MAP@10 .273 .132 .126 .117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 bm25f hits-aut-id-9 hits-aut-ih-15 degree-in-id degree-in-ih degree-in-all hits-aut-all-100 pagerank hits-hub-all-100 hits-hub-ih-100 hits-hub-id-100 degree-out-all degree-out-ih degree-out-id random MRR@10 Figure 2: Effectiveness of different features. seek times of modern hard disks are too slow to retrieve the links within the time constraints, and the graph does not fit into the main memory of a single machine, even when using the most aggressive compression techniques.",
                "In order to experiment with HITS and other query-dependent link-based ranking algorithms that require non-regular accesses to arbitrary nodes and edges in the web graph, we implemented a system called the Scalable Hyperlink Store, or SHS for short.",
                "SHS is a special-purpose database, distributed over an arbitrary number of machines that keeps a highly compressed version of the web graph in memory and allows very fast lookup of nodes and edges.",
                "On our hardware, it takes an average of 2 microseconds to map a URL to a 64-bit integer handle called a UID, 15 microseconds to look up all incoming or outgoing link UIDs associated with a page UID, and 5 microseconds to map a UID back to a URL (the last functionality not being required by HITS).",
                "The RPC overhead is about 100 microseconds, but the SHS API allows many lookups to be batched into a single RPC request.",
                "We implemented the HITS algorithm using the SHS infrastructure.",
                "We compiled three SHS databases, one containing all 17.6 billion links in our web graph (all), one containing only links between pages that are on different hosts (ih, for inter-host), and one containing only links between pages that are on different domains (id).",
                "We consider two URLs to belong to different hosts if the host portions of the URLs differ (in other words, we make no attempt to determine whether two distinct symbolic host names refer to the same computer), and we consider a domain to be the name purchased from a registrar (for example, we consider news.bbc.co.uk and www.bbc.co.uk to be different hosts belonging to the same domain).",
                "Using each of these databases, we computed HITS authority and hub scores for various parameterizations of the sampling operator S, sampling between 1 and 100 back-links of each page in the root set.",
                "Result URLs that were not covered by our web graph automatically received authority and hub scores of 0, since they were not connected to any other nodes in the neighborhood graph and therefore did not receive any endorsements.",
                "We performed forty-five different HITS computations, each combining one of the three link selection predicates (all, ih, and id) with a sampling value.",
                "For each combination, we loaded one of the three databases into an SHS system running on six machines (each equipped with 16 GB of RAM), and computed HITS authority and hub scores, one query at a time.",
                "The longest-running combination (using the all database and sampling 100 back-links of each root set vertex) required 30,456 seconds to process the entire query set, or about 1.1 seconds per query on average. 7.",
                "EXPERIMENTAL RESULTS For a given query Q, we need to rank the set of documents satisfying Q (the result set of Q).",
                "Our hypothesis is that good features should be able to rank relevant documents in this set higher than non-relevant ones, and this should result in an increase in each performance measure over the query set.",
                "We are specifically interested in evaluating the usefulness of HITS and other link-based features.",
                "In principle, we could do this by sorting the documents in each result set by their feature value, and compare the resulting NDCGs.",
                "We call this ranking with isolated features.",
                "Let us first examine the relative performance of the different parameterizations of the HITS algorithm we examined.",
                "Recall that we computed HITS for each combination of three link section schemes - all links (all), inter-host links only (ih), and inter-domain links only (id) - with back-link sampling values ranging from 1 to 100.",
                "Figure 1 shows the impact of the number of sampled back-links on the retrieval performance of HITS authority scores.",
                "Each graph is associated with one performance measure.",
                "The horizontal axis of each graph represents the number of sampled back-links, the vertical axis represents performance under the appropriate measure, and each curve depicts a link selection scheme.",
                "The id scheme slightly outperforms ih, and both vastly outperform the all scheme - eliminating nepotistic links pays off.",
                "The performance of the all scheme increases as more back-links of each root set vertex are sampled, while the performance of the id and ih schemes peaks at between 10 and 25 samples and then plateaus or even declines, depending on the performance measure.",
                "Having compared different parameterizations of HITS, we will now fix the number of sampled back-links at 100 and compare the three link selection schemes against other isolated features: PageRank, in-degree and out-degree counting links of all pages, of different hosts only and of different domains only (all, ih and id datasets respectively), and a text retrieval algorithm exploiting anchor text: BM25F[24].",
                "BM25F is a state-of-the art ranking function solely based on textual content of the documents and their associated anchor texts.",
                "BM25F is a descendant of BM25 that combines the different textual fields of a document, namely title, body and anchor text.",
                "This model has been shown to be one of the best-performing web search scoring functions over the last few years [8, 24].",
                "BM25F has a number of free parameters (2 per field, 6 in our case); we used the parameter values described in [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f <br>ndcg</br>@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 degree-in-ih degree-in-id degree-in-all hits-aut-ih-100 hits-aut-all-100 hits-aut-id-10 pagerank hits-hub-all-100 degree-out-ih hits-hub-id-100 degree-out-all degree-out-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 degree-in-id degree-in-ih degree-in-all hits-aut-ih-100 hits-aut-all-100 pagerank hits-aut-id-10 degree-out-all hits-hub-all-100 degree-out-ih hits-hub-ih-100 degree-out-id hits-hub-id-10 bm25f MRR@10 Figure 3: Effectiveness measures for linear combinations of link-based features with BM25F.",
                "Figure 2 shows the <br>ndcg</br>, MRR, and MAP measures of these features.",
                "Again all performance measures (and for all rank-thresholds we explored) agree.",
                "As expected, BM25F outperforms all link-based features by a large margin.",
                "The link-based features are divided into two groups, with a noticeable performance drop between the groups.",
                "The better-performing group consists of the features that are based on the number and/or quality of incoming links (in-degree, PageRank, and HITS authority scores); and the worse-performing group consists of the features that are based on the number and/or quality of outgoing links (outdegree and HITS hub scores).",
                "In the group of features based on incoming links, features that ignore nepotistic links perform better than their counterparts using all links.",
                "Moreover, using only inter-domain (id) links seems to be marginally better than using inter-host (ih) links.",
                "The fact that features based on outgoing links underperform those based on incoming links matches our expectations; if anything, it is mildly surprising that outgoing links provide a useful signal for ranking at all.",
                "On the other hand, the fact that in-degree features outperform PageRank under all measures is quite surprising.",
                "A possible explanation is that link-spammers have been targeting the published PageRank algorithm for many years, and that this has led to anomalies in the web graph that affect PageRank, but not other link-based features that explore only a distance-1 neighborhood of the result set.",
                "Likewise, it is surprising that simple query-independent features such as in-degree, which might estimate global quality but cannot capture relevance to a query, would outperform query-dependent features such as HITS authority scores.",
                "However, we cannot investigate the effect of these features in isolation, without regard to the overall ranking function, for several reasons.",
                "First, features based on the textual content of documents (as opposed to link-based features) are the best predictors of relevance.",
                "Second, link-based features can be strongly correlated with textual features for several reasons, mainly the correlation between in-degree and numFeature Transform function bm25f T(s) = s pagerank T(s) = log(s + 3 · 10−12 ) degree-in-* T(s) = log(s + 3 · 10−2 ) degree-out-* T(s) = log(s + 3 · 103 ) hits-aut-* T(s) = log(s + 3 · 10−8 ) hits-hub-* T(s) = log(s + 3 · 10−1 ) Table 1: Near-optimal feature transform functions. ber of textual anchor matches.",
                "Therefore, one must consider the effect of link-based features in combination with textual features.",
                "Otherwise, we may find a link-based feature that is very good in isolation but is strongly correlated with textual features and results in no overall improvement; and vice versa, we may find a link-based feature that is weak in isolation but significantly improves overall performance.",
                "For this reason, we have studied the combination of the link-based features above with BM25F.",
                "All feature combinations were done by considering the linear combination of two features as a document score, using the formula score(d) =Pn i=1 wiTi(Fi(d)), where d is a document (or documentquery pair, in the case of BM25F), Fi(d) (for 1 ≤ i ≤ n) is a feature extracted from d, Ti is a transform, and wi is a free scalar weight that needs to be tuned.",
                "We chose transform functions that we empirically determined to be well-suited.",
                "Table 1 shows the chosen transform functions.",
                "This type of linear combination is appropriate if we assume features to be independent with respect to relevance and an exponential model for link features, as discussed in [8].",
                "We tuned the weights by selecting a random subset of 5,000 queries from the query set, used an iterative refinement process to find weights that maximized a given performance measure on that training set, and used the remaining 23,043 queries to measure the performance of the thus derived scoring functions.",
                "We explored the pairwise combination of BM25F with every link-based scoring function.",
                "Figure 3 shows the <br>ndcg</br>, MRR, and MAP measures of these feature combinations, together with a baseline BM25F score (the right-most bar in each graph), which was computed using the same subset of 23,045 queries that were used as the test set for the feature combinations.",
                "Regardless of the performance measure applied, we can make the following general observations: 1.",
                "Combining any of the link-based features with BM25F results in a substantial performance improvement over BM25F in isolation. 2.",
                "The combination of BM25F with features based on incoming links (PageRank, in-degree, and HITS authority scores) performs substantially better than the combination with features based on outgoing links (HITS hub scores and out-degree). 3.",
                "The performance differences between the various combinations of BM25F with features based on incoming links is comparatively small, and the relative ordering of feature combinations is fairly stable across the 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 8 10 12 14 16 18 20 22 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 bm25fnorm pagerank degree-in-id hits-aut-id-100 Figure 4: Effectiveness measures for selected isolated features, broken down by query specificity. ferent performance measures used.",
                "However, the combination of BM25F with any in-degree variant, and in particular with id in-degree, consistently outperforms the combination of BM25F with PageRank or HITS authority scores, and can be computed much easier and faster.",
                "Finally, we investigated whether certain features are better for some queries than for others.",
                "Particularly, we are interested in the relationship between the specificity of a query and the performance of different ranking features.",
                "The most straightforward measure of the specificity of a query Q would be the number of documents in a search engines corpus that satisfy Q.",
                "Unfortunately, the query set available to us did not contain this information.",
                "Therefore, we chose to approximate the specificity of Q by summing up the inverse document frequencies of the individual query terms comprising Q.",
                "The inverse document frequency (IDF) of a term t with respect to a corpus C is defined to be logN/doc(t), where doc(t) is the number of documents in C containing t and N is the total number of documents in C. By summing up the IDFs of the query terms, we make the (flawed) assumption that the individual query terms are independent of each other.",
                "However, while not perfect, this approximation is at least directionally correct.",
                "We broke down our query set into 13 buckets, each bucket associated with an interval of query IDF values, and we computed performance metrics for all ranking functions applied (in isolation) to the queries in each bucket.",
                "In order to keep the graphs readable, we will not show the performance of all the features, but rather restrict ourselves to the four most interesting ones: PageRank, id HITS authority scores, id in-degree, and BM25F.",
                "Figure 4 shows the MAP@10 for all 13 query specificity buckets.",
                "Buckets on the far left of each graph represent very general queries; buckets on the far right represent very specific queries.",
                "The figures on the upper x axis of each graph show the number of queries in each bucket (e.g. the right-most bucket contains 1,629 queries).",
                "BM25F performs best for medium-specific queries, peaking at the buckets representing the IDF sum interval [12,14).",
                "By comparison, HITS peaks at the bucket representing the IDF sum interval [4,6), and PageRank and in-degree peak at the bucket representing the interval [6,8), i.e. more general queries. 8.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a large-scale evaluation of the effectiveness of HITS in comparison with other link-based ranking algorithms, in particular PageRank and in-degree, when applied in isolation or in combination with a text retrieval algorithm exploiting anchor text (BM25F).",
                "Evaluation is carried out with respect to a large number of human evaluated queries, using three different measures of effectiveness: <br>ndcg</br>, MRR, and MAP.",
                "Evaluating link-based features in isolation, we found that web page in-degree outperforms PageRank, and is about as effwective as HITS authority scores.",
                "HITS hub scores and web page out-degree are much less effective ranking features, but still outperform a random ordering.",
                "A linear combination of any link-based features with BM25F produces a significant improvement in performance, and there is a clear difference between combining BM25F with a feature based on incoming links (indegree, PageRank, or HITS authority scores) and a feature based on outgoing links (HITS hub scores and out-degree), but within those two groups the precise choice of link-based feature matters relatively little.",
                "We believe that the measurements presented in this paper provide a solid evaluation of the best well-known link-based ranking schemes.",
                "There are many possible variants of these schemes, and many other link-based ranking algorithms have been proposed in the literature, hence we do not claim this work to be the last word on this subject, but rather the first step on a long road.",
                "Future work includes evaluation of different parameterizations of PageRank and HITS.",
                "In particular, we would like to study the impact of changes to the PageRank damping factor on effectiveness, the impact of various schemes meant to counteract the effects of link spam, and the effect of weighing hyperlinks differently depending on whether they are nepotistic or not.",
                "Going beyond PageRank and HITS, we would like to measure the effectiveness of other link-based ranking algorithms, such as SALSA.",
                "Finally, we are planning to experiment with more complex feature combinations. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of web documents.",
                "In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 296-303, 2000. [2] M. Bianchini, M. Gori, and F. Scarselli.",
                "Inside PageRank.",
                "ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, and J. S. Rosenthal.",
                "Finding authorities and hubs from link structures on the World Wide Web.",
                "In Proc. of the 10th International World Wide Web Conference, pages 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas.",
                "Link analysis ranking: algorithms, theory, and experiments.",
                "ACM Transactions on Interet Technology, 5(1):231-297, 2005. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual Web search engine.",
                "Computer Networks and ISDN Systems, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proc. of the 22nd International Conference on Machine Learning, pages 89-96, New York, NY, USA, 2005.",
                "ACM Press. [7] D. Cohn and H. Chang.",
                "Learning to probabilistically identify authoritative documents.",
                "In Proc. of the 17th International Conference on Machine Learning, pages 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proc. of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 416-423, 2005. [9] E. Garfield.",
                "Citation analysis as a tool in journal evaluation.",
                "Science, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi and H. Garcia-Molina.",
                "Web spam taxonomy.",
                "In 1st International Workshop on Adversarial Information Retrieval on the Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with TrustRank.",
                "In Proc. of the 30th International Conference on Very Large Databases, pages 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic.",
                "Real life information retrieval: a study of user queries on the web.",
                "ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. J¨arvelin and J. Kek¨al¨ainen.",
                "Cumulated gain-based evaluation of IR techniques.",
                "ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating PageRank computations.",
                "In Proc. of the 12th International World Wide Web Conference, pages 261-270, 2003. [15] M. M. Kessler.",
                "Bibliographic coupling between scientific papers.",
                "American Documentation, 14(1):10-25, 1963. [16] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "In Proc. of the 9th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 668-677, 1998. [17] J. M. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, 1999. [18] A. N. Langville and C. D. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics, 1(3):2005, 335-380. [19] R. Lempel and S. Moran.",
                "The stochastic approach for link-structure analysis (SALSA) and the TKC effect.",
                "Computer Networks and ISDN Systems, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng, and M. I. Jordan.",
                "Stable algorithms for link analysis.",
                "In Proc. of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 258-266, 2001. [21] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford Digital Library Technologies Project, 1998. [22] J.",
                "A. Tomlin.",
                "A new paradigm for ranking pages on the World Wide Web.",
                "In Proc. of the 12th International World Wide Web Conference, pages 350-355, 2003. [23] T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: Pagerank or indegree?",
                "In Proc. of the Australasian Document Computing Symposium, pages 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria, and S. Robertson.",
                "Microsoft Cambridge at TREC-13: Web and HARD tracks.",
                "In Proc. of the 13th Text Retrieval Conference, 2004."
            ],
            "original_annotated_samples": [
                "MEASURING PERFORMANCE In this study, we quantify the effectiveness of various ranking algorithms using three measures: <br>ndcg</br>, MRR, and MAP.",
                "The normalized discounted cumulative gains (<br>ndcg</br>) measure [13] discounts the contribution of a document to the overall score as the documents rank increases (assuming that the best document has the lowest rank).",
                "<br>ndcg</br> values are normalized to be between 0 and 1, with 1 being the <br>ndcg</br> of a perfect ranking scheme that completely agrees with the assessment of the human judges.",
                "The <br>ndcg</br> is computed by dividing the DCG of a ranking by the highest possible DCG that can be obtained for that query.",
                "Finally, the NDGCs of all queries in the query set are averaged to produce a mean <br>ndcg</br>."
            ],
            "translated_annotated_samples": [
                "En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: <br>NDCG</br>, MRR y MAP.",
                "La medida de ganancias acumuladas descontadas normalizadas (<br>NDCG</br>) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo).",
                "Los valores de <br>NDCG</br> se normalizan para estar entre 0 y 1, siendo 1 el <br>NDCG</br> de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos.",
                "El <br>NDCG</br> se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta.",
                "Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un <br>NDCG</br> medio."
            ],
            "translated_text": "HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! \n\nMarc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: <br>NDCG</br>, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (<br>NDCG</br>) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de <br>NDCG</br> se normalizan para estar entre 0 y 1, siendo 1 el <br>NDCG</br> de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El <br>NDCG</br> se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un <br>NDCG</br> medio. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}