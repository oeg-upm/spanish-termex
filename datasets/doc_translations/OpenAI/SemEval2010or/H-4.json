{
    "id": "H-4",
    "original_text": "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information. A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated. This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations. The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information. In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties. In the first part, we present a diary study of information re-finding tasks. The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages. In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation. Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1. INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information. PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular. However the evaluation of these PIM systems is problematic. One of the main difficulties is caused by the personal nature of PIM. People collect information as a natural consequence of completing other tasks. This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences. As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation. Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation. The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections. Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations. A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7]. Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation. For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible. Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level. In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations. In the first part of this paper we present a diary study of information re-finding tasks. The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages. We also look at the features of the tasks that make re-finding difficult. In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation. Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2. RELATED WORK A variety of approaches are available to study PIM. Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments. These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM. As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks. A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15]. Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7]. Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues. Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations. Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings. An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis. This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system. In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved. Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer. Nevertheless, there are limitations to this strategy. Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants. Developing a research prototype to this standard is beyond the resources of many researchers. Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time. It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs. This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks. Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope. One difficulty in performing this kind of evaluation is sourcing collections to evaluate. Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research. This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13]. However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection. One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab. This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21]. The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access. Another solution is to use the entire web as a collection when studying web page re-finding [4]. This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5]. A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection. Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26]. A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour. For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3]. Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2]. However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before. Consequently, it is difficult to devise simulated work task situations for PIM. The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22]. There have been other suggestions as to how to classify PIM tasks. For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24]. While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks. Personal collections are one reason why task creation is so difficult. Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised. Systems can then be compared across task types for different users [11]. Unfortunately, no equivalent taxonomy exists for other types of information object. Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11]. This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants? A few methods have been proposed. For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants. This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks. Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties. In section 4 we show that people perform a wider range of email re-finding tasks than this. In [4], generic search tasks were artificially created by running evaluations over two sessions. In the first session, participants were asked to complete work tasks that involved finding some unknown information. In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour. The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives. Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period. Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested. Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants. In the following section we present a diary study of refinding tasks for email and web pages. The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22]. In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations. We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants. This knowledge can then be used to construct tasks for use in PIM evaluations. 3. METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer. Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation. In our diary study, we followed the suggestions in [12] to achieve the best possible data. To this end, we restricted the recorded tasks to web and email re-finding. By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained. The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed. Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen. The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing. This description was to contain both the information that the participant wished to find and the reason that they needed the information. To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session. The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples. The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected. The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard). Finally, they were asked when was the last time they looked at the sought after information. Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago). Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks. The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students. The ages of participants ranged from 19-59. As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4. RESULTS Several analyses were performed on the captured data. The following sections present the findings. Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web. Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants. Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased. As with most diary studies, the number of tasks recorded varied extensively between particpants. The median number of tasks per participant was 8 (interquartile range (IQR)=9.5). More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3). This means that on average each participant recorded approximately one task every two days. From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding. Based on this observation a joint classification scheme was devised, encompassing both email and web tasks. The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks. Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known. Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical. Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner. This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project. I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task. Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for. Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information. In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource. Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages. Often these tasks required the user to process or collate the information in order to solve the task. Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend. Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework. Remind myself of what it is and what it does. Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify. For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper). It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource. There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item. For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page. It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email. Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box. Decided to use some other means Such tasks were labelled as U for unclassifiable. To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks. The agreement between the results of the two analyses was largely consistent (96.8%). Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks. The second researcher achieved a 90% agreement. We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme. The distribution of task types is shown in table 1. Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded. The distribution of the task types was different for web and email re-finding. The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item). Another distinction was the number of recorded multi-item tasks for web and email. Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%). Lookup Item Multi-item Unclass. Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold. We classified the tasks using the form data. Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold. Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified. The remainder were defined as U for unclassifiable. A cross-tabulation of task types and temperatures is shown in table 2. Hot Warm Cold Unclass. Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week. However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information. This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23]. This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult? We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others. For example, we examined whether the media type affected how difficult the participants perceived the task to be. There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult. We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult. Figure 1 shows this information graphically. Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot. To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05). For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593). For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272). These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be. Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be. To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks. We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources. It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks. Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be. These findings have implications for evaluating PIM behaviour at the task level. The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5. TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions. Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems. This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item). In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks. Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections. This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment. There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task. Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date. Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs. To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks. The tasks were selected randomly from the pool of those available. The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks. The issued tasks represented a broad-sampling of the complete set of recorded tasks. They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper. Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task? Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice. Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed. Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances. Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation. Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions. These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality. However, did the diary study generate enough tasks to satisfy the needs of experimenters? Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc. However, for illustrative purposes we chose 5 tasks as a cut-off point for our data. From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks. This means that many of the recruited participants could not actually participate in the final evaluation. This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations. Further, there was some imbalance in the numbers of recorded tasks of different types. Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks. There was also a specific lack of multi-item email tasks. This situation makes it very difficult for experimenters to prepare balanced experimental designs. Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation. However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy. This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1. We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour. Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation. As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks. The collected data revealed several patterns that helped with the creation of artificial tasks. For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information. This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections. Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source. For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies. There were also tasks that were recorded by participants in both groups. For example, searching for an email that would re-confirm the pin code required to access the computer labs. To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours. These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies. This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17]. Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs. Again, patterns emerged that helped with task creation. We found content overlap within and between groups that confirmed many of our observations from the diary study data. For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies. Importantly, the participants were also able to confirm which other students had received the same information. This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups. Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants. We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive. Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed. When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2]. A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures. If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study. The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design. Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment. The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy. The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type. Some of the findings of the evaluation will be published in [10]. Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy. More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6. CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations. The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks. We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections. This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections. In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations. In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages. The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks. We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources. In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation. We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy. We also suggested two methods of creating tasks that can be completed on personal collections. These methods do not compromise the privacy of study participants. We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation. Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users. Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7. ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8. REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc. SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds.), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch. Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no. SI, 207-210. [18] M.W. Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc. UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E. Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60.",
    "original_translation": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60.",
    "original_sentences": [
        "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
        "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
        "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
        "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
        "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
        "In the first part, we present a diary study of information re-finding tasks.",
        "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
        "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
        "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
        "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
        "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
        "However the evaluation of these PIM systems is problematic.",
        "One of the main difficulties is caused by the personal nature of PIM.",
        "People collect information as a natural consequence of completing other tasks.",
        "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
        "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
        "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
        "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
        "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
        "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
        "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
        "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
        "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
        "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
        "In the first part of this paper we present a diary study of information re-finding tasks.",
        "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
        "We also look at the features of the tasks that make re-finding difficult.",
        "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
        "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
        "RELATED WORK A variety of approaches are available to study PIM.",
        "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
        "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
        "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
        "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
        "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
        "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
        "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
        "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
        "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
        "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
        "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
        "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
        "Nevertheless, there are limitations to this strategy.",
        "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
        "Developing a research prototype to this standard is beyond the resources of many researchers.",
        "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
        "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
        "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
        "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
        "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
        "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
        "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
        "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
        "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
        "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
        "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
        "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
        "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
        "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
        "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
        "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
        "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
        "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
        "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
        "Consequently, it is difficult to devise simulated work task situations for PIM.",
        "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
        "There have been other suggestions as to how to classify PIM tasks.",
        "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
        "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
        "Personal collections are one reason why task creation is so difficult.",
        "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
        "Systems can then be compared across task types for different users [11].",
        "Unfortunately, no equivalent taxonomy exists for other types of information object.",
        "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
        "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
        "A few methods have been proposed.",
        "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
        "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
        "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
        "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
        "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
        "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
        "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
        "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
        "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
        "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
        "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
        "In the following section we present a diary study of refinding tasks for email and web pages.",
        "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
        "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
        "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
        "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
        "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
        "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
        "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
        "To this end, we restricted the recorded tasks to web and email re-finding.",
        "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
        "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
        "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
        "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
        "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
        "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
        "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
        "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
        "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
        "Finally, they were asked when was the last time they looked at the sought after information.",
        "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
        "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
        "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
        "The ages of participants ranged from 19-59.",
        "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
        "RESULTS Several analyses were performed on the captured data.",
        "The following sections present the findings.",
        "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
        "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
        "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
        "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
        "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
        "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
        "This means that on average each participant recorded approximately one task every two days.",
        "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
        "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
        "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
        "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
        "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
        "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
        "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
        "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
        "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
        "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
        "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
        "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
        "Often these tasks required the user to process or collate the information in order to solve the task.",
        "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
        "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
        "Remind myself of what it is and what it does.",
        "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
        "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
        "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
        "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
        "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
        "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
        "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
        "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
        "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
        "The agreement between the results of the two analyses was largely consistent (96.8%).",
        "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
        "The second researcher achieved a 90% agreement.",
        "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
        "The distribution of task types is shown in table 1.",
        "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
        "The distribution of the task types was different for web and email re-finding.",
        "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
        "Another distinction was the number of recorded multi-item tasks for web and email.",
        "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
        "Lookup Item Multi-item Unclass.",
        "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
        "We classified the tasks using the form data.",
        "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
        "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
        "The remainder were defined as U for unclassifiable.",
        "A cross-tabulation of task types and temperatures is shown in table 2.",
        "Hot Warm Cold Unclass.",
        "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
        "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
        "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
        "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
        "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
        "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
        "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
        "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
        "Figure 1 shows this information graphically.",
        "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
        "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
        "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
        "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
        "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
        "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
        "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
        "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
        "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
        "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
        "These findings have implications for evaluating PIM behaviour at the task level.",
        "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
        "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
        "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
        "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
        "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
        "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
        "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
        "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
        "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
        "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
        "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
        "The tasks were selected randomly from the pool of those available.",
        "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
        "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
        "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
        "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
        "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
        "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
        "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
        "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
        "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
        "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
        "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
        "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
        "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
        "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
        "This means that many of the recruited participants could not actually participate in the final evaluation.",
        "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
        "Further, there was some imbalance in the numbers of recorded tasks of different types.",
        "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
        "There was also a specific lack of multi-item email tasks.",
        "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
        "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
        "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
        "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
        "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
        "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
        "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
        "The collected data revealed several patterns that helped with the creation of artificial tasks.",
        "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
        "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
        "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
        "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
        "There were also tasks that were recorded by participants in both groups.",
        "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
        "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
        "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
        "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
        "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
        "Again, patterns emerged that helped with task creation.",
        "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
        "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
        "Importantly, the participants were also able to confirm which other students had received the same information.",
        "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
        "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
        "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
        "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
        "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
        "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
        "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
        "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
        "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
        "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
        "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
        "Some of the findings of the evaluation will be published in [10].",
        "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
        "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
        "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
        "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
        "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
        "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
        "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
        "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
        "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
        "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
        "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
        "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
        "We also suggested two methods of creating tasks that can be completed on personal collections.",
        "These methods do not compromise the privacy of study participants.",
        "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
        "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
        "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
        "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
        "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
        "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
        "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
        "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
        "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
        "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
        "SI, 207-210. [18] M.W.",
        "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
        "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
        "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
        "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
    ],
    "translated_text_sentences": [
        "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información.",
        "Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados.",
        "Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM.",
        "Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal.",
        "En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades.",
        "En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información.",
        "El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web.",
        "En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas.",
        "Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1.",
        "INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información.",
        "Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares.",
        "Sin embargo, la evaluación de estos sistemas PIM es problemática.",
        "Una de las principales dificultades es causada por la naturaleza personal de PIM.",
        "Las personas recopilan información como una consecuencia natural de completar otras tareas.",
        "Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario.",
        "Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación.",
        "En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación.",
        "La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales.",
        "Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM.",
        "Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7].",
        "Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM.",
        "Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible.",
        "Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea.",
        "En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio.",
        "En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información.",
        "El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web.",
        "También analizamos las características de las tareas que dificultan volver a encontrarlas.",
        "En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas.",
        "Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales.",
        "TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM.",
        "Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares.",
        "Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM.",
        "Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas.",
        "Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15].",
        "Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7].",
        "Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas.",
        "En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes.",
        "En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados.",
        "Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro.",
        "Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema.",
        "En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados.",
        "El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador.",
        "Sin embargo, existen limitaciones a esta estrategia.",
        "En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes.",
        "Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores.",
        "Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento.",
        "Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros.",
        "Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas.",
        "Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado.",
        "Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar.",
        "Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM.",
        "Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13].",
        "Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida.",
        "Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio.",
        "Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21].",
        "La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota.",
        "Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4].",
        "Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5].",
        "Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal.",
        "Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26].",
        "Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario.",
        "Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3].",
        "Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2].",
        "Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes.",
        "En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM.",
        "La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22].",
        "Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM.",
        "Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24].",
        "Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas.",
        "Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil.",
        "La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas.",
        "Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11].",
        "Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información.",
        "Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11].",
        "Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio?",
        "Se han propuesto algunos métodos.",
        "Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio.",
        "Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas.",
        "Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes.",
        "En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta.",
        "En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones.",
        "En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida.",
        "En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro.",
        "Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas.",
        "Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo.",
        "Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida.",
        "Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio.",
        "En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web.",
        "El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22].",
        "En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas.",
        "Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes.",
        "Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3.",
        "Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador.",
        "Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación.",
        "En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles.",
        "Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos.",
        "Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían.",
        "A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron.",
        "Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo.",
        "El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando.",
        "Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información.",
        "Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria.",
        "El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos.",
        "Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados.",
        "El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil).",
        "Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada.",
        "Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año).",
        "La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas.",
        "La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado.",
        "Las edades de los participantes oscilaron entre 19 y 59 años.",
        "Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4.",
        "RESULTADOS Se realizaron varios análisis en los datos capturados.",
        "Las siguientes secciones presentan los hallazgos.",
        "En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web.",
        "A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes.",
        "Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web.",
        "Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes.",
        "La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5).",
        "Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3).",
        "Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días.",
        "A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web.",
        "Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web.",
        "Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos.",
        "Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido.",
        "Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica.",
        "Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo.",
        "Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante.",
        "Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea.",
        "Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando.",
        "Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información.",
        "En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso.",
        "Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico.",
        "A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea.",
        "Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana.",
        "Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo.",
        "Recordarme qué es y qué hace.",
        "Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar.",
        "Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo.",
        "Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso.",
        "Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos.",
        "Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web.",
        "También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico.",
        "Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje.",
        "Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables.",
        "Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas.",
        "La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%).",
        "Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas.",
        "El segundo investigador logró un acuerdo del 90%.",
        "Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación.",
        "La distribución de tipos de tareas se muestra en la tabla 1.",
        "En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas.",
        "La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico.",
        "La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento).",
        "Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico.",
        "Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%).",
        "Buscar Elemento Multi-elemento No Clasificado.",
        "Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría.",
        "Clasificamos las tareas utilizando los datos del formulario.",
        "La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría.",
        "Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas.",
        "El resto fueron definidos como U para no clasificables.",
        "Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2.",
        "Caliente Cálido Frío Sin clasificar.",
        "Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana.",
        "Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua.",
        "Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23].",
        "Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles?",
        "Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras.",
        "Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea.",
        "No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles.",
        "También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil.",
        "La Figura 1 muestra esta información gráficamente.",
        "Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente.",
        "Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05).",
        "Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593).",
        "Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272).",
        "Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea.",
        "Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea.",
        "Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico.",
        "Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos.",
        "Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos.",
        "Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes.",
        "Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea.",
        "El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5.",
        "Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio.",
        "Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas.",
        "Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos).",
        "En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales.",
        "Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones.",
        "Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado.",
        "También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea.",
        "Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior.",
        "En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos.",
        "Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas.",
        "Las tareas fueron seleccionadas al azar del conjunto de las disponibles.",
        "Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos.",
        "Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas.",
        "También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo.",
        "No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla?",
        "Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran.",
        "De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía.",
        "Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias.",
        "Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación.",
        "Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea.",
        "Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente.",
        "¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores?",
        "Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc.",
        "Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos.",
        "De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web.",
        "Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final.",
        "Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones.",
        "Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos.",
        "Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda.",
        "También hubo una falta específica de tareas de correo electrónico con varios elementos.",
        "Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados.",
        "Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales.",
        "Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes.",
        "Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1.",
        "Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos.",
        "Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas.",
        "Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas.",
        "Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales.",
        "Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información.",
        "Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones.",
        "Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente.",
        "Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo.",
        "También hubo tareas que fueron registradas por los participantes en ambos grupos.",
        "Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación.",
        "Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos.",
        "Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas.",
        "Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17].",
        "Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades.",
        "Una vez más, surgieron patrones que ayudaron con la creación de tareas.",
        "Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario.",
        "Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo.",
        "Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información.",
        "Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos.",
        "Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes.",
        "También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas.",
        "Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara.",
        "Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2].",
        "Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad.",
        "Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario.",
        "Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino.",
        "Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado.",
        "El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía.",
        "La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo.",
        "Algunos de los hallazgos de la evaluación se publicarán en [10].",
        "Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía.",
        "Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6.",
        "CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM.",
        "La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas.",
        "Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones.",
        "Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales.",
        "En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas.",
        "En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web.",
        "Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico.",
        "Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos.",
        "En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM.",
        "Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía.",
        "También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales.",
        "Estos métodos no comprometen la privacidad de los participantes del estudio.",
        "Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa.",
        "Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios.",
        "Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales.",
        "AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8.",
        "REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc.",
        "SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc.",
        "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc.",
        "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc.",
        "ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap.",
        "Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no.",
        "Sí, 207-210. [18] M.W.",
        "Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc.",
        "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc.",
        "UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E.",
        "Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60."
    ],
    "error_count": 7,
    "keys": {
        "personal information management": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based <br>personal information management</br> Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT <br>personal information management</br> (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION <br>personal information management</br> (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for <br>personal information management</br>, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on <br>personal information management</br>, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting <br>personal information management</br> tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) <br>personal information management</br>, ch.",
                "Understanding what works: Evaluating <br>personal information management</br> tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of <br>personal information management</br>., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "Towards Task-based <br>personal information management</br> Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT <br>personal information management</br> (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "INTRODUCTION <br>personal information management</br> (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "REFERENCES [1] R. Boardman, Improving tool support for <br>personal information management</br>, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on <br>personal information management</br>, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting <br>personal information management</br> tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) <br>personal information management</br>, ch."
            ],
            "translated_annotated_samples": [
                "Hacia Evaluaciones de <br>Gestión de Información Personal</br> basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La <br>Gestión de Información Personal</br> (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información.",
                "INTRODUCCIÓN La <br>Gestión de la Información Personal</br> (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información.",
                "REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la <br>gestión de información personal</br>, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de <br>gestión de información personal</br> que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) <br>gestión de información personal</br>, cap."
            ],
            "translated_text": "Hacia Evaluaciones de <br>Gestión de Información Personal</br> basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La <br>Gestión de Información Personal</br> (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La <br>Gestión de la Información Personal</br> (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la <br>gestión de información personal</br>, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de <br>gestión de información personal</br> que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) <br>gestión de información personal</br>, cap. ",
            "candidates": [],
            "error": [
                [
                    "Gestión de Información Personal",
                    "Gestión de Información Personal",
                    "Gestión de la Información Personal",
                    "gestión de información personal",
                    "gestión de información personal",
                    "gestión de información personal"
                ]
            ]
        },
        "measurement": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms <br>measurement</br>Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: <br>measurement</br> and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms <br>measurement</br>Management,Experimentation, Human Factors 1.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: <br>measurement</br> and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch."
            ],
            "translated_annotated_samples": [
                "Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60. ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "experimenter": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an <br>experimenter</br> to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the <br>experimenter</br> can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The <br>experimenter</br> ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "Both ethnographic and fieldwork methods require the presence of an <br>experimenter</br> to assess how PIM is performed, which raises a number of issues.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the <br>experimenter</br> can relate the behaviour of study participants to goals associated with known search tasks.",
                "The <br>experimenter</br> ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples."
            ],
            "translated_annotated_samples": [
                "Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un <br>experimentador</br> para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas.",
                "Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde <br>el experimentador</br> pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas.",
                "El <br>experimentador</br> se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un <br>experimentador</br> para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde <br>el experimentador</br> pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El <br>experimentador</br> se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60. ",
            "candidates": [],
            "error": [
                [
                    "experimentador",
                    "el experimentador",
                    "experimentador"
                ]
            ]
        },
        "human factor": {
            "translated_key": "factor humano",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "re-find information": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and <br>re-find information</br>.",
                "A feature of PIM research is that many systems have been designed to assist users manage and <br>re-find information</br>, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people <br>re-find information</br> from within unique personal collections; researchers know little about the tasks that cause people to <br>re-find information</br>; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to <br>re-find information</br> and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and <br>re-find information</br>.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to <br>re-find information</br> and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or <br>re-find information</br> that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users <br>re-find information</br>, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and <br>re-find information</br>.",
                "A feature of PIM research is that many systems have been designed to assist users manage and <br>re-find information</br>, but very few have been evaluated.",
                "The difficulties include that people <br>re-find information</br> from within unique personal collections; researchers know little about the tasks that cause people to <br>re-find information</br>; and numerous privacy issues concerning personal information.",
                "The study examines the kind of tasks that require users to <br>re-find information</br> and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and <br>re-find information</br>."
            ],
            "translated_annotated_samples": [
                "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información.",
                "Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados.",
                "Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a <br>volver a encontrar información</br>; y numerosos problemas de privacidad relacionados con la información personal.",
                "El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de <br>reencuentro</br> para mensajes de correo electrónico y páginas web.",
                "INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a <br>volver a encontrar información</br>; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de <br>reencuentro</br> para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. ",
            "candidates": [],
            "error": [
                [
                    "volver a encontrar información",
                    "reencuentro"
                ]
            ]
        },
        "privacy issue": {
            "translated_key": "problemas de privacidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous <br>privacy issue</br>s concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that <br>privacy issue</br>s were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous <br>privacy issue</br>s concerning personal information.",
                "This approach ensured that <br>privacy issue</br>s were avoided and participants could use things that they remember to complete tasks."
            ],
            "translated_annotated_samples": [
                "Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos <br>problemas de privacidad</br> relacionados con la información personal.",
                "Este enfoque garantizó que se evitaran <br>problemas de privacidad</br> y que los participantes pudieran utilizar cosas que recordaban para completar las tareas."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos <br>problemas de privacidad</br> relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran <br>problemas de privacidad</br> y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "taxonomy": {
            "translated_key": "taxonomía",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a <br>taxonomy</br> of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a <br>taxonomy</br> of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task <br>taxonomy</br> provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent <br>taxonomy</br> exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the <br>taxonomy</br>, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the <br>taxonomy</br> defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our <br>taxonomy</br>) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the <br>taxonomy</br>.",
                "The key to both the task creation and the analysis of the results was our <br>taxonomy</br>, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the <br>taxonomy</br>.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a <br>taxonomy</br> of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the <br>taxonomy</br> with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the <br>taxonomy</br>.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "The study examines the kind of tasks that require users to re-find information and produces a <br>taxonomy</br> of re-finding tasks for email messages and web pages.",
                "The study examines the kind of tasks that require users to re-find information and produces a <br>taxonomy</br> of re-finding tasks for email messages and web pages.",
                "Roddens photo task <br>taxonomy</br> provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Unfortunately, no equivalent <br>taxonomy</br> exists for other types of information object.",
                "To verify the consistency of the <br>taxonomy</br>, the tasks were recategorised by the same researcher after a delay of two weeks."
            ],
            "translated_annotated_samples": [
                "El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una <br>taxonomía</br> de tareas de reencuentro para mensajes de correo electrónico y páginas web.",
                "El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una <br>taxonomía</br> de tareas de reencuentro para mensajes de correo electrónico y páginas web.",
                "La <br>taxonomía</br> de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas.",
                "Desafortunadamente, no existe una <br>taxonomía</br> equivalente para otros tipos de objetos de información.",
                "Para verificar la consistencia de la <br>taxonomía</br>, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una <br>taxonomía</br> de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una <br>taxonomía</br> de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La <br>taxonomía</br> de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una <br>taxonomía</br> equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la <br>taxonomía</br>, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "individual collection": {
            "translated_key": "colecciones individuales",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of <br>individual collection</br>s.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of <br>individual collection</br>s."
            ],
            "translated_annotated_samples": [
                "La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las <br>colecciones individuales</br>."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las <br>colecciones individuales</br>. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "email message": {
            "translated_key": "mensaje de correo electrónico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an <br>email message</br> and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an <br>email message</br> and a description of the task they are performing."
            ],
            "translated_annotated_samples": [
                "El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un <br>mensaje de correo electrónico</br>, y una descripción de la tarea que estaban realizando."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un <br>mensaje de correo electrónico</br>, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "naturalistic approach": {
            "translated_key": "enfoque naturalista",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "laboratory-based study": {
            "translated_key": "estudio basado en laboratorio",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a user evaluation will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a user evaluation investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "user evaluation": {
            "translated_key": "evaluación de usuario",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Towards Task-based Personal Information Management Evaluations David Elsweiler Department Computer and Information Sciences, University of Strathclyde dce@cis.strath.ac.uk Ian Ruthven Department Computer and Information Sciences, University of Strathclyde ir@cis.strath.ac.uk ABSTRACT Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "A feature of PIM research is that many systems have been designed to assist users manage and re-find information, but very few have been evaluated.",
                "This has been noted by several scholars and explained by the difficulties involved in performing PIM evaluations.",
                "The difficulties include that people re-find information from within unique personal collections; researchers know little about the tasks that cause people to re-find information; and numerous privacy issues concerning personal information.",
                "In this paper we aim to facilitate PIM evaluations by addressing each of these difficulties.",
                "In the first part, we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.",
                "Categories and Subject Descriptors H3.3 [Information Search and Retrieval]: General Terms Measurement,Management,Experimentation, Human Factors 1.",
                "INTRODUCTION Personal Information Management (PIM) is a rapidly growing area of research concerned with how people store, manage and re-find information.",
                "PIM systems - the methods and procedures by which people handle, categorize, and retrieve information on a day-to-day basis [18] - are becoming increasingly popular.",
                "However the evaluation of these PIM systems is problematic.",
                "One of the main difficulties is caused by the personal nature of PIM.",
                "People collect information as a natural consequence of completing other tasks.",
                "This means that the collections people generate are unique to them alone and the information within a collection is intrinsically linked with the owners personal experiences.",
                "As personal collections are unique, we cannot create evaluation tasks that are applicable to all participants in an evaluation.",
                "Secondly, personal collections may contain information that the participants are uncomfortable sharing within an evaluation.",
                "The precise nature of this information - what information individuals would prefer to keep private - varies across individuals making it difficult to base search tasks on the contents of individual collections.",
                "Therefore, experimenters face a number of challenges in order to conduct realistic but controlled PIM evaluations.",
                "A particular feature of PIM research is that many systems have been designed to assist users with managing and re-finding their information, but very few have been evaluated; a situation noted by several scholars [1, 6, 7].",
                "Recently, however, researchers have started to focus on ways to address the problem of PIM evaluation.",
                "For example, Kelly [16] proposes that numerous methodologies must be taken to examine and understand the many issues involved in PIM, although, she makes explicit reference to the need for laboratory based PIM studies and a common set of shared tasks to make this possible.",
                "Capra [6] also identifies the need for controlled PIM lab evaluations to complement other evaluation techniques, placing specific emphasis on the need to understand PIM behaviour at the task level.",
                "In this paper, we attempt to address the difficulties involved to faciliate controlled laboratory PIM evaluations.",
                "In the first part of this paper we present a diary study of information re-finding tasks.",
                "The study examines the kind of tasks that require users to re-find information and produces a taxonomy of re-finding tasks for email messages and web pages.",
                "We also look at the features of the tasks that make re-finding difficult.",
                "In the second part, we propose a task-based evaluation methodology based on our findings and examine the feasibility of the approach using different methods of task creation.",
                "Thus, this paper offers two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 2.",
                "RELATED WORK A variety of approaches are available to study PIM.",
                "Naturalistic approaches study participants performing naturally, completing their own tasks as they occur, within familiar environments.",
                "These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.",
                "As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.",
                "A benefit of the approach is that data can be captured continuously over extended time periods and measurements can be taken at fixed points in time within these [15].",
                "Naturalistic approaches can be applied by conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].",
                "Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.",
                "Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.",
                "Secondly, because participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.",
                "An alternative strategy to conducting naturalistic evaluations is to utilise log file analysis.",
                "This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.",
                "In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.",
                "Log file analysis is a powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.",
                "Nevertheless, there are limitations to this strategy.",
                "Firstly, to attain useful results, the deployed prototype must be something that people would use i.e. it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.",
                "Developing a research prototype to this standard is beyond the resources of many researchers.",
                "Further, caution must be taken when analysing logs, as the captured data shows nothing about the goals and intentions that the user had at the time.",
                "It is, therefore, difficult to make any concrete statements about the reasons for the behaviour depicted in the logs.",
                "This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can relate the behaviour of study participants to goals associated with known search tasks.",
                "Laboratory-based studies simulate users real world environment in the controlled setting of the laboratory, offering the ability to study issues that are tightly defined and narrow in scope.",
                "One difficulty in performing this kind of evaluation is sourcing collections to evaluate.",
                "Kelly [16] proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.",
                "This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].",
                "However, a shared collection would be unsuitable for user studies because it would not be possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.",
                "One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.",
                "This approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].",
                "The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.",
                "Another solution is to use the entire web as a collection when studying web page re-finding [4].",
                "This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].",
                "A second difficulty in performing PIM laboratory studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.",
                "Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].",
                "A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.",
                "For example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].",
                "Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].",
                "However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.",
                "Consequently, it is difficult to devise simulated work task situations for PIM.",
                "The exception is the study of personal photograph management, where Roddens work on categorising personal photograph search tasks has facilitated the creation of simulated work task situations [22].",
                "There have been other suggestions as to how to classify PIM tasks.",
                "For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g. [24].",
                "While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.",
                "Personal collections are one reason why task creation is so difficult.",
                "Roddens photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.",
                "Systems can then be compared across task types for different users [11].",
                "Unfortunately, no equivalent taxonomy exists for other types of information object.",
                "Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email collections to create tasks as they were with photographs in [11].",
                "This presents a serious problem - how can researchers devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or jeopardising the privacy of study participants?",
                "A few methods have been proposed.",
                "For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.",
                "This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.",
                "Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.",
                "In section 4 we show that people perform a wider range of email re-finding tasks than this.",
                "In [4], generic search tasks were artificially created by running evaluations over two sessions.",
                "In the first session, participants were asked to complete work tasks that involved finding some unknown information.",
                "In the second session, participants completed the same tasks again, which naturally involved some re-finding behaviour.",
                "The limitations of this technique are that it does not allow participants to exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.",
                "Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.",
                "Our review of evaluation approaches motivates a requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.",
                "Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the privacy of the study participants.",
                "In the following section we present a diary study of refinding tasks for email and web pages.",
                "The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].",
                "In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.",
                "We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.",
                "This knowledge can then be used to construct tasks for use in PIM evaluations. 3.",
                "METHOD Diary Studies are a naturalistic technique, offering the ability to capture factual data, in a natural setting, without the distracting influence of an observer.",
                "Limitations of the technique include difficulties in maintaining participant dedication levels and convincing participants that seemingly mundane information is useful and should be reported [19]. [12] suggest that the effects of the negatives can be limited, however, with careful design and good implementation.",
                "In our diary study, we followed the suggestions in [12] to achieve the best possible data.",
                "To this end, we restricted the recorded tasks to web and email re-finding.",
                "By asking users to record fewer tasks it was anticipated that participant apathy would be reduced and dedication levels maintained.",
                "The participants were provided with a personalised web form in which they could record details about their information needs and the contexts in which these needs developed.",
                "Web forms were deployed rather than paperbased diaries because to re-find web and email information the user would be at a computer with an Internet connection and there would be no need to search for a paper-based diary and pen.",
                "The diary form solicited the following information: whether the information need related to re-finding a web page or an email message and a description of the task they are performing.",
                "This description was to contain both the information that the participant wished to find and the reason that they needed the information.",
                "To help with this, the form gave three example task descriptions, which were also explained verbally to each participant during an introductory session.",
                "The experimenter ensured that the participants understood that the tasks to be recorded were not limited to the types shown in the examples.",
                "The examples were supplied purely to get participants thinking about the kinds of things they could record and to show the level of and type of details expected.",
                "The form also asked participants to rate each task in terms of difficulty (on a scale from 1-5, where 1 was very easy and 5 was very hard).",
                "Finally, they were asked when was the last time they looked at the sought after information.",
                "Again, they were able to choose from 5 options (less than a day ago, less than a week ago, less than a month ago, less than a year ago, more than a year ago).",
                "Time information was used to examine the frequency with which the participants re-found old and new information, and when combined with difficulty ratings created a picture of whether or not the time period between accessing and re-accessing impacted on how difficult the participants perceived tasks to be. 36 participants, recruited by mass advertisement through departmental communication channels, research group meetings and undergraduate lectures, were asked to digitally record details of their information re-finding tasks over a period of approximately 3 weeks.",
                "The final population consisted of 4 academic staff members, 8 research staff members, 6 research students and 18 undergraduate students.",
                "The ages of participants ranged from 19-59.",
                "As both personal and work tasks were recorded, the results collected cover a broad range of re-finding tasks. 4.",
                "RESULTS Several analyses were performed on the captured data.",
                "The following sections present the findings.",
                "Firstly, we examine the kinds of re-finding tasks that were performed both when searching on email and on the web.",
                "Next, we consider the distribution of tasks - which kinds of tasks were performed most often by participants.",
                "Lastly, we explore the kinds of re-finding tasks that participants perceived as difficult. 4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded. 150 (36.41%) of these tasks were email based, 262 (63.59%) were webbased.",
                "As with most diary studies, the number of tasks recorded varied extensively between particpants.",
                "The median number of tasks per participant was 8 (interquartile range (IQR)=9.5).",
                "More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).",
                "This means that on average each participant recorded approximately one task every two days.",
                "From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.",
                "Based on this observation a joint classification scheme was devised, encompassing both email and web tasks.",
                "The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.",
                "Lookup tasks involve searching for specific information from within a resource, for example an email or a web page, where the resource may or may not be known.",
                "Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - its used in a script that is run to set up a practical.",
                "Id previously obtained this about 3 weeks ago from our website. • LU2: I am trying to determine the date by which I step down as an External Examiner.",
                "This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.",
                "I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.",
                "Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.",
                "Lookup tasks involve a need for a small piece of information e.g. a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.",
                "In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.",
                "Multi-item tasks were tasks that required information that was contained within numerous web pages or email messages.",
                "Often these tasks required the user to process or collate the information in order to solve the task.",
                "Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.",
                "Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.",
                "Remind myself of what it is and what it does.",
                "Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.",
                "For example, consider the following recorded task: • LU4: re-find ASs paper on graded relevance assessments because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item task(refind the paper) and 1 lookup task (look for specific information within the paper).",
                "It was decided to treat this as a lookup task because the users ultimate goal was to access and use the information within the resource.",
                "There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.",
                "For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.",
                "It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.",
                "Another problem was that some of the logs lacked the detail required to perform a categorisation e.g. • U1: searching for how to retrieve users selection from a message box.",
                "Decided to use some other means Such tasks were labelled as U for unclassifiable.",
                "To verify the consistency of the taxonomy, the tasks were recategorised by the same researcher after a delay of two weeks.",
                "The agreement between the results of the two analyses was largely consistent (96.8%).",
                "Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.",
                "The second researcher achieved a 90% agreement.",
                "We feel that this high agreement on a large number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.",
                "The distribution of task types is shown in table 1.",
                "Overall, lookup and item tasks were the most common, with multiitem tasks only representing 8.98% of those recorded.",
                "The distribution of the task types was different for web and email re-finding.",
                "The majority of email tasks (60%) involved looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).",
                "Another distinction was the number of recorded multi-item tasks for web and email.",
                "Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).",
                "Lookup Item Multi-item Unclass.",
                "Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the temperature metaphor proposed by [24], which classifies information as one of three temperatures: hot, warm and cold.",
                "We classified the tasks using the form data.",
                "Information that had been seen less than a day or less than a week before the task were defined as hot, information that had been seen less than a month before the task as warm, and information that had been seen less than a year or more than a year before the task as cold.",
                "Unfortunately, a technical difficulty with the form only allowed 335(81.3%) of the tasks to be classified.",
                "The remainder were defined as U for unclassifiable.",
                "A cross-tabulation of task types and temperatures is shown in table 2.",
                "Hot Warm Cold Unclass.",
                "Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.",
                "However there were also a number of re-finding tasks that involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.",
                "This is important with respect to evaluation because there is psychological evidence suggesting that people remember less over time e.g. [23].",
                "This means that users may find searching for older information more difficult or perhaps alter their seeking strategy when looking for hot, warm or cold information. 4.2 What tasks are difficult?",
                "We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than others.",
                "For example, we examined whether the media type affected how difficult the participants perceived the task to be.",
                "There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.",
                "We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.",
                "Figure 1 shows this information graphically.",
                "Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.",
                "To assess the relationship between information temperature and the perceived difficulty, we used Moods median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).",
                "For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).",
                "For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).",
                "These tests confirm that the length of time between accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.",
                "Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e. < 3, suggests that there are other factors that influence how difficult a task is perceived to be.",
                "To learn about these factors would require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work. 4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.",
                "We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple resources.",
                "It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.",
                "Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how difficult the participants perceived tasks to be.",
                "These findings have implications for evaluating PIM behaviour at the task level.",
                "The remainder of this paper concentrates on this, discussing what the findings mean with respect to performing task-based PIM user evaluations. 5.",
                "TASK-BASED PIM EVALUATIONS The findings described in section 4 are useful with respect to evaluation because they provide experimenters with enough knowledge to conduct controlled user evaluations in lab conditions.",
                "Greco-Latin square experimental designs can be constructed where participants are assigned n tasks of the three types described above to perform on their own collections using x systems.",
                "This would allow the performance of the systems or the behaviour of the participants using different systems to be analysed with respect to the type of task being performed (look-up, item, or multi-item).",
                "In the following sections we evaluate the feasibility of this approach when employing different methods of task creation. 5.1 Using Real Tasks One method of creating realistic re-finding tasks without compromising the privacy of participants is to use real tasks.",
                "Diary-studies, similar to that described above, would allow experimenters to capture a pool of tasks for participants to complete by searching on their own collections.",
                "This is extremely advantageous because it would allow experimenters to evaluate the behaviour of real users, completing real search tasks on real collections while in a controlled environment.",
                "There is also the additional benefit that the task descriptions would not make any assumptions about what the user would remember in a real life situation because they would only include the information that had been recorded i.e. the information that was available when the user originally performed the task.",
                "Nevertheless, to gain these benefits we must, firstly, confirm that the task descriptions recorded are of sufficient quality to enable the task to be re-performed at a later date.",
                "Secondly, we must ensure that a diary-study would provide experimenters with enough tasks to construct a balanced experimental design that would satisfy their data needs.",
                "To examine the quality of recorded tasks, 6 weeks after the diary study had completed, we asked 6 of our participants, selected randomly from the pool of those who recorded enough tasks, to re-perform 5 of their own tasks.",
                "The tasks were selected randomly from the pool of those available.",
                "The issued tasks consisted of 10 email and 20 web tasks, 9 of which were lookup tasks, 12 were item tasks, and 8 were multi-item tasks.",
                "The issued tasks represented a broad-sampling of the complete set of recorded tasks.",
                "They also included tasks with vague descriptions e.g. • LU5:Find a software key for an application I required to reinstall. • LU6:Trying to find a quote to use in a paper.",
                "Cannot remember the person or the exact quote The usefulness of such tasks would rely on the memories of participants i.e. would the recorder of task LU5 remember which application he referred to and would the recorder of LU6 remember enough about the context in which the task took place to re-perform the task?",
                "Presented with the tasks exactly as they recorded them, the participants were asked to re-perform each task with any system of their choice.",
                "Of the 30 tasks issued, 26 (86.67%) were completed without problems, 2 (6.67%) of the tasks were not completed because the description recorded was insufficent to recreate the task, and 2 tasks (6.67%) were not completed because the task was too difficult or the required web page no longer existed.",
                "Experimenters are likely to be interested in the final group of tasks because it is important to discover what makes a task difficult and how user behaviour changes in these circumstances.",
                "Therefore, from the 30 tasks tested, only 2 tasks were not of sufficient quality to be used in an evaluation situation.",
                "Further, there did not seem to be any issue of the type, temperature or difficulty ratings affecting the quality of the task descriptions.",
                "These findings suggest that the participants who recorded most tasks in the diary study also recorded tasks with sufficient quality.",
                "However, did the diary study generate enough tasks to satisfy the needs of experimenters?",
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a <br>user evaluation</br> will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "However, for illustrative purposes we chose 5 tasks as a cut-off point for our data.",
                "From tables 3 and 4, which show the quantities of email and web tasks recorded for each participant, we can see that of the 36 participants, only 13 (36.1%) recorded 5 or more email tasks and 20 (55.6%) recorded 5 or more web tasks.",
                "This means that many of the recruited participants could not actually participate in the final evaluation.",
                "This is a major limitation of using recorded tasks in evaluations because participant recruitment for user tests is challenging and it may not be possible to recruit enough participants if experimenters lose between half and two-thirds of their populations.",
                "Further, there was some imbalance in the numbers of recorded tasks of different types.",
                "Some participants recorded several lookup tasks but very few item tasks and others recorded several item tasks but few lookup tasks.",
                "There was also a specific lack of multi-item email tasks.",
                "This situation makes it very difficult for experimenters to prepare balanced experimental designs.",
                "Therefore, even though our first test suggests that the quality of recorded tasks was sufficient for the participants to re-perform the tasks at a later stage, the number of tasks recorded was probably too low to make this a viable option for experimental task creation.",
                "However, it may be possible to increase the number of tasks recorded by frequently reminding participants or by making personal visits etc. 5.2 Using Simulated Tasks Based on Real Tasks Another benefit of diary-studies is that they provide information about the contents and uses of private collections without invading participants privacy.",
                "This section explores the possibility of using a combination of the knowledge gained from diary studies and other attributes known about participants to artificially create re-finding tasks corresponding to the taxonomy defined in section 4.1.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a <br>user evaluation</br> investigating email re-finding behaviour.",
                "Space limitations prevent us from reporting our findings; instead we concentrate on the methods of task creation.",
                "As preparation for the evaluation, we performed a second diary-study, where 34 new participants, consisting of 16 post-graduate students and 18 under-graduate students, recorded 150 email tasks over a period of approximately 3 weeks.",
                "The collected data revealed several patterns that helped with the creation of artificial tasks.",
                "For example, students in both groups recorded tasks relating to classes that they were taking at the time and often different participants recorded tasks that involved searching for the same information.",
                "This was useful because it provided us with a clue that even though some of the participants did not record a particular task, it was possible that the task may still be applicable to their collections.",
                "Other patterns revealed included that students within the same group often searched for emails containing announcements from the same source.",
                "For example, several undergraduate students recorded tasks that included re-finding information relating to job vacancies.",
                "There were also tasks that were recorded by participants in both groups.",
                "For example, searching for an email that would re-confirm the pin code required to access the computer labs.",
                "To supplement our knowledge of the participants email collections, we asked 2 participants from each group to provide email tours.",
                "These consisted of short 5-10 minute sessions, where participants were asked to explain why they use email, who sends them email, and their organisational strategies.",
                "This approach has been used successfully in the past as a non-intrusive means to learn about how people store and maintain their personal information [17].",
                "Originally, we had planned to ask more participants to provide tours, but we found 2 tours per group was sufficient for our needs.",
                "Again, patterns emerged that helped with task creation.",
                "We found content overlap within and between groups that confirmed many of our observations from the diary study data.",
                "For example, the students who gave tours revealed that they received emails from lecturers for particular class assignments, receipts for completed assignments, and various announcements from systems support and about job vacancies.",
                "Importantly, the participants were also able to confirm which other students had received the same information.",
                "This confirmed that many of tasks recorded during the diary study were applicable, not only to the recorder, but to every participant in 1 or both groups.",
                "Based on this initial investigatory work, a set of 15 tasks (5 of each type in our taxonomy) was created for each group of participants.",
                "We also created a set of tasks for a third group of participants that consisted of research and academic staff members, based on our knowledge of the emails our colleagues receive.",
                "Where possible we used the information recorded in the diary study descriptions to provide a context for the task i.e. a work task or motivation that would require the task to be performed.",
                "When the diary study data did not provide sufficient context information to supply the participants with a robust description of the information need, we created simulated work task situations according to the guidelines of [2].",
                "A further advantage of using simulated tasks in this way, rather than real-tasks, is that some of the users will not have performed the task in the recent past and this allows the examination of tasks that look for information of different temperatures.",
                "If only real-tasks had been used all of the participants would have performed the tasks during the period of the diary study.",
                "The created tasks were used in a final evaluation, where we examined the email re-finding behaviour of users with three different email systems. 21 users (7 in each group) performed 9 tasks each (1 task of each type on each system) using their own personal collections in a Greco-Latin square experimental design.",
                "Performing a PIM evaluation in this way allowed the examination of re-finding behaviour in a way not possible before - we were able to observe the email re-finding strategies employed by real users, performing realistic tasks, on their own collections in a controlled environment.",
                "The study revealed that the participants remembered different attributes of emails, demostrated different finding behaviour, and exhibited different levels of performance when asked to complete tasks of the different types in the taxonomy.",
                "The key to both the task creation and the analysis of the results was our taxonomy, which provided the template to create tasks and also a means to compare the behaviour and performance of different users (and systems) performing different tasks of the same type.",
                "Some of the findings of the evaluation will be published in [10].",
                "Summarising the approach, to conduct a user experiment using our methodology, researchers would be required to perform the following steps: 1)Conduct a diary study as above 1 . 2)Analyse the recorded tasks looking for overlap between the participants. 3)Supplement the gained knowledge about the contents of participants collections by asking a selection of the participants to provide a tour of their collection. 4)Use the knowledge gained to devise tasks of the three different types defined within the taxonomy.",
                "More de1 Information about this and the diary forms required can be found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations tailed information on how to use the research described in this paper to perform task-based PIM evaluations can be found at our website (see footnote 1). 6.",
                "CONCLUSIONS This paper has focused on overcoming the difficulties involved in performing PIM evaluations.",
                "The personal nature of PIM means that it is difficult to construct balanced experiments because participants each have their own unique collections that are self-generated by completing other tasks.",
                "We suggested that to incorporate the personal aspects of PIM in evaluations, the performance of systems or users should be examined when users complete tasks on their own collections.",
                "This approach itself has problems because task creation for personal collections is difficult: researchers dont know much about the kinds of re-finding tasks people perform and they dont know what information is within individual personal collections.",
                "In this paper we described ways of overcoming these challenges to facilitate task based PIM user evaluations.",
                "In the first part of the paper we performed a diary study that examined the tasks that caused people to re-find email messages and web pages.",
                "The collected data included a wide range of both work and non-work related tasks, and based on the data we created a taxonomy of web and email re-finding tasks.",
                "We discovered that people perform three main types of re-finding task: tasks that require specific information from within a single resource, tasks that require a single complete resource, and tasks that require information to be recovered from multiple resources.",
                "In the second part of the paper, we discussed the significance of the taxonomy with respect to PIM evaluation.",
                "We demonstrated that balanced experiments could be conducted comparing system or user performance on the task categories within the taxonomy.",
                "We also suggested two methods of creating tasks that can be completed on personal collections.",
                "These methods do not compromise the privacy of study participants.",
                "We examined the techniques suggested, firstly by simulating an experimental situation - participants were asked to re-perform their own tasks as they recorded them, and secondly, in the context of a full evaluation.",
                "Performing evaluations in this way will allow systems that have been proposed to improve users ability to manage and re-find their information to be tested, so that we can learn about the needs and desires of users.",
                "Thus, this paper has offered two contributions to the field: an increased understanding of PIM behaviour at the task level and an evaluation method that will facilitate further investigations. 7.",
                "ACKNOWLEDGMENTS We would like to thank Dr Mark Baillie for his insightful comments and help analysing the data. 8.",
                "REFERENCES [1] R. Boardman, Improving tool support for personal information management, Ph.D. thesis, Imperial College London, 2004. [2] P. Borlund, The iir evaluation model: A framework for evaluation of interactive information retrieval systems, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Bystr¨om and K. J¨arvelin, Task complexity affects information seeking and use, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra and M. A. Perez-Quinones, Re-finding found things: An exploratory study of how users re-find information, Tech. report, Virginia Tech, 2003. [5] R. G. Capra and M. A. Perez-Quinones, Using web search engines to find and refind information, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra and M. A. Perez-Quinones, Factors and evaluation of refinding behaviors., SIGIR 2006 Workshop on Personal Information Management, August 10-11, 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais, and R.Sarin, Fast, flexible filtering with phlat, Proc.",
                "SIGCHI 06 (New York, NY, USA), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz, and S. Wilhite, A diary study of task switching and interruptions, Proc.",
                "SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, and D.C. Robbins, Stuff ive seen: a system for personal information retrieval and re-use, Proc.",
                "SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memory and email re-finding, In preparation for ACM TOIS CFP special issue on Keeping, Re-finding, and Sharing Personal Information (2007). [11] D. Elsweiler, I. Ruthven, and C. Jones, Dealing with fragmented recollection of context in information management, Context-Based Information Retrieval (CIR-05) Workshop in CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven, and C. Jones, Towards memory supporting personal information management tools, (to appear in) Journal of the American Society for Information Science and Technology (2007). [13] D. Harman, What we have learned, and not learned, from trec, Proc.",
                "ECIR 2000, 2000. [14] P. Ingwersen, Information retrieval interaction, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt, and M. Skeels (eds. ), Pim workshop report: Measurement and design, 2005. [16] D. Kelly and J. Teevan, (to appear in) personal information management, ch.",
                "Understanding what works: Evaluating personal information management tools, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, How a personal documents intended use or purpose affects its classification in an office, SIGIR89 23 (1989), no.",
                "SI, 207-210. [18] M.W.",
                "Lansdale, The psychology of personal information management., Appl Ergon 19 (1988), no. 1, 55-66. [19] L. Palen and M. Salzman, Voice-mail diary studies for naturalistic data capture under mobile conditions, CSCW 02: Proceedings of the 2002 ACM conference on Computer supported cooperative work, 2002. [20] M. Ringel, E. Cutrell, S. Dumais, and E. Horvitz, Milestones in time: The value of landmarks in retrieving information from personal stores., Proc.",
                "INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, and M. van Dantzich, Data mountain: using spatial memory for document management, Proc.",
                "UIST 98:, 1998. [22] K. Rodden, How do people organise their photographs, BCS IRSG 21st Annual Colloquium on Information Retrieval Research,Glasgow, Scotland, 1999. [23] D.C. Rubin and A.E.",
                "Wenzel, One hundred years of forgetting: A quantitative description of retention, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen and R. H. R. Harper, The myth of the paperless office, MIT Press, Cambridge, MA, USA, 2003. [25] P. Vakkari, Task complexity, problem structure and information actions: Integrating studies in on information seeking and retrieval., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, A theory of task-based information retrieval, Journal of Documentation 57 (2001), no. 1, 44-60."
            ],
            "original_annotated_samples": [
                "Participant Tasks Lookup Item Multi-item Unclass. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Table 3: The quantities of recorded email tasks Participant Tasks Lookup Item Multi-item Unclass. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Table 4: The quantities of recorded web tasks Naturally the exact number of tasks required to perform a <br>user evaluation</br> will depend on the goals of the evaluation, the number of users and the number of systems to be tested etc.",
                "We explain the techniques used and demonstrate the feasibility of creating simulated tasks within the context of a <br>user evaluation</br> investigating email re-finding behaviour."
            ],
            "translated_annotated_samples": [
                "Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una <br>evaluación de usuario</br> dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc.",
                "Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una <br>evaluación de usuario</br> que investiga el comportamiento de reencontrar correos electrónicos."
            ],
            "translated_text": "Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una <br>evaluación de usuario</br> dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una <br>evaluación de usuario</br> que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}